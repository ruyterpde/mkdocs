{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#home","title":"Home","text":"<p>My Personal Documentation Hub</p> <p>Hey there! This is my personal space where I collect notes, thoughts, and documentation on a wide variety of topics and small projects I\u2019ve explored over time. From tech snippets and DIY hacks to random experiments\u2014this is basically my digital notebook.</p> <p>Please keep in mind:</p> <ul> <li>These notes are primarily for my own use, but I\u2019ve made them publicly available in case they\u2019re useful to others too.</li> <li>I do my best to be accurate, but I\u2019m not responsible for any errors or misunderstandings that might be here, or any consequences that may result from using this information.</li> </ul> <p>Feel free to browse, learn, get inspired\u2014or just see how someone else keeps their brain organized. Thanks for stopping by!</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#about","title":"About","text":"<p>Welcome to RUYTER.ORG (dms), the organized chaos of my brain!</p> <p>Here you'll find an ever-growing collection of notes, ideas, and how-to's on all sorts of topics I've explored - tech stuff, tools, tiny side projects, and whatever else caught my curiosity. It's not perfect, and it's not always polished, but it's real and (hopefully) helpful.</p> <p>Please be advised:</p> <ul> <li>If you\u2019re curious about the boring but important stuff, check out the Legal and Privacy pages.</li> <li>And if you want to say hi or have a question, feel free to Contact me.</li> </ul> <p>Everything here was written mainly for my future self, but if it helps you too, awesome! Dive in, poke around, and make of it what you will.</p>"},{"location":"credits/","title":"Credits","text":""},{"location":"credits/#credits","title":"Credits","text":"<p>Credits &amp; Shoutouts!</p> <p>This little corner of the internet didn\u2019t come together in a vacuum. It\u2019s built on the shoulders of some amazing tools, open-source projects, and generous communities who\u2019ve shared their work, knowledge, and time.</p> <ul> <li> <p>Here\u2019s a non-exhaustive list of the stuff (and people) that helped make this site\u2014and the ideas in it\u2014possible:  </p> <ul> <li>https://www.youtube.com/@Frenck</li> <li>https://www.youtube.com/@james-willett</li> <li>https://www.youtube.com/@SmartHomeJunkie  </li> </ul> </li> <li> <p>Open-source everything \u2013 From code editors to static site generators, I owe a huge thanks to the open-source community. Special mentions to [Home-Assistant], [MkDocs], and [Material] for making my life easier.</p> </li> <li> <p>Docs, forums &amp; stack traces \u2013 The unsung heroes. Stack Overflow, GitHub Issues, and countless random blog posts saved me more times than I can count.</p> </li> <li> <p>Fonts, icons &amp; UI bits \u2013 Some visual flair courtesy of [Font/Design Resource] and [Icon Set], because why not make things look nice while we\u2019re here?</p> </li> <li> <p>Friends, mentors &amp; internet strangers \u2013 Whether it was a tip in a Discord thread or a late-night debug session, I\u2019m grateful for every bit of help along the way.</p> </li> <li> <p>My past self \u2013 For bothering to write things down when I didn\u2019t feel like it. You did good, buddy.</p> </li> </ul> <p>This is all a patchwork of shared knowledge and personal trial-and-error, stitched together into something (hopefully) useful. If I\u2019ve missed giving credit where it's due, it wasn\u2019t intentional\u2014just let me know and I\u2019ll fix it.  </p> <p>Thanks to everyone who helped\u2014even if you didn\u2019t know you did.</p>"},{"location":"links/","title":"Links","text":""},{"location":"links/#links","title":"Links","text":"<p>External links used across the documentation, sorted alphabetically by link text.</p> <p>This list is generated automatically, so it may be a little messy.</p>"},{"location":"links/#_1","title":"Links","text":"<ul> <li>$13 voice assistant for Home Assistant</li> </ul>"},{"location":"links/#a","title":"A","text":"<ul> <li>Adding a custom sentence</li> </ul>"},{"location":"links/#c","title":"C","text":"<ul> <li>CallMeBot Website</li> <li>Chocolatey Node.js Package</li> <li>Cloud Convert Dashboard</li> <li>cloudconvert.com</li> <li>Community Edition n8n</li> <li>Community Forum</li> <li>Community Themes and Custom Cards</li> <li>Contact</li> <li>Control your Windows PC with Home Assistant</li> <li>Customizing responses</li> </ul>"},{"location":"links/#d","title":"D","text":"<ul> <li>Docker in WSL Guide</li> <li>Docker Official Documentation</li> </ul>"},{"location":"links/#e","title":"E","text":"<ul> <li>ESPHome Documentation</li> <li>Example Waste Collection APIs</li> <li>Experta Documentation</li> </ul>"},{"location":"links/#f","title":"F","text":"<ul> <li>fal.ai</li> <li>fal.ai Official Documentation</li> <li>Flask Web Framework</li> <li>fortuna/m5stack-atom-echo.yaml</li> </ul>"},{"location":"links/#g","title":"G","text":"<ul> <li>Generic x86-64</li> <li>Get started Prep Windows for containers</li> <li>Getting started - Local Assist</li> <li>Glances MQTT Integration</li> <li>Glances Official Documentation</li> <li>Google Style Docstring</li> </ul>"},{"location":"links/#h","title":"H","text":"<ul> <li>HASS Agent Documentation</li> <li>HASS Agent GitHub</li> <li>HASS Agent Releases</li> <li>HASS Agent Setup</li> <li>HASS Agent Wiki</li> <li>Helpers in Home Assistant</li> <li>Home Assistant Add-ons Guide</li> <li>Home Assistant Dashboard Documentation</li> <li>Home Assistant Documentation</li> <li>Home Assistant Downloads</li> <li>Home Assistant ESPHome Guide</li> <li>Home Assistant Integration Guide</li> <li>Home Assistant Light Integration</li> <li>Home Assistant MQTT Documentation</li> <li>Home Assistant MQTT Integration</li> <li>Home Assistant Networking</li> <li>Home Assistant Official Voice Documentation</li> <li>Home Assistant Pipeline</li> <li>Home Assistant Template Sensors</li> <li>home-assistant/esphome-firmware</li> <li>HomeWizard P1 API Documentation</li> <li>HomeWizard P1 Meter</li> <li>Hosting n8n</li> <li>How To Update the Sonoff Dongle E to Ember firmware</li> </ul>"},{"location":"links/#i","title":"I","text":"<ul> <li>IIS URL Rewrite Guide</li> <li>Install Docker</li> <li>Install HAOS without UEFI</li> <li>Installation Zigbee2MQTT on Github</li> <li>Installing PowerShell on Windows</li> </ul>"},{"location":"links/#l","title":"L","text":"<ul> <li>Legal</li> <li>Let's Encrypt Guide</li> <li>Llama.cpp Repository</li> <li>LOCAL VOICE CONTROL of Home Assistant with the M5Stack Atom Echo</li> </ul>"},{"location":"links/#m","title":"M","text":"<ul> <li>M5STACK ATOM ECHO Smart Speaker Development Kit</li> <li>m5stack-atom-echo.yaml</li> <li>Material Design Icons</li> <li>media-players/m5stack/m5stack-atom-echo.yaml</li> <li>Microsoft IIS ARR Documentation</li> <li>Microsoft IIS Extensions</li> <li>MkDocs Official Documentation</li> <li>MkDocs-Material Documentation</li> <li>Models section</li> <li>Mosquitto MQTT Broker</li> <li>Mosquitto Official Documentation</li> <li>MSYS2</li> </ul>"},{"location":"links/#n","title":"N","text":"<ul> <li>n8n Documentation</li> <li>n8n Official Docs</li> <li>NGINX Reverse Proxy Setup</li> <li>Node.js Official Documentation</li> </ul>"},{"location":"links/#o","title":"O","text":"<ul> <li>Official Cloud Convert API documentation</li> <li>Official Node.js website</li> <li>Official Python website</li> <li>Official Zigbee2MQTT Documentation</li> <li>Ollama Official Documentation</li> <li>ollama.com/download</li> <li>Online UUID Generator Tool</li> <li>OpenAI Whisper</li> <li>OpenWakeWord GitHub</li> <li>OS 15.x fails to boot on certain SATA drives</li> </ul>"},{"location":"links/#p","title":"P","text":"<ul> <li>PEP 8</li> <li>Privacy</li> <li>Pymdown Extensions Documentation</li> <li>Python Markdown</li> </ul>"},{"location":"links/#r","title":"R","text":"<ul> <li>Ready-Made Projects \u2014 ESPHome</li> <li>Rufus</li> </ul>"},{"location":"links/#s","title":"S","text":"<ul> <li>Scoop Node.js Package</li> <li>Service exited with code 256 (by signal 4) on x86_64</li> <li>Sonoff Zigbee 3.0 USB Dongle Documentation</li> <li>Sonoff Zigbee 3.0 USB Dongle Firmware Download</li> <li>Sonoff Zigbee 3.0 USB Dongle Firmware Flasher</li> <li>Sonoff Zigbee 3.0 USB Dongle Plus-E V2</li> <li>Switching to Docker</li> <li>System Bridge</li> </ul>"},{"location":"links/#t","title":"T","text":"<ul> <li>Templates and Custom Sensors in Home Assistant</li> <li>Tools for Node.js</li> </ul>"},{"location":"links/#w","title":"W","text":"<ul> <li>WSL Documentation</li> <li>Wyoming</li> <li>Wyoming-Whisper</li> </ul>"},{"location":"links/#z","title":"Z","text":"<ul> <li>ZHA Documentation</li> <li>Zigbee Firmware Repository</li> <li>Zigbee Map Community Thread</li> <li>Zigbee Map Releases</li> <li>zigbee-map-panel.js</li> </ul>"},{"location":"sitemap/","title":"Sitemap","text":""},{"location":"sitemap/#sitemap","title":"Sitemap","text":"<pre><code>graph LR\nN1[\"Home\"]\nN2[\"About\"]\nN3[\"Blog\"]\nN4[\"Credits\"]\nN5[\"Documentation\"]\nN6[\"Home Assistant\"]\nN5 --&gt; N6\nN7[\"Add-Ons\"]\nN6 --&gt; N7\nN8[\"Esphome\"]\nN7 --&gt; N8\nN9[\"Mosquitto Broker\"]\nN7 --&gt; N9\nN10[\"Zigbee2Mqtt\"]\nN7 --&gt; N10\nN11[\"Zigbee Map\"]\nN7 --&gt; N11\nN12[\"Assist\"]\nN6 --&gt; N12\nN13[\"Commands\"]\nN12 --&gt; N13\nN14[\"Setup\"]\nN12 --&gt; N14\nN15[\"Whisper\"]\nN12 --&gt; N15\nN16[\"Dashboards\"]\nN6 --&gt; N16\nN17[\"Cards\"]\nN16 --&gt; N17\nN18[\"Custom\"]\nN17 --&gt; N18\nN19[\"Button-Card\"]\nN18 --&gt; N19\nN20[\"Hardware\"]\nN6 --&gt; N20\nN21[\"Homewizard\"]\nN20 --&gt; N21\nN22[\"M5Stack\"]\nN20 --&gt; N22\nN23[\"Sonoff\"]\nN20 --&gt; N23\nN24[\"Installation\"]\nN6 --&gt; N24\nN25[\"Integrations\"]\nN6 --&gt; N25\nN26[\"Esphome\"]\nN25 --&gt; N26\nN27[\"Hass Agent\"]\nN25 --&gt; N27\nN28[\"Mqtt\"]\nN25 --&gt; N28\nN29[\"Messaging\"]\nN6 --&gt; N29\nN30[\"Whatsapp\"]\nN29 --&gt; N30\nN31[\"Monitoring\"]\nN6 --&gt; N31\nN32[\"Glances\"]\nN31 --&gt; N32\nN33[\"Sensors\"]\nN6 --&gt; N33\nN34[\"Battery-Sensor\"]\nN33 --&gt; N34\nN35[\"Lights-Sensor\"]\nN33 --&gt; N35\nN36[\"Trash-Sensor\"]\nN33 --&gt; N36\nN37[\"Local Ai\"]\nN5 --&gt; N37\nN38[\"Installation\"]\nN37 --&gt; N38\nN39[\"Offline Assistant\"]\nN37 --&gt; N39\nN40[\"Local N8N\"]\nN5 --&gt; N40\nN41[\"Accessibility\"]\nN40 --&gt; N41\nN42[\"Configuration\"]\nN40 --&gt; N42\nN43[\"Docker\"]\nN40 --&gt; N43\nN44[\"Installation\"]\nN40 --&gt; N44\nN45[\"Nginx N8N\"]\nN40 --&gt; N45\nN46[\"Workflows\"]\nN40 --&gt; N46\nN47[\"Mkdocs\"]\nN5 --&gt; N47\nN48[\"Configuration\"]\nN47 --&gt; N48\nN49[\"Installation\"]\nN47 --&gt; N49\nN50[\"Links\"]\nN47 --&gt; N50\nN51[\"Theme\"]\nN47 --&gt; N51\nN52[\"Server\"]\nN5 --&gt; N52\nN53[\"Software\"]\nN52 --&gt; N53\nN54[\"Docker%20Desktop\"]\nN53 --&gt; N54\nN55[\"Volumes\"]\nN54 --&gt; N55\nN56[\"Backup\"]\nN55 --&gt; N56\nN57[\"Restore\"]\nN55 --&gt; N57\nN58[\"Start-Stop Script\"]\nN53 --&gt; N58\nN59[\"Configuration\"]\nN52 --&gt; N59\nN60[\"Installation\"]\nN52 --&gt; N60\nN61[\"Howto\"]\nN62[\"Cmd\"]\nN61 --&gt; N62\nN63[\"Docker.Exe\"]\nN62 --&gt; N63\nN64[\"Manage-Bde.Exe\"]\nN62 --&gt; N64\nN65[\"Mklink.Exe\"]\nN62 --&gt; N65\nN66[\"W32Tm.Exe\"]\nN62 --&gt; N66\nN67[\"Powershell\"]\nN61 --&gt; N67\nN68[\"Learn%20About%20This%20Picture\"]\nN67 --&gt; N68\nN69[\"Product%20Key\"]\nN67 --&gt; N69\nN70[\"Links\"]\nN71[\"Sitemap\"]\nN72[\"Tutorials\"]\nN73[\"All Public Functions\"]\nN72 --&gt; N73\nN74[\"Cloudconvert\"]\nN72 --&gt; N74\nN75[\"Falai\"]\nN72 --&gt; N75\nN76[\"Pixeldrain\"]\nN72 --&gt; N76\nclick N1 \"/\"\nclick N2 \"/about/\"\nclick N3 \"/blog/\"\nclick N4 \"/credits/\"\nclick N5 \"/documentation/\"\nclick N6 \"/documentation/Home_Assistant/\"\nclick N7 \"/documentation/Home_Assistant/add-ons/\"\nclick N8 \"/documentation/Home_Assistant/add-ons/esphome/\"\nclick N9 \"/documentation/Home_Assistant/add-ons/mosquitto_broker/\"\nclick N10 \"/documentation/Home_Assistant/add-ons/zigbee2mqtt/\"\nclick N11 \"/documentation/Home_Assistant/add-ons/zigbee_map/\"\nclick N12 \"/documentation/Home_Assistant/assist/\"\nclick N13 \"/documentation/Home_Assistant/assist/commands/\"\nclick N14 \"/documentation/Home_Assistant/assist/setup/\"\nclick N15 \"/documentation/Home_Assistant/assist/whisper/\"\nclick N16 \"/documentation/Home_Assistant/dashboards/\"\nclick N17 \"/documentation/Home_Assistant/dashboards/cards/\"\nclick N18 \"/documentation/Home_Assistant/dashboards/cards/custom/\"\nclick N19 \"/documentation/Home_Assistant/dashboards/cards/custom/button-card/\"\nclick N20 \"/documentation/Home_Assistant/hardware/\"\nclick N21 \"/documentation/Home_Assistant/hardware/homewizard/\"\nclick N22 \"/documentation/Home_Assistant/hardware/m5stack/\"\nclick N23 \"/documentation/Home_Assistant/hardware/sonoff/\"\nclick N24 \"/documentation/Home_Assistant/installation/\"\nclick N25 \"/documentation/Home_Assistant/integrations/\"\nclick N26 \"/documentation/Home_Assistant/integrations/esphome/\"\nclick N27 \"/documentation/Home_Assistant/integrations/hass_agent/\"\nclick N28 \"/documentation/Home_Assistant/integrations/mqtt/\"\nclick N29 \"/documentation/Home_Assistant/messaging/\"\nclick N30 \"/documentation/Home_Assistant/messaging/whatsapp/\"\nclick N31 \"/documentation/Home_Assistant/monitoring/\"\nclick N32 \"/documentation/Home_Assistant/monitoring/glances/\"\nclick N33 \"/documentation/Home_Assistant/sensors/\"\nclick N34 \"/documentation/Home_Assistant/sensors/battery-sensor/\"\nclick N35 \"/documentation/Home_Assistant/sensors/lights-sensor/\"\nclick N36 \"/documentation/Home_Assistant/sensors/trash-sensor/\"\nclick N37 \"/documentation/Local_AI/\"\nclick N38 \"/documentation/Local_AI/installation/\"\nclick N39 \"/documentation/Local_AI/offline_assistant/\"\nclick N40 \"/documentation/Local_n8n/\"\nclick N41 \"/documentation/Local_n8n/accessibility/\"\nclick N42 \"/documentation/Local_n8n/configuration/\"\nclick N43 \"/documentation/Local_n8n/docker/\"\nclick N44 \"/documentation/Local_n8n/installation/\"\nclick N45 \"/documentation/Local_n8n/nginx_n8n/\"\nclick N46 \"/documentation/Local_n8n/workflows/\"\nclick N47 \"/documentation/MkDocs/\"\nclick N48 \"/documentation/MkDocs/configuration/\"\nclick N49 \"/documentation/MkDocs/installation/\"\nclick N50 \"/documentation/MkDocs/links/\"\nclick N51 \"/documentation/MkDocs/theme/\"\nclick N52 \"/documentation/Server/\"\nclick N53 \"/documentation/Server/Software/\"\nclick N54 \"/documentation/Server/Software/Docker%20Desktop/\"\nclick N55 \"/documentation/Server/Software/Docker%20Desktop/Volumes/\"\nclick N56 \"/documentation/Server/Software/Docker%20Desktop/Volumes/backup/\"\nclick N57 \"/documentation/Server/Software/Docker%20Desktop/Volumes/restore/\"\nclick N58 \"/documentation/Server/Software/start-stop_script/\"\nclick N59 \"/documentation/Server/configuration/\"\nclick N60 \"/documentation/Server/installation/\"\nclick N61 \"/howto/\"\nclick N62 \"/howto/cmd/\"\nclick N63 \"/howto/cmd/docker.exe/\"\nclick N64 \"/howto/cmd/manage-bde.exe/\"\nclick N65 \"/howto/cmd/mklink.exe/\"\nclick N66 \"/howto/cmd/w32tm.exe/\"\nclick N67 \"/howto/powershell/\"\nclick N68 \"/howto/powershell/learn%20about%20this%20picture/\"\nclick N69 \"/howto/powershell/product%20key/\"\nclick N70 \"/links/\"\nclick N71 \"/sitemap/\"\nclick N72 \"/tutorials/\"\nclick N73 \"/tutorials/all_public_functions/\"\nclick N74 \"/tutorials/cloudconvert/\"\nclick N75 \"/tutorials/falai/\"\nclick N76 \"/tutorials/pixeldrain/\"</code></pre>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2025/05/01/welcome/","title":"Welcome!","text":""},{"location":"blog/2025/05/01/welcome/#welcome","title":"Welcome!","text":"<p>This is my personal space.</p> <p>Here you'll find an ever-growing collection of notes, ideas, and how-to's on all sorts of topics I've explored - tech stuff, tools, tiny side projects, and whatever else caught my curiosity. It's not perfect, and it's not always polished, but it's real and (hopefully) helpful.</p>"},{"location":"documentation/Home_Assistant/dashboards/","title":"Dashboards","text":""},{"location":"documentation/Home_Assistant/dashboards/#dashboards","title":"Dashboards","text":""},{"location":"documentation/Home_Assistant/dashboards/#generating-dashboards-for-home-assistant","title":"Generating Dashboards for Home Assistant","text":"<p>A comprehensive guide to designing, configuring, and optimizing Home Assistant dashboards.</p>"},{"location":"documentation/Home_Assistant/dashboards/#overview","title":"Overview","text":"<p>Home Assistant dashboards allow users to visualize and control smart home devices. This guide covers the setup, customization, and best practices for creating user-friendly dashboards.</p>"},{"location":"documentation/Home_Assistant/dashboards/#technical-details","title":"Technical Details","text":"<p>Home Assistant provides Lovelace as a powerful and customizable UI framework. Dashboards can be configured using YAML or the UI editor, integrating various cards, themes, and custom components.</p>"},{"location":"documentation/Home_Assistant/dashboards/#infobox","title":"Infobox","text":"Feature Description UI Mode Drag-and-drop visual editor YAML Mode Manual configuration for advanced customization Custom Cards Additional functionalities beyond built-in components Themes Personalized dashboard styling"},{"location":"documentation/Home_Assistant/dashboards/#steps","title":"Steps","text":"<ol> <li> <p>Access the Dashboard    Navigate to <code>Settings &gt; Dashboards</code> in Home Assistant UI.</p> </li> <li> <p>Create a New Dashboard    Click <code>Add Dashboard</code> and provide a name and icon.</p> </li> <li> <p>Choose Configuration Mode    Select either <code>UI Editor</code> or <code>YAML Editor</code>.</p> </li> <li> <p>Add Cards    Use the editor to add components such as buttons, graphs, or entity controls.</p> </li> <li> <p>Customize Layout    Arrange cards in a grid format and set visibility conditions.</p> </li> <li> <p>Apply Themes    Select or customize a theme for aesthetic improvements.</p> </li> <li> <p>Save &amp; Test    Ensure functionality and responsiveness across devices.</p> </li> </ol>"},{"location":"documentation/Home_Assistant/dashboards/#commands","title":"Commands","text":"<pre><code># Example YAML configuration for a custom dashboard\ntitle: My Dashboard\nviews:\n  - title: Home\n    path: home\n    cards:\n      - type: entity\n        entity: light.living_room\n</code></pre>"},{"location":"documentation/Home_Assistant/dashboards/#examples","title":"Examples","text":"<pre><code># Adding a graph card\ntype: history-graph\nentities:\n  - entity: sensor.temperature_living_room\n</code></pre>"},{"location":"documentation/Home_Assistant/dashboards/#summary","title":"Summary","text":"<ul> <li>Framework: Lovelace UI</li> <li>Configuration: YAML-based or through graphical UI editor</li> <li>Customization: Full control over layouts, themes, and views</li> <li>Device Support: Responsive design for mobile, tablet, and desktop</li> <li>User Personalization: Per-user dashboards and custom visibility options</li> <li>Dynamic Content: Real-time updates based on entity states</li> <li>Card System: Modular design with a wide variety of built-in and custom cards</li> <li>Theming: Supports custom themes (dark mode, light mode, color schemes)</li> <li>Access Control: User authentication and permission-based dashboard access</li> <li>Extensions: Support for custom cards and third-party plugins</li> </ul>"},{"location":"documentation/Home_Assistant/dashboards/#resources","title":"Resources","text":"<ul> <li>Home Assistant Dashboard Documentation</li> <li>Community Themes and Custom Cards</li> </ul>"},{"location":"documentation/Home_Assistant/dashboards/#troubleshooting","title":"Troubleshooting","text":"Issue Resolution Dashboard not loading Clear browser cache or restart Home Assistant Missing entities Check device status and ensure proper integration Styling issues Verify theme settings and card configurations <p>This guide provides essential details to create efficient and visually appealing dashboards in Home Assistant. Happy automating!</p> <p>Generated using AI </p>"},{"location":"documentation/Home_Assistant/installation/","title":"Installation","text":""},{"location":"documentation/Home_Assistant/installation/#installation","title":"Installation","text":""},{"location":"documentation/Home_Assistant/installation/#installation-of-home-assistant-on-legacy-hardware-x64-without-uefi-bios","title":"Installation of Home Assistant on Legacy Hardware x64 without UEFI BIOS","text":""},{"location":"documentation/Home_Assistant/installation/#overview","title":"Overview","text":"<p>This guide provides step-by-step instructions for installing Home Assistant on legacy x64 hardware that does not support UEFI BIOS. It covers the preparation of bootable media, BIOS configuration, and installation of the Home Assistant Operating System (HAOS).</p>"},{"location":"documentation/Home_Assistant/installation/#technical-details","title":"Technical Details","text":"<ul> <li>Hardware Requirements:</li> <li>x64 architecture</li> <li>Legacy BIOS (non-UEFI)</li> <li>Minimum 2 GB RAM and 32 GB storage</li> <li>Software Requirements:</li> <li>Home Assistant Operating System (HAOS) image</li> <li>Rufus for creating bootable media</li> <li>Outcome: A fully functional Home Assistant instance running on legacy hardware.</li> </ul>"},{"location":"documentation/Home_Assistant/installation/#infobox","title":"Infobox","text":"<p>Key Facts: - Platform: Legacy x64 hardware - Boot Mode: Legacy BIOS - Use Case: Home automation on older hardware - Tools: Rufus, HAOS image</p>"},{"location":"documentation/Home_Assistant/installation/#steps","title":"Steps","text":""},{"location":"documentation/Home_Assistant/installation/#1-download-the-home-assistant-operating-system-image","title":"1. Download the Home Assistant Operating System Image","text":"<ol> <li>Visit the Home Assistant Downloads page.</li> <li>Select the appropriate image for your hardware (e.g., x64 Generic).</li> <li>Download the <code>.img.xz</code> file to your computer.</li> </ol>"},{"location":"documentation/Home_Assistant/installation/#2-prepare-bootable-media","title":"2. Prepare Bootable Media","text":"<ol> <li>Insert a USB drive (minimum 8 GB) into your computer.</li> <li>Use a tool like Balena Etcher or Rufus to create bootable media:</li> <li>Rufus:<ol> <li>Open Rufus.</li> <li>Select the USB drive.</li> <li>Choose the downloaded <code>.img.xz</code> file.</li> <li>Set the partition scheme to \"MBR\" for legacy BIOS.</li> <li>Click \"Start\" to create the bootable media.</li> </ol> </li> </ol>"},{"location":"documentation/Home_Assistant/installation/#3-configure-bios-settings","title":"3. Configure BIOS Settings","text":"<ol> <li>Restart your computer and enter the BIOS setup (usually by pressing <code>DEL</code>, <code>F2</code>, or <code>F12</code> during boot).</li> <li>Ensure the following settings are configured:</li> <li>Boot Mode: Legacy BIOS</li> <li>Secure Boot: Disabled</li> <li>Boot Priority: Set the USB drive as the first boot device.</li> <li>Save changes and exit the BIOS.</li> </ol>"},{"location":"documentation/Home_Assistant/installation/#4-install-home-assistant-operating-system","title":"4. Install Home Assistant Operating System","text":"<ol> <li>Insert the bootable USB drive into the target hardware.</li> <li>Power on the hardware and boot from the USB drive.</li> <li>Follow the on-screen instructions to install HAOS on the internal storage.</li> <li>Once the installation is complete, the system will reboot automatically.</li> </ol>"},{"location":"documentation/Home_Assistant/installation/#5-access-home-assistant","title":"5. Access Home Assistant","text":"<ol> <li>Connect the hardware to your network via Ethernet or Wi-Fi.</li> <li>Open a web browser on a device connected to the same network.</li> <li>Navigate to <code>http://homeassistant.local:8123</code> or the IP address assigned to the device.</li> <li>Complete the initial setup wizard to configure your Home Assistant instance.</li> </ol>"},{"location":"documentation/Home_Assistant/installation/#examples","title":"Examples","text":""},{"location":"documentation/Home_Assistant/installation/#bios-configuration-example","title":"BIOS Configuration Example","text":"<ul> <li>Boot Mode: Legacy</li> <li>Secure Boot: Disabled</li> <li>Boot Priority: USB Drive &gt; Hard Disk</li> </ul>"},{"location":"documentation/Home_Assistant/installation/#yaml-configuration-for-static-ip","title":"YAML Configuration for Static IP","text":"<pre><code>network:\n  version: 2\n  ethernets:\n    eth0:\n      dhcp4: false\n      addresses:\n        - 192.168.1.100/24\n      gateway4: 192.168.1.1\n      nameservers:\n        addresses:\n          - 8.8.8.8\n          - 8.8.4.4\n</code></pre>"},{"location":"documentation/Home_Assistant/installation/#resources","title":"Resources","text":"<ul> <li>Home Assistant Installation Guide</li> <li>Rufus</li> <li>Home Assistant Networking</li> <li>Generic x86-64</li> </ul>"},{"location":"documentation/Home_Assistant/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/Home_Assistant/installation/#issue-usb-drive-not-detected-in-bios","title":"Issue: USB Drive Not Detected in BIOS","text":"<p>Resolution: Ensure the USB drive is properly formatted and inserted. Try a different USB port or recreate the bootable media.</p>"},{"location":"documentation/Home_Assistant/installation/#issue-unable-to-access-home-assistant-web-interface","title":"Issue: Unable to Access Home Assistant Web Interface","text":"<p>Resolution: Verify the device is connected to the network. Check the IP address assigned to the device and use it to access the interface.</p>"},{"location":"documentation/Home_Assistant/installation/#issue-installation-fails-on-legacy-hardware","title":"Issue: Installation Fails on Legacy Hardware","text":"<p>Resolution: Confirm that the hardware meets the minimum requirements. Check the BIOS settings for compatibility with HAOS.</p>"},{"location":"documentation/Home_Assistant/installation/#issue-installation-fails-to-boot","title":"Issue: Installation Fails to boot","text":"<p>OS 15.x fails to boot on certain SATA drives </p> <p></p> <p>Resolution: Change boot loader after installation. Install HAOS without UEFI</p> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/add-ons/esphome/","title":"ESPHome","text":""},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/","title":"Mosquitto Broker","text":""},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#mosquitto-broker","title":"Mosquitto Broker","text":""},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#installation-and-configuration-of-mosquitto-broker-in-home-assistant","title":"Installation and Configuration of Mosquitto Broker in Home Assistant","text":"<p>Integrate Mosquitto Broker with Home Assistant to enable seamless MQTT communication.</p>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#overview","title":"Overview","text":"<p>Mosquitto is a lightweight MQTT broker that enables IoT devices to communicate efficiently via the MQTT protocol. This guide outlines the installation and configuration process within Home Assistant.</p>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#technical-details","title":"Technical Details","text":"<p>Mosquitto operates as an MQTT broker, facilitating message exchanges between clients. Configuration in Home Assistant includes authentication, topic management, and SSL security settings.</p>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#infobox","title":"Infobox","text":"Feature Description Broker Mosquitto MQTT Broker Protocol MQTT Home Assistant Compatible via MQTT integration Security Supports authentication and SSL encryption"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#steps","title":"Steps","text":""},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#install-mosquitto-broker-add-on","title":"Install Mosquitto Broker Add-on","text":"<ol> <li>Navigate to Home Assistant &gt; Settings &gt; Add-ons.</li> <li>Search for Mosquitto Broker and click Install.</li> <li>Once installed, start the add-on and review the logs for confirmation.</li> </ol>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#configure-mosquitto-in-home-assistant","title":"Configure Mosquitto in Home Assistant","text":"<ol> <li>Enable MQTT integration in Home Assistant.</li> <li>Set up authentication credentials (username/password) in <code>configuration.yaml</code>.</li> <li>Restart Home Assistant for changes to take effect.</li> </ol>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#commands","title":"Commands","text":""},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#verify-mosquitto-installation","title":"Verify Mosquitto Installation","text":"<pre><code>mosquitto -v\n</code></pre>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#test-connection","title":"Test Connection","text":"<pre><code>mosquitto_sub -h localhost -t \"home/assistant\"\nmosquitto_pub -h localhost -t \"home/assistant\" -m \"Hello MQTT\"\n</code></pre>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#examples","title":"Examples","text":""},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#example-mqtt-configuration-in-home-assistant","title":"Example MQTT Configuration in Home Assistant","text":"<pre><code>mqtt:\n  broker: localhost\n  username: homeassistant\n  password: securepassword\n</code></pre>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#resources","title":"Resources","text":"<ul> <li>Mosquitto Official Documentation</li> <li>Home Assistant MQTT Integration</li> </ul>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#issue-mqtt-broker-not-starting","title":"Issue: MQTT Broker Not Starting","text":"<ul> <li>Check logs in Home Assistant &gt; Settings &gt; Add-ons &gt; Mosquitto Broker.</li> <li>Ensure correct credentials are set in <code>configuration.yaml</code>.</li> <li>Restart Home Assistant.</li> </ul>"},{"location":"documentation/Home_Assistant/add-ons/mosquitto_broker/#issue-devices-not-connecting","title":"Issue: Devices Not Connecting","text":"<ul> <li>Validate MQTT topics with <code>mosquitto_sub</code> and <code>mosquitto_pub</code>.</li> <li>Check firewall settings to allow MQTT traffic.</li> </ul> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/","title":"Zigbee2MQTT","text":""},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#zigbee2mqtt","title":"Zigbee2MQTT","text":""},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#installing-zigbee2mqtt-in-home-assistant","title":"Installing Zigbee2MQTT in Home Assistant","text":"<p>A clear and concise guide for setting up Zigbee2MQTT in Home Assistant.</p>"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#overview","title":"Overview","text":"<p>Zigbee2MQTT allows you to connect Zigbee devices with Home Assistant without relying on proprietary hubs. This guide will walk you through the installation and configuration process.</p>"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#technical-details","title":"Technical Details","text":"<p>Zigbee2MQTT requires a Zigbee adapter compatible with the software. Common adapters include: - CC2531 - CC2652 - Sonoff ZBDongle</p> <p>The add-on requires MQTT to function properly, which must be installed and configured in Home Assistant before proceeding.</p>"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#infobox","title":"Infobox","text":"Component Description Zigbee2MQTT Add-on Enables direct communication between Zigbee devices and Home Assistant MQTT Broker Required for Zigbee2MQTT to relay messages Zigbee Coordinator USB adapter to connect Zigbee devices"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#steps","title":"Steps","text":"<ol> <li>Install MQTT Broker: Ensure the MQTT add-on is installed and running.</li> <li>Install Zigbee2MQTT Add-on:</li> <li>Open Home Assistant.</li> <li>Navigate to Settings &gt; Add-ons.</li> <li>Search for Zigbee2MQTT and install it.</li> <li>Configure Zigbee2MQTT:</li> <li>Open the Zigbee2MQTT add-on configuration.</li> <li>Set the MQTT broker details.</li> <li> <p>Define the serial port used by the Zigbee adapter (See Sonoff).</p> <pre><code>port: &gt;-\n  /dev/serial/by-id/usb-Itead_Sonoff_Zigbee_3.0_USB_Dongle_Plus_V2_d2c4d0ccfc73ef119820e21e313510fd-if00-port0\nadapter: ember\n</code></pre> </li> <li> <p>Restart the Add-on: Apply changes and restart Zigbee2MQTT.</p> </li> <li>Pair Devices: Place Zigbee devices in pairing mode and add them to Zigbee2MQTT.</li> </ol>"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#commands","title":"Commands","text":"<pre><code># Check Zigbee2MQTT logs\ndocker logs zigbee2mqtt\n\n# Restart Zigbee2MQTT\ndocker restart zigbee2mqtt\n</code></pre>"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#examples","title":"Examples","text":"<pre><code>mqtt:\n  host: \"mqtt-broker.local\"\n  port: 1883\nzigbee:\n  serial:\n    port: \"/dev/ttyUSB0\"\n</code></pre>"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#resources","title":"Resources","text":"<ul> <li>Official Zigbee2MQTT Documentation</li> <li>Home Assistant Add-ons Guide</li> <li>Installation Zigbee2MQTT on Github</li> </ul>"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#issue-zigbee2mqtt-not-connecting","title":"Issue: Zigbee2MQTT Not Connecting","text":"<ul> <li>Ensure the serial port is correctly set.</li> <li>Verify MQTT broker credentials.</li> </ul>"},{"location":"documentation/Home_Assistant/add-ons/zigbee2mqtt/#issue-devices-not-pairing","title":"Issue: Devices Not Pairing","text":"<ul> <li>Reset the Zigbee device.</li> <li>Bring the device closer to the coordinator.</li> <li>Restart Zigbee2MQTT and attempt pairing again.</li> </ul> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/","title":"Zigbee Map","text":""},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#zigbee-map","title":"Zigbee Map","text":"<p>Visualizing your Zigbee mesh network is essential for understanding device connectivity, diagnosing issues, and optimizing performance. This guide outlines how to use Zigbee Map tools within Home Assistant to generate interactive network graphs.</p>"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#overview","title":"Overview","text":"<p>Zigbee Map is a visualization tool that displays the topology of your Zigbee mesh network. It helps users:</p> <ul> <li>Identify weak signal paths</li> <li>Detect isolated or poorly connected devices</li> <li>Understand routing behavior</li> <li>Improve placement of repeaters and routers</li> </ul>"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#supported-integrations","title":"Supported Integrations","text":"<p>Zigbee Map works with the following Home Assistant integrations:</p> Integration Description Requirements ZHA Native Zigbee integration in Home Assistant No external dependencies Zigbee2MQTT MQTT-based Zigbee integration MQTT broker + Zigbee2MQTT"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#installation","title":"Installation","text":""},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#manual-installation-recommended","title":"Manual Installation (Recommended)","text":"<ol> <li>Download the panel script: zigbee-map-panel.js</li> <li>Place it in the conf/www directory</li> <li>Add the following snippet to your configuration.yaml file:</li> </ol> <pre><code> panel_custom:\n   - name: zigbee-map-panel\n     url_path: zigbee-map\n     module_url: /local/zigbee-map-panel.js\n     sidebar_title: Zigbee Map\n     sidebar_icon: mdi:hub\n</code></pre> 4. Restart Home Assistant 5. The Zigbee Map panel should now appear in your sidebar"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#configuration","title":"Configuration","text":""},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#usage","title":"Usage","text":"<p>Once configured, Zigbee Map will generate a dynamic graph showing:</p> <ul> <li>Nodes (devices)</li> <li>Edges (connections)</li> <li>Signal strength</li> <li>Routing paths</li> </ul>"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#example-screenshot","title":"Example Screenshot","text":""},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#troubleshooting","title":"Troubleshooting","text":"Issue Solution Devices missing from map Ensure they are paired and online Map not loading Check browser console for errors Incorrect routing shown Restart Zigbee coordinator and refresh map"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#resources","title":"Resources","text":"<ul> <li>Zigbee Map Community Thread</li> <li>Zigbee Map Releases</li> <li>ZHA Documentation</li> <li>Zigbee2MQTT Docs</li> </ul>"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#best-practices","title":"Best Practices","text":"<ul> <li>Place routers strategically to improve mesh coverage</li> <li>Avoid physical obstructions between devices</li> <li>Regularly check the map for topology changes</li> <li>Use powered devices as repeaters when possible</li> </ul>"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#contribution","title":"Contribution","text":"<p>Want to improve Zigbee Map?</p> <ol> <li>Fork the repository</li> <li>Submit pull requests</li> <li>Join the discussion on the community thread</li> </ol>"},{"location":"documentation/Home_Assistant/add-ons/zigbee_map/#summary","title":"Summary","text":"<p>Zigbee Map is a powerful tool for smart home enthusiasts using Zigbee devices. Whether you're troubleshooting connectivity or optimizing your mesh layout, this visualization tool offers valuable insights into your network.</p> <p>Ready to map your mesh? Dive in and explore your Zigbee universe!</p> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/assist/commands/","title":"Commands","text":""},{"location":"documentation/Home_Assistant/assist/commands/#commands","title":"Commands","text":""},{"location":"documentation/Home_Assistant/assist/commands/#voice-commands-in-home-assistant","title":"Voice Commands in Home Assistant","text":""},{"location":"documentation/Home_Assistant/assist/commands/#overview","title":"Overview","text":"<p>Home Assistant declared 2023 the Year of the Voice, focusing on making local voice control a first-class citizen in smart home ecosystems. The goal was to bring natural, private, and fully offline voice interactions to Home Assistant, empowering users to control their homes without relying on cloud services.</p>"},{"location":"documentation/Home_Assistant/assist/commands/#technical-details","title":"Technical Details","text":"<p>Home Assistant\u2019s voice capabilities are built around the following key features:</p>"},{"location":"documentation/Home_Assistant/assist/commands/#assist","title":"Assist","text":"<p>A new voice assistant feature introduced in Home Assistant that allows users to give voice commands locally, such as \"Turn on the kitchen lights.\"</p>"},{"location":"documentation/Home_Assistant/assist/commands/#multilingual-support","title":"Multilingual Support","text":"<p>Assist supports multiple languages, including English, Dutch, German, French, and more, expanding accessibility globally.</p>"},{"location":"documentation/Home_Assistant/assist/commands/#wake-word-integration","title":"Wake Word Integration","text":"<p>Home Assistant supports wake word detection using open-source solutions like Porcupine and OpenWakeWord, enabling fully hands-free interactions.</p>"},{"location":"documentation/Home_Assistant/assist/commands/#custom-voice-pipelines","title":"Custom Voice Pipelines","text":"<p>Users can define their own voice pipelines using open-source speech-to-text (STT) and text-to-speech (TTS) engines, such as Whisper and Coqui TTS.</p>"},{"location":"documentation/Home_Assistant/assist/commands/#esphome-integration","title":"ESPHome Integration","text":"<p>Low-cost ESP-based devices (like ESP32s with microphones and speakers) can function as voice satellites throughout the house.</p>"},{"location":"documentation/Home_Assistant/assist/commands/#infobox","title":"Infobox","text":"Feature Description Assist Local voice assistant for smart home control Multilingual Support Supports multiple languages Wake Word Integration Hands-free voice interactions Custom Voice Pipelines Uses open-source STT and TTS engines ESPHome Integration ESP-based voice satellite devices"},{"location":"documentation/Home_Assistant/assist/commands/#steps","title":"Steps","text":"<ol> <li>Install Home Assistant.</li> <li>Enable Assist in the Home Assistant settings.</li> <li>Configure voice pipelines using STT and TTS engines.</li> <li>Install Whisper (listens to you)</li> <li>Install Piper (talks to you)</li> <li>Install Wyoming Protocol</li> <li>Set up wake word detection for hands-free use.</li> <li>Integrate ESPHome-compatible voice satellite devices (See M5Stack Atom Echo).</li> </ol>"},{"location":"documentation/Home_Assistant/assist/commands/#commands_1","title":"Commands","text":""},{"location":"documentation/Home_Assistant/assist/commands/#example-voice-commands","title":"Example Voice Commands","text":"<p>\"Turn off all the lights in the house.\" \"Set the thermostat to 72 degrees.\" \"Is the front door locked?\" \"Start the vacuum cleaner.\" \"Open the garage door.\"</p>"},{"location":"documentation/Home_Assistant/assist/commands/#examples","title":"Examples","text":"<p>Adding a custom sentence to trigger an automation: Adding a custom sentence</p> <p>Customizing responses: Customizing responses</p> <p>Audio: Instead of the build-in speaker of the Atom Echo, you can use your own Media Player as output device. Add the following section into your yaml file, just after the block: on_tts_start: Be sure to use the right indent</p> <p></p><pre><code>  on_tts_end: # Addded for Media Player Output\n    - homeassistant.service:\n        service: media_player.play_media\n        data:\n          entity_id: media_player.msi_b150m\n          media_content_id: !lambda 'return x;'\n          media_content_type: music\n          announce: \"true\" # Last line manual adjustment for Media Player Output\n</code></pre> You also need to configure your device to be able to: Allow the device to perform Home Assistant actions. (last but not least, turn of the volume of the Atom Echo itself)."},{"location":"documentation/Home_Assistant/assist/commands/#resources","title":"Resources","text":"<ul> <li>Home Assistant Official Voice Documentation</li> <li>ESPHome Documentation</li> <li>OpenWakeWord GitHub</li> </ul>"},{"location":"documentation/Home_Assistant/assist/commands/#troubleshooting","title":"Troubleshooting","text":"<p>Failure</p> <p>[12:46:25] INFO: Service exited with code 256 (by signal 4) [12:46:26] WARNING: Your CPU does not support Advanced Vector Extensions (AVX). Whisper will run slower than normal. [12:46:27] INFO: Service exited with code 256 (by signal 4) [12:46:28] WARNING: Your CPU does not support Advanced Vector Extensions (AVX). Whisper will run slower than normal.</p>"},{"location":"documentation/Home_Assistant/assist/commands/#unsupported-cpu","title":"Unsupported CPU","text":"<p>Problem, I can't run Whisper on my HA device due to the fact that my CPU doesn't support AVX.</p> <p>Info</p> <p>The HP Compaq nc6320, equipped with an Intel  Core 2 Duo T5600 processor, does not support AVX (Advanced Vector Extensions). AVX was introduced with Intel's Sandy Bridge microarchitecture in 2011, whereas the T5600, based on the older Merom architecture, lacks this instruction set. If you require AVX support for specific applications, you'll need to consider upgrading to a more recent system with a compatible processor.</p> <p>Solution Solved that problem by hosting the Whisper function on another server in my network (see Whisper on Server).</p>"},{"location":"documentation/Home_Assistant/assist/commands/#issue-wake-word-not-detected","title":"Issue: Wake word not detected","text":"<p>Solution: Ensure wake word detection is enabled and microphone sensitivity is correctly configured.</p>"},{"location":"documentation/Home_Assistant/assist/commands/#issue-incorrect-voice-command-execution","title":"Issue: Incorrect voice command execution","text":"<p>Solution: Verify command sentences and adjust custom pipelines if necessary.</p> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/assist/setup/","title":"Setup","text":""},{"location":"documentation/Home_Assistant/assist/setup/#setup","title":"Setup","text":""},{"location":"documentation/Home_Assistant/assist/setup/#setting-up-assist-local","title":"Setting Up Assist Local","text":"<p>Enable voice assistant functionality in Home Assistant with local processing for privacy and performance.</p>"},{"location":"documentation/Home_Assistant/assist/setup/#overview","title":"Overview","text":"<p>This guide explains how to set up Assist Local in Home Assistant to use voice commands without relying on cloud services. It covers installation, configuration, and troubleshooting.</p>"},{"location":"documentation/Home_Assistant/assist/setup/#technical-details","title":"Technical Details","text":"<p>Assist Local uses Whisper for speech recognition and Piper for text-to-speech. These tools run locally, ensuring privacy and reducing latency. You can also configure a custom media player for audio output.</p>"},{"location":"documentation/Home_Assistant/assist/setup/#infobox","title":"Infobox","text":"<ul> <li>Speech Recognition: Whisper  </li> <li>Text-to-Speech: Piper  </li> <li>Custom Output: Media Player (optional)  </li> <li>Use Case: Local voice assistant for Home Assistant.</li> </ul>"},{"location":"documentation/Home_Assistant/assist/setup/#steps","title":"Steps","text":"<ol> <li>Install Whisper:</li> <li> <p>Whisper is used for speech recognition. If your device does not support AVX, you can host Whisper on another server in your network. See Whisper on Server for details.</p> </li> <li> <p>Install Piper:</p> </li> <li> <p>Piper handles text-to-speech functionality. Install it on your Home Assistant instance.</p> </li> <li> <p>Configure Media Player Output (optional):</p> </li> <li> <p>Add the following configuration to your YAML file to use a custom media player for audio output:</p> <p></p><pre><code>on_tts_end: # Added for Media Player Output\n  - homeassistant.service:\n      service: media_player.play_media\n      data:\n        entity_id: media_player.msi_b150m\n        media_content_id: !lambda 'return x;'\n        media_content_type: music\n        announce: \"true\" # Last line manual adjustment for Media Player Output\n</code></pre>    - Ensure the Atom Echo's volume is turned off if using an external media player. </li> <li> <p>Restart Home Assistant:</p> </li> <li>Apply the changes by restarting Home Assistant.</li> </ol>"},{"location":"documentation/Home_Assistant/assist/setup/#commands","title":"Commands","text":"<ul> <li>Restart Home Assistant:</li> </ul> <pre><code>ha core restart\n</code></pre> <ul> <li>Check Configuration:</li> </ul> <pre><code>ha core check\n</code></pre>"},{"location":"documentation/Home_Assistant/assist/setup/#examples","title":"Examples","text":"<ul> <li>$13 voice assistant for Home Assistant</li> <li>Home Assistant Pipeline</li> </ul>"},{"location":"documentation/Home_Assistant/assist/setup/#resources","title":"Resources","text":"<ul> <li>Wyoming</li> <li>m5stack-atom-echo.yaml</li> <li>Getting started - Local Assist</li> </ul>"},{"location":"documentation/Home_Assistant/assist/setup/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Issue: Audio output is not working. Resolution: Verify the media player configuration and ensure the Atom Echo's volume is turned off.</li> <li>Issue: Your CPU does not support AVX. Resolution: Use a version of Whisper compiled without AVX or host Whisper on a compatible server.  </li> </ul> <p>See also:  </p> <ul> <li>Service exited with code 256 (by signal 4) on x86_64</li> </ul> <p>Question</p> <p>Is Speech-to-Phrase a possibility to use instead of Whisper</p> <ul> <li>Getting started - Local</li> </ul> <p>Danger</p> <p></p> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/assist/whisper/","title":"Whisper","text":""},{"location":"documentation/Home_Assistant/assist/whisper/#whisper","title":"Whisper","text":""},{"location":"documentation/Home_Assistant/assist/whisper/#overview","title":"Overview","text":"<p>Whisper + Wyoming Installation Guide (Windows Server)</p> <p>This guide helps you install OpenAI Whisper and Wyoming-Whisper on a Windows Server so you can offload transcription for Home Assistant device or in my case if your CPU doesn't support AVX.</p>"},{"location":"documentation/Home_Assistant/assist/whisper/#technical-details","title":"Technical Details","text":"<ul> <li>Windows Server or Windows 10/11</li> <li>Python 3.8+ (installed from https://www.python.org/)</li> <li>Admin rights on the machine</li> </ul>"},{"location":"documentation/Home_Assistant/assist/whisper/#infobox","title":"Infobox","text":"<p>Succes</p> <p>Succesfully tested on Windows Server 2025.</p>"},{"location":"documentation/Home_Assistant/assist/whisper/#steps","title":"Steps","text":"<ol> <li>Use Correct Python    Verify Python is installed:</li> </ol> <pre><code>where python\n</code></pre> <p>If the first result is something like:  </p> <p>C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python3xx\\python.exe  </p> <p>You\u2019re good. If you see msys64 or Git\\usr\\bin, reinstall Python from python.org and check \"Add to PATH\" during installation.</p> <ol> <li>Create and Activate Virtual Environment    Use the correct Python path explicitly:</li> </ol> <pre><code>\"C:\\Program Files\\Python\\Python313\\python.exe\" -m venv whisper_env  \n</code></pre> <pre><code>whisper_env\\Scripts\\activate\n</code></pre> <p>You should now see your prompt change to:</p> <p>(whisper_env) C:\\Users\\Administrator&gt;</p> <ol> <li>Install Whisper and Torch    Install Whisper and PyTorch (use CPU if no GPU available):</li> </ol> <pre><code>pip install git+https://github.com/openai/whisper.git\n</code></pre> <pre><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n</code></pre> <p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD    You can replace cpu with cu118 for CUDA 11.8 if you have a compatible NVIDIA GPU. =======     You can replace cpu with cu118 for CUDA 11.8 if you have a compatible NVIDIA GPU.</p> <p>803483de19e089041654b9596233bb7b0444ac00</p> <ol> <li>Install and Run Wyoming-Whisper    Clone and install Wyoming-Whisper:</li> </ol> <pre><code>git clone https://github.com/rhasspy/wyoming-faster-whisper.git\n</code></pre> <pre><code>cd wyoming-faster-whisper\n</code></pre> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Start Whispwer with:</p> <pre><code>python -m wyoming_faster_whisper --model tiny-int8 --language en --uri tcp://0.0.0.0:10300 --data-dir .\\data --download-dir .\\data\n</code></pre> <p>This starts the Wyoming server on port 10300. You can change the model if you like.</p> <ol> <li>Connect to Home Assistant    In Home Assistant:</li> </ol> <p>In Home Assistant: Configure Wyoming Integration    Go to Home Assistant UI.    Go to Settings &gt; Devices &amp; Services &gt; Add Integration    Search for Wyoming    Host: The local IP address of your Windows Server (e.g., 192.168.1.100)    Port: 10300 (or whatever port Wyoming-Whisper is using)    Click Submit.  </p> <p>Use services.yaml (if manual setup is needed) If you want to manually define the Wyoming STT (Speech-to-Text) service in your config files:</p> <pre><code>stt:\n  - platform: wyoming\n    name: Whisper STT\n    host: 192.168.1.100  # Your Windows Server IP\n    port: 10300\n</code></pre> <p>After editing the config, restart Home Assistant. Change the Speech-to-text option in the Home Assistant &gt; Voice Assistants settings to [faster-whisper]</p> <ol> <li>(Optional): Test Whisper Locally    Try running a quick transcription:</li> </ol> <pre><code>whisper example.wav --model small\n</code></pre> <p>Auto-Start (Optional) Create a .bat file with run command (nog aanpassen):</p> <pre><code>@echo off\nREM Set working directory to where this .bat file is located\ncd /d %~dp0\n\necho INFO:__open__\nREM Activate the virtual environment\ncall whisper_env\\Scripts\\activate.bat\n\nREM Change to wyoming-faster-whisper directory\ncd wyoming-faster-whisper\n\nREM Start the Wyoming Faster Whisper server using venv Python\npython -m wyoming_faster_whisper ^\n  --model tiny-int8 ^\n  --language en ^\n  --uri tcp://0.0.0.0:10300 ^\n  --data-dir .\\data ^\n  --download-dir .\\data\n\npause\n</code></pre> <p>Place this in Startup or use Task Scheduler to auto-start at boot.</p>"},{"location":"documentation/Home_Assistant/assist/whisper/#youre-done","title":"You're Done!","text":"<p>Whisper is now offloaded from your Home Assistant device to your more powerful Windows Server.</p>"},{"location":"documentation/Home_Assistant/assist/whisper/#new-pip","title":"New pip:","text":"<p>To update, run:</p> <pre><code>python.exe -m pip install --upgrade pip\n</code></pre>"},{"location":"documentation/Home_Assistant/assist/whisper/#firewall-settings","title":"Firewall Settings","text":"<p>Run this in an elevated CMD to allow Home Assistant to reach port 10300:</p> <pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nnetsh advfirewall firewall add rule name=\"Whisper Wyoming\" dir=in action=allow protocol=TCP localport=10300 profile=private,domain\n\n=======\nnetsh advfirewall firewall add rule name=\"Whisper Wyoming\" dir=in action=allow protocol=TCP localport=10300\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; 803483de19e089041654b9596233bb7b0444ac00\n</code></pre>"},{"location":"documentation/Home_Assistant/assist/whisper/#commands","title":"Commands","text":"<pre><code>@echo off\necho -----------------------------------\necho   Updating Wyoming Faster Whisper \necho -----------------------------------\n\nREM Navigate to base folder\ncd /d %~dp0\n\nREM Activate the virtual environment\ncall whisper_env\\Scripts\\activate.bat\n\nREM Upgrade pip\necho Upgrading pip...\npython -m pip install --upgrade pip\n\nREM Go into the wyoming-faster-whisper directory\ncd wyoming-faster-whisper\n\nREM Pull latest code (safe if not modified)\necho Pulling latest Wyoming Faster Whisper code...\ngit pull\n\nREM Upgrade all dependencies\necho Upgrading Python dependencies...\npip install --upgrade -r requirements.txt\n\necho Update complete!\npause\n</code></pre>"},{"location":"documentation/Home_Assistant/assist/whisper/#examples","title":"Examples","text":"<pre><code>Code snippets, commands, or use cases.\n</code></pre>"},{"location":"documentation/Home_Assistant/assist/whisper/#resources","title":"Resources","text":"<pre><code>Links to related articles, external documentation, or downloadable tools.\n</code></pre>"},{"location":"documentation/Home_Assistant/assist/whisper/#troubleshooting","title":"Troubleshooting","text":"<pre><code>Issues and resolutions.\n</code></pre> <p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p>"},{"location":"documentation/Home_Assistant/assist/whisper/#choices","title":"Choices","text":"<p>And to make it even more complex: See my Docker CE adventure Plan is to run Whisper from a Docker Container</p> <p>=======</p> <p>803483de19e089041654b9596233bb7b0444ac00</p> <p>Generated using AI </p>"},{"location":"documentation/Home_Assistant/dashboards/cards/custom/button-card/","title":"Button card","text":"<p>bar</p> <pre><code>type: custom:button-card\nentity: sensor.home_assistant_host_disk_used\nname: STORAGE USED\nshow_icon: false\nshow_state: true\ntab_action:\n  action: more-info\nstyles:\n  card:\n    - height: 80px\n    - padding: 0px\n    - border-radius: 10px\n    - border: 1px solid\n    - border-color: \"#888888\"\n    - background: |\n        [[[\n          let value = (entity.state);\n          if (value &lt; 60) return 'linear-gradient(to right, #43A047 ' + value + '%, #434954 ' + value + '%)';\n          if (value &lt; 85) return 'linear-gradient(to right, #FFA600 ' + value + '%, #434954 ' + value + '%)';          \n          return 'linear-gradient(to right, #DB4437 ' + value + '%, #434954 ' + value + '%)';\n        ]]]\n  name:\n    - justify-self: start\n    - padding-left: 30px\n    - font-size: 14px\n    - color: white\n  state:\n    - justify-self: start\n    - padding-left: 30px\n    - font-size: 14px\n    - color: white\n</code></pre>"},{"location":"documentation/Home_Assistant/hardware/homewizard/","title":"HomeWizard","text":""},{"location":"documentation/Home_Assistant/hardware/homewizard/#homewizard","title":"HomeWizard","text":""},{"location":"documentation/Home_Assistant/hardware/homewizard/#homewizard-p1-meter-installation-and-integration-with-home-assistant","title":"HomeWizard P1 Meter Installation and Integration with Home Assistant","text":""},{"location":"documentation/Home_Assistant/hardware/homewizard/#overview","title":"Overview","text":"<p>This guide details the installation and configuration of the HomeWizard P1 meter within Home Assistant, ensuring seamless integration for real-time energy monitoring.</p>"},{"location":"documentation/Home_Assistant/hardware/homewizard/#technical-details","title":"Technical Details","text":"<p>HomeWizard P1 meter connects via Wi-Fi to provide smart energy readings. Integration with Home Assistant allows automated control and analytics. Recommended setup includes: - HomeWizard P1 meter - Home Assistant running on Raspberry Pi or similar - Wi-Fi connectivity</p>"},{"location":"documentation/Home_Assistant/hardware/homewizard/#infobox","title":"Infobox","text":"Feature Description Compatibility Works with Home Assistant (via API) Connectivity Wi-Fi enabled Power Supply USB-powered Data Refresh Real-time energy monitoring"},{"location":"documentation/Home_Assistant/hardware/homewizard/#steps","title":"Steps","text":""},{"location":"documentation/Home_Assistant/hardware/homewizard/#1-install-homewizard-p1-meter","title":"1. Install HomeWizard P1 Meter","text":"<ul> <li>Connect HomeWizard P1 meter to the P1 port of the energy meter.</li> <li>Power the device using USB adapter.</li> <li>Ensure proper Wi-Fi connection.</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/homewizard/#2-configure-home-assistant","title":"2. Configure Home Assistant","text":"<ul> <li>Navigate to Settings &gt; Integrations in Home Assistant.</li> <li>Search for HomeWizard Energy and install the integration.</li> <li>Enter the local IP address of the P1 meter.</li> <li>Save and restart Home Assistant.</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/homewizard/#3-validate-data-flow","title":"3. Validate Data Flow","text":"<ul> <li>Navigate to Developer Tools &gt; States and confirm sensor data visibility.</li> <li>Add P1 meter entities to Home Assistant dashboard.</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/homewizard/#commands","title":"Commands","text":"<pre><code>sensor:\n  - platform: homewizard\n    host: \"192.168.x.x\"\n    monitored_conditions:\n      - total_power\n      - voltage\n</code></pre>"},{"location":"documentation/Home_Assistant/hardware/homewizard/#examples","title":"Examples","text":""},{"location":"documentation/Home_Assistant/hardware/homewizard/#example-automation","title":"Example Automation","text":"<pre><code>automation:\n  - alias: Notify on Power Spike\n    trigger:\n      - platform: numeric_state\n        entity_id: sensor.homewizard_power\n        above: 3000\n    action:\n      - service: notify.mobile_app\n        data:\n          message: \"Power consumption is unusually high!\"\n</code></pre>"},{"location":"documentation/Home_Assistant/hardware/homewizard/#resources","title":"Resources","text":"<ul> <li>HomeWizard P1 Meter</li> <li>HomeWizard P1 API Documentation</li> <li>Home Assistant Integration Guide</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/homewizard/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/Home_Assistant/hardware/homewizard/#issue-data-not-appearing-in-home-assistant","title":"Issue: Data Not Appearing in Home Assistant","text":"<p>Solution: Ensure the IP address is correct and check network connectivity.</p>"},{"location":"documentation/Home_Assistant/hardware/homewizard/#issue-integration-fails","title":"Issue: Integration Fails","text":"<p>Solution: Restart Home Assistant and reinstall the HomeWizard integration.</p> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/hardware/m5stack/","title":"M5Stack","text":""},{"location":"documentation/Home_Assistant/hardware/m5stack/#m5stack","title":"M5Stack","text":""},{"location":"documentation/Home_Assistant/hardware/m5stack/#flashing-and-installing-the-m5stack-atom-echo","title":"Flashing and Installing the M5Stack Atom Echo","text":""},{"location":"documentation/Home_Assistant/hardware/m5stack/#overview","title":"Overview","text":"<p>The ATOM ECHO Smart Speaker Development Kit is a Programmable Smart Speaker based on the M5ATOM design. With its compact form factor measuring only 24 * 24 * 17 mm, this speaker delivers impressive capabilities. Easily play music wirelessly using the BT capabilities of the ESP32 from your mobile phone or tablet. What sets ATOM ECHO apart is its programmability and integration with cloud platforms such as AWS and Baidu. Utilizing the built-in microphone and speaker, it enables voice interaction and AI functionality. Experience voice control, story-telling, and seamless integration with the Internet of Things (IoT). The speaker is equipped with an embedded RGB LED (SK6812), allowing for visual display of connection status. Beyond its role as a Bluetooth speaker, ATOM ECHO retains the control abilities of the Atom series. The convenient screw hole on the back facilitates easy installation for users. With ATOM ECHO, you have a powerful, programmable smart speaker that combines compact design, AI capabilities, and seamless IoT integration for an enhanced audio experience in any setting. </p>"},{"location":"documentation/Home_Assistant/hardware/m5stack/#technical-details","title":"Technical Details","text":"Resources Parameter SoC ESP-PICO-D4, 240MHz, Dual Core, Wi-Fi Flash 4MB Interface 1x IR-TX,1x Function Button,1x Reset Button PinOut G21/G25/5V/GND, 3V3/G22/G19/G23/G33 RGB LED SK6812 Speaker 0.5W/NS4168 I2S Microphone SPM1423 PDM Net weight 5g Gross weight 10g Product Size 242417mm Package Size 636312mm Case Material Plastic ( PC )"},{"location":"documentation/Home_Assistant/hardware/m5stack/#steps","title":"Steps","text":"<ol> <li>Install ESPHome</li> <li>Connect Atom Echo (use the right USB-C Cord)</li> <li>Enter Network credentials</li> <li>Skip installation (do not create config on device at this stage)</li> <li>Select ESP32</li> <li>Store created Encryption Key</li> <li>SKIP</li> <li>Replace content atom-echo.yaml</li> </ol> <p>Warning</p> <p>NOT THE ENCRYPTION KEY</p> atom-echo.yaml<pre><code>esphome:\n  name: atom-echo\n  friendly_name: Atom Echo\n\ni2s_audio:\n  i2s_lrclk_pin: GPIO33\n  i2s_bclk_pin: GPIO19\n\nesp32:\n  board: m5stack-atom\n  framework:\n    type: arduino\n\nlogger:\napi:\n  encryption: \n    key: {use the key generated automatically}\nota:\n\nwifi:\n  ssid: !secret wifi_ssid\n  password: !secret wifi_password\n\n  # Enable fallback hotspot (captive portal) in case wifi connection fails\n  ap:\n    ssid: \"Atom-Echo Fallback Hotspot\"\n    password: \"somepassword\"\n\ncaptive_portal:\n\nimprov_serial:\n\nmicrophone:\n  - platform: i2s_audio\n    id: atom_echo_microphone\n    adc_type: external\n    i2s_din_pin: GPIO23\n    pdm: true\n\nvoice_assistant:\n  microphone: atom_echo_microphone\n  on_start:\n    - light.turn_on:\n        id: led\n        blue: 100%\n        red: 0%\n        green: 0%\n        effect: none\n  on_tts_start:\n    - light.turn_on:\n        id: led\n        blue: 0%\n        red: 0%\n        green: 100%\n        effect: none\n  on_tts_end:\n    - media_player.play_media: !lambda return x;\n    - light.turn_on:\n        id: led\n        blue: 0%\n        red: 0%\n        green: 100%\n        effect: pulse\n  on_end:\n    - delay: 1s\n    - wait_until:\n        not:\n          media_player.is_playing: media_out\n    - light.turn_off: led\n  on_error:\n    - light.turn_on:\n        id: led\n        blue: 0%\n        red: 100%\n        green: 0%\n        effect: none\n    - delay: 1s\n    - light.turn_off: led\n\nbinary_sensor:\n  - platform: gpio\n    pin:\n      number: GPIO39\n      inverted: true\n    name: Button\n    id: echo_button\n    on_multi_click:\n      - timing:\n          - ON FOR AT MOST 350ms\n          - OFF FOR AT LEAST 10ms\n        then:\n          - media_player.toggle: media_out\n      - timing:\n          - ON FOR AT LEAST 350ms\n        then:\n          - voice_assistant.start:\n      - timing:\n          - ON FOR AT LEAST 350ms\n          - OFF FOR AT LEAST 10ms\n        then:\n          - voice_assistant.stop:\n\nmedia_player:\n  - platform: i2s_audio\n    id: media_out\n    name: None\n    dac_type: external\n    i2s_dout_pin: GPIO22\n    mode: mono\n\nlight:\n  - platform: esp32_rmt_led_strip\n    id: led\n    name: None\n    pin: GPIO27\n    default_transition_length: 0s\n    chipset: SK6812\n    num_leds: 1\n    rgb_order: grb\n    rmt_channel: 0\n    effects:\n      - pulse:\n          transition_length: 250ms\n          update_interval: 250ms\n</code></pre> <ol> <li>Make use of I2S Audio Microphone</li> <li>Save atom-echo.yaml</li> <li>Validate</li> <li>INSTALL</li> <li>Plug into this computer (the one with the browser on it)</li> <li>Select the right USB and Connect</li> <li>Wait for a couple of minutes .....</li> <li>Configuration Installed!</li> <li>Settings &gt; Devices &gt; .....</li> </ol>"},{"location":"documentation/Home_Assistant/hardware/m5stack/#commands","title":"Commands","text":"<p>INFO ESPHome 2025.4.1 INFO Reading configuration /config/esphome/atom-echo.yaml... INFO Starting log output from 192.168.0.106 using esphome API INFO Successfully connected to atom-echo @ 192.168.0.106 in 0.254s INFO Successful handshake with atom-echo @ 192.168.0.106 in 0.096s [13:17:14][I][app:100]: ESPHome version 2025.4.1 compiled on Apr 29 2025, 12:02:10</p>"},{"location":"documentation/Home_Assistant/hardware/m5stack/#examples","title":"Examples","text":"<ul> <li>LOCAL VOICE CONTROL of Home Assistant with the M5Stack Atom Echo</li> <li>media-players/m5stack/m5stack-atom-echo.yaml</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/m5stack/#resources","title":"Resources","text":"<ul> <li>M5STACK ATOM ECHO Smart Speaker Development Kit</li> <li>Wyoming Protocol</li> <li>Ready-Made Projects \u2014 ESPHome</li> <li>home-assistant/esphome-firmware</li> <li>fortuna/m5stack-atom-echo.yaml</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/m5stack/#troubleshooting","title":"Troubleshooting","text":"<p>Failure</p> <p>INFO ESPHome 2025.4.1 INFO Reading configuration /config/esphome/atom-echo.yaml... Failed config  </p> <pre><code>binary_sensor.gpio: [source /config/esphome/atom-echo.yaml:87]  \n  platform: gpio  \n  pin:   \n    number: GPIO39  \n    inverted: True  \n  name: Button  \n  id: echo_button  \n  on_multi_click:   \n    - timing:   \n        - ON FOR AT MOST 350ms  \n        - OFF FOR AT LEAST 10ms  \n      then:   \n        -   \n          expected a dictionary.\n\n          media_player.toggle: media_out  \n    - timing:   \n        - ON FOR AT LEAST 350ms  \n        then:  \n          - voice_assistant.start:  \n      - timing:  \n          - ON FOR AT LEAST 350ms  \n          - OFF FOR AT LEAST 10ms  \n        then:  \n          - voice_assistant.stop:  \n</code></pre> <p>Correct: see id media-out</p> <pre><code>binary_sensor:  \n  - platform: gpio  \n    pin:  \n      number: GPIO39  \n      inverted: true  \n    name: Button  \n    id: echo_button  \n    on_multi_click:  \n      - timing:  \n          - ON FOR AT MOST 350ms  \n          - OFF FOR AT LEAST 10ms  \n        then:  \n          - media_player.toggle:  \n              id: media_out  \n      - timing:  \n          - ON FOR AT LEAST 350ms  \n        then:  \n          - voice_assistant.start:  \n      - timing:  \n          - ON FOR AT LEAST 350ms  \n          - OFF FOR AT LEAST 10ms  \n        then:  \n          - voice_assistant.stop:  \n</code></pre> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/hardware/sonoff/","title":"Sonoff","text":""},{"location":"documentation/Home_Assistant/hardware/sonoff/#sonoff","title":"Sonoff","text":""},{"location":"documentation/Home_Assistant/hardware/sonoff/#how-to-flash-sonoff-zigbee-30-usb-dongle-plus-e-v2-to-ember","title":"How to Flash Sonoff Zigbee 3.0 USB Dongle Plus-E V2 to Ember","text":""},{"location":"documentation/Home_Assistant/hardware/sonoff/#sub-title","title":"Sub-title","text":"<p>Learn how to flash the Sonoff Zigbee 3.0 USB Dongle Plus-E V2 with Ember firmware and integrate it into your smart home setup.</p>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#overview","title":"Overview","text":"<p>This guide provides detailed instructions for flashing the Sonoff Zigbee 3.0 USB Dongle Plus-E V2 with Ember firmware. The process includes downloading the necessary tools, preparing the hardware, and integrating the dongle with Home Assistant.</p>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#technical-details","title":"Technical Details","text":"<p>The Sonoff Zigbee 3.0 USB Dongle Plus-E V2 is a versatile Zigbee coordinator based on the Silicon Labs EFR32MG21 chip. Flashing it with Ember firmware enhances compatibility with Zigbee2MQTT and ZHA (Zigbee Home Automation).</p>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#requirements","title":"Requirements:","text":"<ul> <li>Hardware: Sonoff Zigbee 3.0 USB Dongle Plus-E V2, USB extension cable (optional)</li> <li>Software: Ember firmware, Zigbee Firmware Flasher tool</li> <li>System: Windows, macOS, or Linux</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#infobox","title":"Infobox","text":"Feature Details Device Sonoff Zigbee 3.0 USB Dongle Plus-E V2 Firmware Ember Integration Home Assistant, Zigbee2MQTT Tools Required Zigbee Firmware Flasher, Terminal"},{"location":"documentation/Home_Assistant/hardware/sonoff/#steps","title":"Steps","text":"<ol> <li>Download Firmware and Tools:</li> <li>Visit the Zigbee Firmware Repository to download the Ember firmware and flashing tool.</li> <li> <p>Install any required USB drivers.</p> </li> <li> <p>Prepare the USB Dongle:</p> </li> <li>Connect the dongle to your computer.</li> <li> <p>Verify the device is recognized (e.g., check Device Manager on Windows).</p> </li> <li> <p>Flash the Firmware:</p> </li> <li>Open a terminal and navigate to the flashing tool directory.</li> <li>Run the flashing command:      <pre><code>python3 flash.py --port &lt;COM_PORT&gt; --firmware &lt;FIRMWARE_FILE&gt;\n</code></pre></li> <li> <p>Replace <code>&lt;COM_PORT&gt;</code> and <code>&lt;FIRMWARE_FILE&gt;</code> with appropriate values.</p> </li> <li> <p>Verify the Flash:</p> </li> <li> <p>Reconnect the dongle and verify the firmware version:      </p><pre><code>python3 flash.py --port &lt;COM_PORT&gt; --verify\n</code></pre> </li> <li> <p>Integrate with Home Assistant:</p> </li> <li>Plug the dongle into the Home Assistant device.</li> <li>Add the ZHA integration and configure the serial port.</li> </ol>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#commands","title":"Commands","text":""},{"location":"documentation/Home_Assistant/hardware/sonoff/#flashing-command","title":"Flashing Command","text":"<pre><code>python3 flash.py --port &lt;COM_PORT&gt; --firmware &lt;FIRMWARE_FILE&gt;\n</code></pre>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#verification-command","title":"Verification Command","text":"<pre><code>python3 flash.py --port &lt;COM_PORT&gt; --verify\n</code></pre>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#examples","title":"Examples","text":""},{"location":"documentation/Home_Assistant/hardware/sonoff/#example-flashing-on-windows","title":"Example: Flashing on Windows","text":"<pre><code>python3 flash.py --port COM3 --firmware ember_firmware.bin\n</code></pre>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#example-flashing-on-linux","title":"Example: Flashing on Linux","text":"<pre><code>python3 flash.py --port /dev/ttyUSB0 --firmware ember_firmware.bin\n</code></pre>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#another-approach","title":"Another approach","text":"<ul> <li>How To Update the Sonoff Dongle E to Ember firmware</li> </ul> <p>Configuration in Home Assistant: </p><pre><code>    port: &gt;-\n      /dev/serial/by-id/usb-Itead_Sonoff_Zigbee_3.0_USB_Dongle_Plus_V2_d2c4d0ccfc73ef119820e21e313510fd-if00-port0\n    adapter: ember\n</code></pre>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#resources","title":"Resources","text":"<ul> <li>Sonoff Zigbee 3.0 USB Dongle Documentation</li> <li>Zigbee2MQTT Setup Guide</li> <li>Home Assistant ZHA Integration</li> <li>Sonoff Zigbee 3.0 USB Dongle Plus-E V2</li> <li>Sonoff Zigbee 3.0 USB Dongle Firmware Download</li> <li>Sonoff Zigbee 3.0 USB Dongle Firmware Flasher</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/Home_Assistant/hardware/sonoff/#issue-device-not-recognized","title":"Issue: Device Not Recognized","text":"<ul> <li>Ensure drivers are installed.</li> <li>Try a different USB port or cable.</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#issue-flashing-fails","title":"Issue: Flashing Fails","text":"<ul> <li>Double-check the COM port and firmware file path.</li> <li>Ensure no other applications are using the dongle.</li> </ul>"},{"location":"documentation/Home_Assistant/hardware/sonoff/#issue-zigbee-devices-not-pairing","title":"Issue: Zigbee Devices Not Pairing","text":"<ul> <li>Verify Zigbee channel settings.</li> <li>Reset and re-pair devices.</li> </ul> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/integrations/esphome/","title":"ESPHome","text":""},{"location":"documentation/Home_Assistant/integrations/esphome/#esphome","title":"ESPHome","text":""},{"location":"documentation/Home_Assistant/integrations/esphome/#esphome-installation-and-configuration","title":"ESPHome Installation and Configuration","text":"<p>ESPHome allows seamless integration of ESP-based microcontrollers into Home Assistant.</p>"},{"location":"documentation/Home_Assistant/integrations/esphome/#overview","title":"Overview","text":"<p>ESPHome is a powerful tool for managing smart home devices. It provides a simple YAML-based configuration for ESP8266 and ESP32 boards, making IoT automation effortless.</p>"},{"location":"documentation/Home_Assistant/integrations/esphome/#technical-details","title":"Technical Details","text":"<p>ESPHome supports various ESP-based microcontrollers and communication protocols. It integrates tightly with Home Assistant through the API or MQTT.</p>"},{"location":"documentation/Home_Assistant/integrations/esphome/#infobox","title":"Infobox","text":"Feature Description Supported Boards ESP8266, ESP32 Integration Methods Native API, MQTT Configuration YAML-based"},{"location":"documentation/Home_Assistant/integrations/esphome/#steps","title":"Steps","text":"<ol> <li>Install ESPHome using pip:    <pre><code>pip install esphome\n</code></pre></li> <li>Add ESPHome as an integration in Home Assistant.</li> <li>Configure ESP devices using YAML files.</li> </ol>"},{"location":"documentation/Home_Assistant/integrations/esphome/#commands","title":"Commands","text":"<p>Example commands for flashing firmware:    </p><pre><code>esphome run my_device.yaml\n</code></pre> <pre><code>esphome upload my_device.yaml --port /dev/ttyUSB0\n</code></pre>"},{"location":"documentation/Home_Assistant/integrations/esphome/#examples","title":"Examples","text":"<p>Example YAML configuration for ESPHome:    </p><pre><code>esphome:\n  name: my_device\n  platform: ESP8266\n  board: nodemcu\n</code></pre> <pre><code>wifi:\n  ssid: \"my_wifi\"\n  password: \"super_secret\"\n</code></pre>"},{"location":"documentation/Home_Assistant/integrations/esphome/#resources","title":"Resources","text":"<ul> <li>ESPHome Documentation</li> <li>Home Assistant ESPHome Guide</li> </ul>"},{"location":"documentation/Home_Assistant/integrations/esphome/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and resolutions: <code>`` | Issue              | Solution                            | | ------------------ | ----------------------------------- | | Connection failure | Verify Wi-Fi credentials            | | Flashing errors    | Check USB cable and port            | | YAML validation    | Run</code>esphome config my_device.yaml` |</p> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/","title":"HASS Agent","text":""},{"location":"documentation/Home_Assistant/integrations/hass_agent/#hass-agent","title":"HASS Agent","text":""},{"location":"documentation/Home_Assistant/integrations/hass_agent/#hass-agent-integration-with-home-assistant","title":"HASS Agent Integration with Home Assistant","text":"<p>A clear and concise guide on installing and configuring HASS Agent.</p>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#overview","title":"Overview","text":"<p>HASS Agent is a lightweight Windows-based tool designed for seamless integration with Home Assistant. This guide walks you through installing, configuring, and troubleshooting HASS Agent, ensuring smooth connectivity with your Home Assistant setup.</p>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#technical-details","title":"Technical Details","text":"<p>HASS Agent provides essential features like MQTT-based device integration, Windows sensor monitoring, and automation capabilities with Home Assistant.</p> <p>Configuration Details </p><pre><code>mqtt:\n  host: \"your_home_assistant_ip\"\n  port: 1883\n  username: \"mqtt_user\"\n  password: \"mqtt_password\"\n</code></pre>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#infobox","title":"Infobox","text":"<ul> <li>Tool Name: HASS Agent</li> <li>Platform: Windows</li> <li>Integration Type: MQTT, Commands, Sensors</li> <li>Official Repository: HASS Agent GitHub</li> </ul>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#steps","title":"Steps","text":""},{"location":"documentation/Home_Assistant/integrations/hass_agent/#1-install-hass-agent","title":"1. Install HASS Agent","text":"<ol> <li>Download the latest version from the HASS Agent Releases.</li> <li>Run the installer and follow the instructions.</li> <li>Once installed, launch HASS Agent.</li> </ol>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#2-configure-mqtt","title":"2. Configure MQTT","text":"<ol> <li>Open HASS Agent and navigate to the MQTT configuration section.</li> <li>Enter your Home Assistant IP, username, and password.</li> <li>Save the settings and test the connection.</li> </ol>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#3-enable-windows-sensors","title":"3. Enable Windows Sensors","text":"<ol> <li>Go to the Sensors tab in HASS Agent.</li> <li>Enable relevant sensors (e.g., CPU, RAM usage).</li> <li>Save and sync with Home Assistant.</li> </ol>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#commands","title":"Commands","text":"<p>Configure custom commands within HASS Agent to execute Windows-specific actions. </p><pre><code>commands:\n  - name: \"Shutdown PC\"\n    type: \"shell\"\n    command: \"shutdown /s /t 0\"\n</code></pre>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#examples","title":"Examples","text":"<p>Here\u2019s how to define an automation in Home Assistant to trigger HASS Agent commands. </p><pre><code>automation:\n  alias: \"Shutdown Windows PC\"\n  trigger:\n    - platform: state\n      entity_id: binary_sensor.shutdown_trigger\n      to: \"on\"\n  action:\n    - service: mqtt.publish\n      data:\n        topic: \"hass-agent/commands/shutdown_pc\"\n        payload: \"execute\"\n</code></pre>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#resources","title":"Resources","text":"<ul> <li>Home Assistant MQTT Documentation</li> <li>HASS Agent Wiki</li> <li>Community Forum</li> <li>HASS Agent Documentation</li> <li>System Bridge</li> <li>HASS Agent Setup</li> <li>Control your Windows PC with Home Assistant</li> </ul>"},{"location":"documentation/Home_Assistant/integrations/hass_agent/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/Home_Assistant/integrations/hass_agent/#common-issues","title":"Common Issues:","text":"<ol> <li>MQTT Connection Fails </li> <li>Ensure Home Assistant\u2019s MQTT broker is running.  </li> <li> <p>Verify credentials and network connectivity.</p> </li> <li> <p>Sensors Not Updating </p> </li> <li>Check firewall settings to allow HASS Agent communication.  </li> <li>Restart Home Assistant and HASS Agent.</li> </ol> <p>Bug</p> <p>(Latest) HA Core update 2024.5.0 breaks notification/media player entities.</p> <p>Ok, so, Quick &amp; Dirty fix for anyone that can/wants edit the files manually  </p> <p>Navigate to \"/config/custom_components/hass_agent\" - either inside the container or via some editor when using the supervisor enabled HA.  </p> <p>Edit \"init.py\" file (for example \"vi init.py\")  </p> <p>Add \"async\" in following places:  </p> <pre><code>line 27: \"async def update_device_info(hass: HomeAssistant, entry: ConfigEntry, new_device_info):\"\nline 139: \"async def updated(message: ReceiveMessage):\"\n</code></pre> <p>Add \"await\" in following places:  </p> <pre><code>line 124: \"await update_device_info(hass, entry, response_json)\"\nline 144: \"await update_device_info(hass, entry, payload)\"\n</code></pre> <p> </p> <p>Restart Home Assistant</p> <p>What I did was do the above changes on version lower than 2024.5.0, confirmed that notifications and media player are working, then I upgraded to 2024.5.0 and tested the same - appears to work as expected.</p> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/integrations/mqtt/","title":"MQTT","text":""},{"location":"documentation/Home_Assistant/integrations/mqtt/#mqtt","title":"MQTT","text":""},{"location":"documentation/Home_Assistant/integrations/mqtt/#installation-of-mqtt-in-home-assistant","title":"Installation of MQTT in Home Assistant","text":""},{"location":"documentation/Home_Assistant/integrations/mqtt/#overview","title":"Overview","text":"<p>MQTT (Message Queuing Telemetry Transport) is a lightweight messaging protocol for small sensors and mobile devices. This guide provides a structured approach to installing and configuring MQTT within Home Assistant.</p>"},{"location":"documentation/Home_Assistant/integrations/mqtt/#technical-details","title":"Technical Details","text":"<p>MQTT enables smart home devices to communicate efficiently. Below is a diagram of a basic MQTT architecture:</p> <p></p>"},{"location":"documentation/Home_Assistant/integrations/mqtt/#system-requirements","title":"System Requirements:","text":"Component Minimum Requirement Home Assistant Version 2023.4 or later MQTT Broker Mosquitto or any compatible broker Network Stable local network connection"},{"location":"documentation/Home_Assistant/integrations/mqtt/#infobox","title":"Infobox","text":"<p>Key Facts about MQTT - Lightweight protocol for IoT messaging. - Works over TCP/IP networks. - Supports QoS (Quality of Service) levels for reliability.</p>"},{"location":"documentation/Home_Assistant/integrations/mqtt/#steps","title":"Steps","text":"<ol> <li>Install the MQTT Broker</li> <li>Go to Home Assistant UI and navigate to <code>Settings &gt; Add-ons &gt; Add-on Store</code>.</li> <li>Search for Mosquitto broker and click <code>Install</code>.</li> <li> <p>After installation, enable <code>Start on boot</code> and <code>Watchdog</code>.</p> </li> <li> <p>Configure MQTT in Home Assistant</p> </li> <li>Navigate to <code>Settings &gt; Devices &amp; Services &gt; MQTT</code>.</li> <li>Click <code>Configure</code> and enable Discovery.</li> <li> <p>Set up authentication details if required.</p> </li> <li> <p>Verify the Installation</p> </li> <li>Use MQTT Explorer or MQTT CLI to test connectivity.</li> <li>Publish a test message and check logs.</li> </ol>"},{"location":"documentation/Home_Assistant/integrations/mqtt/#commands","title":"Commands","text":"<p>To test the MQTT broker, use:</p> <pre><code>mosquitto_pub -h localhost -t \"home/test\" -m \"Hello MQTT\"\nmosquitto_sub -h localhost -t \"home/test\"\n</code></pre>"},{"location":"documentation/Home_Assistant/integrations/mqtt/#examples","title":"Examples","text":"<p>Example Home Assistant configuration for MQTT integration:</p> <pre><code>mqtt:\n  broker: localhost\n  port: 1883\n  username: \"user\"\n  password: \"password\"\n</code></pre>"},{"location":"documentation/Home_Assistant/integrations/mqtt/#resources","title":"Resources","text":"<ul> <li>Home Assistant MQTT Documentation</li> <li>Mosquitto MQTT Broker</li> </ul>"},{"location":"documentation/Home_Assistant/integrations/mqtt/#troubleshooting","title":"Troubleshooting","text":"<p>Issue: MQTT broker does not start. Resolution: Check <code>mosquitto.conf</code> for errors and ensure the port is not blocked.</p> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/messaging/whatsapp/","title":"WhatsApp","text":""},{"location":"documentation/Home_Assistant/messaging/whatsapp/#whatsapp","title":"WhatsApp","text":""},{"location":"documentation/Home_Assistant/messaging/whatsapp/#how-to-send-whatsapp-messages-in-home-assistant","title":"How to Send WhatsApp Messages in Home Assistant","text":""},{"location":"documentation/Home_Assistant/messaging/whatsapp/#introduction","title":"Introduction","text":"<p>Home Assistant is an open-source home automation platform that allows you to integrate various smart devices and services. One useful feature is the ability to send WhatsApp messages directly from Home Assistant. This guide will walk you through how to set up and use Call Me Bot for sending personal WhatsApp messages.  </p>"},{"location":"documentation/Home_Assistant/messaging/whatsapp/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have the following: - A working Home Assistant installation - An internet connection - A WhatsApp account - Access to Call Me Bot (CallMeBot Website)  </p>"},{"location":"documentation/Home_Assistant/messaging/whatsapp/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"documentation/Home_Assistant/messaging/whatsapp/#step-1-request-api-access","title":"Step 1: Request API Access","text":"<ol> <li>Visit the Call Me Bot website.  </li> <li>Follow the instructions to request access to their WhatsApp API.  </li> <li>Once approved, you will receive a unique API key.  </li> </ol>"},{"location":"documentation/Home_Assistant/messaging/whatsapp/#step-2-configure-home-assistant","title":"Step 2: Configure Home Assistant","text":"<p>Edit your <code>configuration.yaml</code> file to include the following automation for sending messages:  </p> <pre><code>notify:  \n  - name: whatsapp  \n    platform: rest  \n    resource: https://api.callmebot.com/whatsapp.php\n    data:\n      source: HA\n      phone: YOUR_PHONE\n      apikey: YOUR_APIKEY  \n</code></pre> <p>Replace <code>YOUR_PHONE</code> and <code>YOUR_APIKEY</code> with your actual phone number and API key from Call Me Bot.  </p>"},{"location":"documentation/Home_Assistant/messaging/whatsapp/#step-3-test-the-integration","title":"Step 3: Test the Integration","text":"<p>To verify that your WhatsApp message automation is working, create a script in Home Assistant:  </p> <pre><code>script:  \n  send_whatsapp_message:  \n    alias: Send WhatsApp Message  \n    sequence:  \n      - service: notify.whatsapp  \n        data:  \n          message: \"Hello from Home Assistant!\"  \n</code></pre> <p>Trigger the script from Home Assistant\u2019s UI or through an automation. If correctly set up, you should receive a WhatsApp message.  </p>"},{"location":"documentation/Home_Assistant/messaging/whatsapp/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues, consider the following: - Ensure that your API key and phone number are correctly formatted. - Verify that Call Me Bot is operational by checking their website. - Check Home Assistant logs for any error messages related to the notification service.  </p>"},{"location":"documentation/Home_Assistant/messaging/whatsapp/#conclusion","title":"Conclusion","text":"<p>With this setup, you can automate personal WhatsApp messaging within Home Assistant using Call Me Bot, enabling better notifications and smart integrations for your home automation needs.</p> <p>Generated using AI </p>"},{"location":"documentation/Home_Assistant/monitoring/glances/","title":"Glances","text":""},{"location":"documentation/Home_Assistant/monitoring/glances/#glances","title":"Glances","text":""},{"location":"documentation/Home_Assistant/monitoring/glances/#installation-and-usage-of-glances-add-on-integration-within-home-assistant","title":"Installation and Usage of Glances Add-on / Integration within Home Assistant","text":"<p>Learn how to set up and use the Glances add-on or integration in Home Assistant for real-time system monitoring.</p>"},{"location":"documentation/Home_Assistant/monitoring/glances/#overview","title":"Overview","text":"<p>Glances is a cross-platform system monitoring tool that provides detailed insights into system performance. When integrated with Home Assistant, it enables users to monitor CPU, memory, disk usage, and more directly from their smart home dashboard.</p>"},{"location":"documentation/Home_Assistant/monitoring/glances/#technical-details","title":"Technical Details","text":"<ul> <li>Requirements:<ul> <li>Home Assistant Core 2023.4 or later</li> <li>Glances 3.2 or later</li> </ul> </li> <li>Features:<ul> <li>Real-time system monitoring</li> <li>Integration with Home Assistant dashboards</li> <li>Customizable sensors for CPU, memory, disk, and network usage</li> </ul> </li> <li>Outcome: A fully integrated system monitoring solution within Home Assistant.</li> </ul>"},{"location":"documentation/Home_Assistant/monitoring/glances/#infobox","title":"Infobox","text":"<p>Key Facts:    - Tool: Glances    - Platform: Home Assistant    - Features: Real-time monitoring, customizable sensors, and dashboard integration.    - Extensions: Support for MQTT and REST API for advanced configurations.</p> <p></p>"},{"location":"documentation/Home_Assistant/monitoring/glances/#steps","title":"Steps","text":""},{"location":"documentation/Home_Assistant/monitoring/glances/#1-install-glances-add-on","title":"1. Install Glances Add-on","text":"<ol> <li>Open Home Assistant and navigate to Settings &gt; Add-ons.</li> <li>Search for \"Glances\" in the add-on store.</li> <li>Click Install and wait for the installation to complete.</li> <li>Start the add-on and configure it as needed.</li> </ol>"},{"location":"documentation/Home_Assistant/monitoring/glances/#2-configure-glances-integration","title":"2. Configure Glances Integration","text":"<ol> <li>Go to Settings &gt; Devices &amp; Services in Home Assistant.</li> <li>Click Add Integration and search for \"Glances.\"</li> <li>Enter the IP address and port of the Glances server.</li> <li>Save the configuration and restart Home Assistant.</li> </ol>"},{"location":"documentation/Home_Assistant/monitoring/glances/#3-add-glances-sensors-to-dashboard","title":"3. Add Glances Sensors to Dashboard","text":"<ol> <li>Navigate to Settings &gt; Dashboards.</li> <li>Add a new card and select the desired Glances sensors (e.g., CPU usage, memory usage).</li> <li>Customize the card layout and save the changes.</li> </ol>"},{"location":"documentation/Home_Assistant/monitoring/glances/#4-test-the-configuration","title":"4. Test the Configuration","text":"<ol> <li>Verify that the Glances sensors are updating in real-time on the dashboard.</li> <li>Check the Home Assistant logs for any errors or warnings.</li> </ol>"},{"location":"documentation/Home_Assistant/monitoring/glances/#examples","title":"Examples","text":"<ul> <li> <p>Add Glances Sensor to Dashboard:      </p><pre><code>type: entities\nentities:\n  - entity: sensor.glances_cpu_usage\n    name: CPU Usage\n  - entity: sensor.glances_memory_usage\n    name: Memory Usage\n  - entity: sensor.glances_disk_usage\n    name: Disk Usage\n</code></pre> </li> <li> <p>Use MQTT for Advanced Configuration:      </p><pre><code>mqtt:\n  broker: mqtt.example.com\n  port: 1883\n  username: user\n  password: pass\n</code></pre> </li> </ul>"},{"location":"documentation/Home_Assistant/monitoring/glances/#resources","title":"Resources","text":"<ul> <li>Glances Official Documentation</li> <li>Home Assistant Documentation</li> <li>Glances MQTT Integration</li> </ul>"},{"location":"documentation/Home_Assistant/monitoring/glances/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Issue: Glances sensors not updating.      Resolution: Verify the Glances server is running and accessible from Home Assistant.</li> <li>Issue: Integration not found in Home Assistant.      Resolution: Ensure the Glances add-on is installed and configured correctly.</li> <li>Issue: Dashboard not displaying sensors.      Resolution: Check the entity IDs and ensure they are added to the dashboard configuration.</li> </ul> <p>Generated using AI </p>"},{"location":"documentation/Home_Assistant/sensors/battery-sensor/","title":"Battery Sensor","text":""},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#battery-sensor","title":"Battery Sensor","text":""},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#creating-a-custom-sensor-for-low-battery-devices-in-home-assistant","title":"Creating a Custom Sensor for Low Battery Devices in Home Assistant","text":"<p>This guide explains how to create a custom sensor in Home Assistant that lists devices with low battery levels. A helper is used to set the battery threshold, and the sensor is displayed on a dashboard.</p>"},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#overview","title":"Overview","text":"<p>Home Assistant allows users to monitor device battery levels. By creating a custom sensor and using a helper to define a threshold, you can easily identify devices with low battery levels and display them on your dashboard.</p>"},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#technical-details","title":"Technical Details","text":"<ul> <li>Helper: A numeric input helper is used to set the battery threshold dynamically.</li> <li>Template Sensor: A template sensor is created to check device battery levels against the threshold.</li> <li>Dashboard Integration: The sensor is added to a dashboard for easy monitoring.</li> </ul>"},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#infobox","title":"Infobox","text":"<ul> <li>Helper Type: Numeric Input</li> <li>Threshold: User-defined battery percentage (e.g., 20%)</li> <li>Sensor Type: Template Sensor</li> <li>Use Case: Monitor and display low battery devices.</li> </ul>"},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#steps","title":"Steps","text":"<ol> <li> <p>Create a Helper:</p> <ul> <li>Navigate to Settings &gt; Devices &amp; Services &gt; Helpers.</li> <li>Add a new Number helper and name it <code>low_battery_threshold</code>.</li> <li>Set the minimum value to <code>0</code> and the maximum value to <code>100</code>.</li> </ul> </li> <li> <p>Define a Template Sensor:       Add the following configuration to your <code>configuration.yaml</code> file:       </p><pre><code>template:\n  - sensor:\n      - name: \"Low Battery Devices\"\n        state: &gt;\n          {% set threshold = states('input_number.low_battery_threshold') | int %}\n          {% set low_battery_devices = states.sensor | selectattr('attributes.battery_level', 'defined') | selectattr('attributes.battery_level', 'lt', threshold) | map(attribute='entity_id') | list %}\n          {{ low_battery_devices | join(', ') if low_battery_devices else 'None' }}\n        attributes:\n          devices: &gt;\n            {% set threshold = states('input_number.low_battery_threshold') | int %}\n            {% set low_battery_devices = states.sensor | selectattr('attributes.battery_level', 'defined') | selectattr('attributes.battery_level', 'lt', threshold) | map(attribute='entity_id') | list %}\n            {{ low_battery_devices }}\n</code></pre> </li> <li> <p>Restart Home Assistant:</p> <ul> <li>Restart Home Assistant to apply the changes.</li> </ul> </li> <li> <p>Add to Dashboard:</p> <ul> <li>Go to your dashboard and add an Entities Card.</li> <li>Select the <code>sensor.low_battery_devices</code> sensor to display the list of low battery devices.</li> </ul> </li> </ol>"},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#commands","title":"Commands","text":"<ul> <li>Restart Home Assistant:      <pre><code>ha core restart\n</code></pre></li> <li>Check Configuration:      <pre><code>ha core check\n</code></pre></li> </ul>"},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#examples","title":"Examples","text":"<ul> <li>Helper Configuration:      <pre><code>input_number:\n  low_battery_threshold:\n    name: Low Battery Threshold\n    initial: 20\n    min: 0\n    max: 100\n    step: 1\n</code></pre></li> <li>Template Sensor Output:<ul> <li>If the threshold is set to 20%, the sensor might display: <code>sensor.device_1, sensor.device_2</code>.</li> </ul> </li> </ul>"},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#resources","title":"Resources","text":"<ul> <li>Templates and Custom Sensors in Home Assistant</li> <li>Home Assistant Template Sensors</li> <li>Helpers in Home Assistant</li> <li>Material Design Icons</li> <li>Online UUID Generator Tool</li> </ul>"},{"location":"documentation/Home_Assistant/sensors/battery-sensor/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>Issue: The sensor does not display any devices. Resolution: Ensure that the devices have a <code>battery_level</code> attribute and that the helper is configured correctly.</p> </li> <li> <p>Issue: Configuration errors after adding the template sensor. Resolution: Use the <code>ha core check</code> command to validate your configuration.</p> </li> </ul> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/sensors/lights-sensor/","title":"Lights Sensor","text":""},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#lights-sensor","title":"Lights Sensor","text":""},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#creating-a-custom-sensor-for-counting-lights-in-home-assistant","title":"Creating a Custom Sensor for Counting Lights in Home Assistant","text":"<p>This guide explains how to create a custom sensor in Home Assistant that calculates the number of lights currently turned on. The sensor can be displayed on a dashboard for quick monitoring.</p>"},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#overview","title":"Overview","text":"<p>Home Assistant allows users to monitor and control lights in their home. By creating a custom template sensor, you can calculate the number of lights that are currently turned on and display this information on your dashboard.</p>"},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#technical-details","title":"Technical Details","text":"<ul> <li>Sensor Type: Template Sensor</li> <li>Functionality: Counts the number of lights in the <code>on</code> state.</li> <li>Dashboard Integration: The sensor is added to a dashboard for easy monitoring.</li> </ul>"},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#infobox","title":"Infobox","text":"<ul> <li>Sensor Name: <code>number_lights_on</code></li> <li>Friendly Name: Number Lights On</li> <li>Icon: <code>mdi:lightbulb-group</code></li> <li>Use Case: Monitor the number of active lights in your home.</li> </ul>"},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#steps","title":"Steps","text":"<ol> <li> <p>Define the Template Sensor:       Add the following configuration to your <code>configuration.yaml</code> file:       </p><pre><code>template:\n  - sensor:\n      - name: \"Number Lights On\"\n        friendly_name: \"Number Lights On\"\n        value_template: &gt;-\n          {{ states.light\n                | rejectattr('attributes.entity_id', 'defined')\n                | selectattr('state', 'eq', 'on')\n                | list | count }}\n        icon_template: mdi:lightbulb-group\n</code></pre> </li> <li> <p>Restart Home Assistant:</p> <ul> <li>Restart Home Assistant to apply the changes.</li> </ul> </li> <li> <p>Add to Dashboard:</p> <ul> <li>Go to your dashboard and add a Gauge Card or Entities Card.</li> <li>Select the <code>sensor.number_lights_on</code> sensor to display the number of lights currently turned on.</li> </ul> </li> </ol>"},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#commands","title":"Commands","text":"<ul> <li>Restart Home Assistant:      <pre><code>ha core restart\n</code></pre></li> <li>Check Configuration:      <pre><code>ha core check\n</code></pre></li> </ul>"},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#examples","title":"Examples","text":"<ul> <li> <p>Template Sensor Output:</p> <ul> <li>If 3 lights are turned on, the sensor will display: <code>3</code>.</li> </ul> </li> <li> <p>Dashboard Example:</p> <ul> <li>Add a Gauge Card to visually represent the number of lights turned on.</li> </ul> </li> </ul>"},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#resources","title":"Resources","text":"<ul> <li>Templates and Custom Sensors in Home Assistant</li> <li>Home Assistant Template Sensors</li> <li>Home Assistant Light Integration</li> <li>Dashboard Customization</li> </ul>"},{"location":"documentation/Home_Assistant/sensors/lights-sensor/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>Issue: The sensor always shows <code>0</code>. Resolution: Ensure that your lights are correctly integrated into Home Assistant and that their states are being updated.</p> </li> <li> <p>Issue: Configuration errors after adding the template sensor. Resolution: Use the <code>ha core check</code> command to validate your configuration.</p> </li> </ul> <p>Generated using AI</p>"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/","title":"Trash Sensor","text":""},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#trash-sensor","title":"Trash Sensor","text":""},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#creating-a-custom-sensor-for-trash-collection-days-in-home-assistant","title":"Creating a Custom Sensor for Trash Collection Days in Home Assistant","text":"<p>Guide on implementing a custom sensor to track trash collection days in Home Assistant.</p>"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#overview","title":"Overview","text":"<p>This guide provides instructions on setting up a custom sensor in Home Assistant to track trash collection days, improving automation and scheduling.</p>"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#technical-details","title":"Technical Details","text":"<p>Setting up a custom sensor involves YAML configuration and potentially a custom Python script. Home Assistant's template sensors can be used to extract and format waste collection schedules.</p>"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#infobox","title":"Infobox","text":"Feature Description Platform Home Assistant Sensor Type Template &amp; Custom Integration Data Source Local municipality schedule, external APIs Frequency Weekly or custom intervals Use Cases Notification automation, dashboard display"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#steps","title":"Steps","text":"<ol> <li>Identify Data Source: Check municipality schedules or APIs for waste collection days.</li> <li>Create Template Sensor: Use Home Assistant YAML to define a sensor based on schedule data.</li> <li>Automation Setup: Configure alerts and notifications for trash collection reminders.</li> <li>Dashboard Display: Implement Lovelace UI elements to show collection schedule.</li> <li>Testing &amp; Validation: Ensure correct functioning through debugging and HA logs.</li> </ol>"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#commands","title":"Commands","text":"<pre><code>- sensor:\n    - name: \"Trash Type This Week\"\n      unique_id: UUID\n      state: &gt;\n        {% set week_number = now().isocalendar().week %}\n        {% if week_number % 2 == 1 %}\n          GFT\n        {% else %}\n          Restafval\n        {% endif %}\n    - name: \"Paper Bin Today\"\n      unique_id: UUID\n      state: &gt;\n        {% set start_date = as_datetime('2025-05-02') %}  {# change if needed #}\n        {% set today = now().date() %}\n        {% set days_difference = (today - start_date.date()).days %}\n        {% if days_difference % 28 == 0 %}\n          Paper\n        {% else %}\n          No Paper\n        {% endif %}\n</code></pre>"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#examples","title":"Examples","text":"<pre><code>- sensor:\n    - name: \"Count Days to GFT Pick-up\"\n      unique_id: UUID\n      state: &gt;\n        {% set pickup_weekday = 0 %}  {# dinsdag = 1 #}\n        {% set today = now().date() %}\n        {% set weekday_today = today.weekday() %}\n        {% set base_date = today + timedelta(days=((pickup_weekday - weekday_today) % 7)) %}\n        {% set week_num = base_date.isocalendar().week %}\n        {% if week_num % 2 == 1 %}\n          {% set days_until = (base_date - today).days %}\n        {% else %}\n          {% set days_until = (base_date + timedelta(days=7) - today).days %}\n        {% endif %}\n        {{ days_until }}\n      unit_of_measurement: \"days\"\n</code></pre> <pre><code>alias: Notification - MobileApp - Trash\ndescription: \"\"\ntriggers:\n  - at: \"07:00:00\"\n    trigger: time\nconditions:\n  - condition: time\n    weekday:\n      - mon\nactions:\n  - action: notify.mobile_app\n    metadata: {}\n    data:\n      message: &gt;\n        Zet de {{ states('sensor.trash_type_this_week') }} container aan de\n        straat!\nmode: single\n</code></pre>"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#dashboard","title":"Dashboard","text":"<pre><code>type: grid\ncards:\n  - type: custom:button-card\n    entity: sensor.count_days_to_gft_pick_up\n    name: GFT\n    icon: mdi:recycle\n    show_state: true\n    color_type: icon\n    state:\n      - value: 0\n        icon: mdi:trash-can\n        color: red\n        name: TODAY\n      - value: 1\n        icon: mdi:trash-can\n        color: orange\n        name: TOMORROW\n      - operator: &lt;\n        value: 3\n        color: green\n        name: SOON\n      - operator: default\n        color: gray\n  - type: custom:button-card\n    entity: sensor.count_days_to_rest_pick_up\n    name: REST\n    icon: mdi:trash-can\n    show_state: true\n    color_type: icon\n    state:\n      - value: 0\n        icon: mdi:trash-can\n        color: red\n        name: TODAY\n      - value: 1\n        icon: mdi:trash-can\n        color: orange\n        name: TOMORROW\n      - operator: &lt;\n        value: 3\n        color: green\n        name: SOON\n      - operator: default\n        color: gray\n  - type: custom:button-card\n    entity: sensor.count_days_to_paper_pick_up\n    name: PAPER\n    icon: mdi:newspaper\n    show_state: true\n    color_type: icon\n    state:\n      - value: 0\n        icon: mdi:trash-can\n        color: red\n        name: TODAY\n      - value: 1\n        icon: mdi:trash-can\n        color: orange\n        name: TOMORROW\n      - operator: &lt;\n        value: 10\n        color: green\n        name: SOON\n      - operator: default\n        color: gray\n</code></pre> <p>The icons will change of color depending on the amount of days left to pick up. From gray to green, orange and red on the day itself.</p>"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#resources","title":"Resources","text":"<ul> <li>Home Assistant Documentation</li> <li>Template Sensor Guide</li> <li>Example Waste Collection APIs</li> </ul>"},{"location":"documentation/Home_Assistant/sensors/trash-sensor/#troubleshooting","title":"Troubleshooting","text":"<p>Issue: Sensor data not updating Resolution: Check YAML syntax, validate API responses, and verify Home Assistant logs.</p> <p>Issue: Notifications not triggering Resolution: Ensure automations are correctly set up and review logs for errors.</p> <p>Generated using AI</p>"},{"location":"documentation/Local_AI/installation/","title":"Installation","text":""},{"location":"documentation/Local_AI/installation/#installation","title":"Installation","text":""},{"location":"documentation/Local_AI/installation/#installation-of-llm-local-ai-on-windows","title":"Installation of LLM Local AI on Windows","text":"<p>Guidelines for setting up a small, local Language Model (LLM) using Ollama or llama.cpp.</p>"},{"location":"documentation/Local_AI/installation/#overview","title":"Overview","text":"<p>This guide provides step-by-step instructions for installing a local and lightweight Language Model (LLM) on Windows. The recommended tools include Ollama and llama.cpp, with compact models such as Mistral, TinyLlama, and Gemma:2b.</p>"},{"location":"documentation/Local_AI/installation/#technical-details","title":"Technical Details","text":"<ul> <li>Model Options: Mistral, TinyLlama, Gemma:2b</li> <li>Tool Used: Ollama</li> <li>Execution Method: Simple CLI (<code>ollama run mistral</code>)</li> <li>Hardware Requirements: Runs on CPU or GPU</li> <li>Customization: Fine-tuning and prompt engineering options available</li> </ul>"},{"location":"documentation/Local_AI/installation/#infobox","title":"Infobox","text":"Feature Details Model Types Mistral, TinyLlama, Gemma:2b Tool Used Ollama Execution CLI: <code>ollama run mistral</code> Supported Hardware CPU, GPU Customization Fine-tuning, prompt engineering"},{"location":"documentation/Local_AI/installation/#steps","title":"Steps","text":"<ol> <li> <p>Install Python     Download and install Python 3.10+     During installation: check the box \"Add Python to PATH\"  </p> <pre><code>    python --version\n</code></pre> </li> <li> <p>Install pip dependencies     Open a terminal (CMD or PowerShell) and run  </p> <pre><code>pip install flask experta requests\n</code></pre> </li> <li> <p>Install Waitress     Open a terminal (CMD or PowerShell) and run  </p> <pre><code>pip install waitress\n</code></pre> <p>Waitress is a production-ready WSGI server for Python, as an alternative to Flask's own development server.</p> </li> <li> <p>Install and Run Ollama on Windows     Ollama now offers a Windows-native version. Visit the official Ollama website and download the latest version.     Go to: ollama.com/download     Install the Windows version.</p> </li> <li> <p>Run a model locally     After installation, in a new terminal  </p> <pre><code>ollama run mistral\n</code></pre> <p>The first time, it will download the model (~4-7 GB). Your language model will now run locally via http://localhost:11434</p> </li> <li> <p>Run the Script     A sample script is available offline_assistent.py. Make sure you have saved this script locally, e.g., as offline_assistent.py     Start the script via CMD or PowerShell  </p> <pre><code>python offline_assistent.py\n</code></pre> </li> <li> <p>Test your installation     Then visit in your browser &gt;</p> <p>http://localhost:5000</p> </li> <li> <p>Fine-tune or customize     Modify prompts or parameters as needed to optimize model performance.</p> </li> </ol>"},{"location":"documentation/Local_AI/installation/#commands","title":"Commands","text":"<p>Commonly used commands for installing and running the model: </p><pre><code>ollama pull mistral\nollama run mistral\n</code></pre>"},{"location":"documentation/Local_AI/installation/#examples","title":"Examples","text":"<p>Example usage of the installed model: </p><pre><code>ollama run tinyllama\n</code></pre>"},{"location":"documentation/Local_AI/installation/#resources","title":"Resources","text":"<ul> <li>Ollama Official Documentation</li> <li>MkDocs-Material Documentation</li> <li>Llama.cpp Repository</li> </ul>"},{"location":"documentation/Local_AI/installation/#troubleshooting","title":"Troubleshooting","text":"Issue Resolution Installation fails Ensure Ollama is properly downloaded and installed Model not found Verify the model name and run <code>ollama pull &lt;model&gt;</code> Performance issues Adjust settings or run on GPU for optimization <p>Generated using AI</p>"},{"location":"documentation/Local_AI/offline_assistant/","title":"Offline Assistant","text":""},{"location":"documentation/Local_AI/offline_assistant/#offline-assistant","title":"Offline Assistant","text":""},{"location":"documentation/Local_AI/offline_assistant/#simple-offline-ai-assistant","title":"Simple Offline AI Assistant","text":""},{"location":"documentation/Local_AI/offline_assistant/#overview","title":"Overview","text":"<p>This project provides a sample Python-based AI assistant that operates offline. It integrates a language model and a rule-based system to simulate conversational AI while allowing extensions via a web interface.</p>"},{"location":"documentation/Local_AI/offline_assistant/#technical-details","title":"Technical Details","text":"<ul> <li>Language Model Simulation: Processes user input via <code>parse_user_input</code>.</li> <li>Rule-Based System: Uses <code>Experta</code> for logical inference.</li> <li>LLM Integration: Utilizes <code>Ollama</code> for enhanced AI responses.</li> <li>Web Interface: Extendable for interaction beyond CLI.</li> </ul>"},{"location":"documentation/Local_AI/offline_assistant/#infobox","title":"Infobox","text":"Feature Description Language Model Simulates conversation via parsing logic Rule System Implements logical inference with <code>Experta</code> LLM Integration Uses <code>Ollama</code> to enhance AI capabilities Web Interface Extensible for broader access"},{"location":"documentation/Local_AI/offline_assistant/#steps","title":"Steps","text":"<p>Not applicable.</p>"},{"location":"documentation/Local_AI/offline_assistant/#commands","title":"Commands","text":"<pre><code>python offline_assistent.py\n</code></pre>"},{"location":"documentation/Local_AI/offline_assistant/#examples","title":"Examples","text":"offline_assistent.py<pre><code>from experta import *\nfrom flask import Flask, request, jsonify, render_template_string\nimport subprocess\nimport requests\nimport json\n\n# ---------------------------\n# Regelgebaseerde AI\n# ---------------------------\nclass SmartAssistant(KnowledgeEngine):\n\n    @Rule(Fact(intent='turn_off_lights'), Fact(location='not_home'))\n    def turn_off_lights(self):\n        print(\"[Actie] Lichten worden uitgezet.\")\n\n    @Rule(Fact(intent='turn_on_heater'), Fact(temperature='cold'))\n    def turn_on_heater(self):\n        print(\"[Actie] Verwarming wordt aangezet.\")\n\n\n# ---------------------------\n# Simpele LLM-integratie via Ollama\n# ---------------------------\ndef call_llm(prompt):\n    url = \"http://localhost:11434/api/generate\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = {\n        \"model\": \"mistral\",\n        \"prompt\": prompt,\n        \"stream\": False\n    }\n    response = requests.post(url, headers=headers, json=data)\n    if response.ok:\n        result = response.json()\n        return result.get(\"response\", \"\")\n    else:\n        return \"\"\n\n\ndef parse_llm_response(response):\n    \"\"\"\n    Simpele parser: verwacht JSON-achtige output van de LLM zoals:\n    {'intent': 'turn_off_lights'}\n    \"\"\"\n    try:\n        return json.loads(response)\n    except:\n        return {}\n\n\n# ---------------------------\n# Flask Webinterface\n# ---------------------------\napp = Flask(__name__)\n\nHTML_PAGE = '''\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;Offline AI Assistent&lt;/title&gt;&lt;/head&gt;\n&lt;body style=\"font-family: sans-serif; padding: 20px;\"&gt;\n    &lt;h2&gt;Offline AI Assistent&lt;/h2&gt;\n    &lt;form method=\"post\"&gt;\n        &lt;input type=\"text\" name=\"user_input\" placeholder=\"Typ je opdracht...\" style=\"width: 300px;\" /&gt;\n        &lt;button type=\"submit\"&gt;Verstuur&lt;/button&gt;\n    &lt;/form&gt;\n    {% if response %}\n        &lt;p&gt;&lt;strong&gt;Reactie:&lt;/strong&gt; {{ response }}&lt;/p&gt;\n    {% endif %}\n&lt;/body&gt;\n&lt;/html&gt;\n'''\n\n@app.route(\"/\", methods=[\"GET\", \"POST\"])\ndef index():\n    response = \"\"\n    if request.method == \"POST\":\n        user_input = request.form[\"user_input\"]\n        llm_output = call_llm(f\"Zet deze opdracht om in JSON: '{user_input}'\")\n        parsed = parse_llm_response(llm_output)\n\n        engine = SmartAssistant()\n        engine.reset()\n        engine.declare(Fact(location='not_home'))\n        engine.declare(Fact(temperature='cold'))\n\n        if parsed:\n            engine.declare(Fact(**parsed))\n            engine.run()\n            response = f\"Herkende intentie: {parsed.get('intent')}\"\n        else:\n            response = \"Geen geldige intentie herkend.\"\n\n    return render_template_string(HTML_PAGE, response=response)\n\n\nfrom waitress import serve\n\nif __name__ == \"__main__\":\n    serve(app, host=\"0.0.0.0\", port=5000)\n</code></pre>"},{"location":"documentation/Local_AI/offline_assistant/#resources","title":"Resources","text":"<ul> <li>Experta Documentation</li> <li>Ollama Integration</li> <li>Flask Web Framework</li> </ul>"},{"location":"documentation/Local_AI/offline_assistant/#troubleshooting","title":"Troubleshooting","text":"Issue Solution Assistant not responding Ensure <code>Ollama</code> is properly installed Web interface not working Check Flask installation and API routes Dependency errors Verify packages via <code>pip list</code> <p>Generated using AI</p>"},{"location":"documentation/Local_n8n/accessibility/","title":"Accessibility","text":""},{"location":"documentation/Local_n8n/accessibility/#accessibility","title":"Accessibility","text":""},{"location":"documentation/Local_n8n/accessibility/#making-n8n-accessible-via-iis-reverse-proxy-and-ssl","title":"Making n8n accessible via IIS Reverse Proxy and SSL","text":""},{"location":"documentation/Local_n8n/accessibility/#overview","title":"Overview","text":"<p>This document provides step-by-step instructions to make a local n8n installation accessible externally via IIS, acting as a reverse proxy with SSL configuration.</p>"},{"location":"documentation/Local_n8n/accessibility/#technical-details","title":"Technical Details","text":"<p>IIS (Internet Information Services) can be configured as a reverse proxy to handle HTTPS connections for n8n, forwarding requests securely to a locally hosted instance.</p>"},{"location":"documentation/Local_n8n/accessibility/#infobox","title":"Infobox","text":"Component Description IIS Version IIS 10 or later Reverse Proxy Application Request Routing (ARR) Security SSL Certificate required Local Server n8n running on localhost:5678"},{"location":"documentation/Local_n8n/accessibility/#steps","title":"Steps","text":""},{"location":"documentation/Local_n8n/accessibility/#1-install-required-iis-components","title":"1. Install Required IIS Components","text":"<p>Ensure that Application Request Routing (ARR) and URL Rewrite modules are installed in IIS.</p> <ul> <li>Open IIS Manager (<code>inetmgr</code> via Run).</li> <li>Go to Server Manager &gt; Roles and Features and check if ARR and URL Rewrite are installed.</li> <li>If missing, download ARR from Microsoft IIS Extensions.</li> </ul>"},{"location":"documentation/Local_n8n/accessibility/#2-configure-application-request-routing-arr","title":"2. Configure Application Request Routing (ARR)","text":"<ul> <li>Open IIS Manager.</li> <li>Click on the server name in the left panel.</li> <li>Go to Application Request Routing Cache.</li> <li>Click Server Proxy Settings in the right panel.</li> <li>Check Enable Proxy and click Apply.</li> </ul>"},{"location":"documentation/Local_n8n/accessibility/#3-create-a-new-site-binding-for-your-subdomain","title":"3. Create a New Site Binding for Your Subdomain","text":"<ul> <li>Go to Sites and select your website (<code>n8n.domain.nl</code>).</li> <li>Click Bindings... (on the right panel).</li> <li>Add a new binding:</li> <li>Type: HTTPS</li> <li>IP Address: All unassigned</li> <li>Port: 443</li> <li>SSL Certificate: Select the correct certificate for <code>n8n.domain.nl</code></li> <li>Click OK.</li> </ul>"},{"location":"documentation/Local_n8n/accessibility/#4-set-up-a-url-rewrite-rule","title":"4. Set Up a URL Rewrite Rule","text":"<ul> <li>Select your site (<code>n8n.domain.nl</code>) and open URL Rewrite.</li> <li>Click Add Rules... and choose Reverse Proxy.</li> <li>Set the following configurations:</li> <li>Inbound URL: <code>https://n8n.domain.nl</code></li> <li>Rewrite to: <code>http://localhost:5678</code></li> <li>Allow SSL Offloading: On</li> <li>Preserve Host Header: On</li> <li>Click Apply.</li> </ul>"},{"location":"documentation/Local_n8n/accessibility/#5-test-the-configuration","title":"5. Test the Configuration","text":"<p>Visit <code>https://n8n.domain.nl</code> in your browser. If configured correctly, IIS will forward HTTPS traffic to your n8n instance at <code>http://localhost:5678</code>.</p>"},{"location":"documentation/Local_n8n/accessibility/#commands","title":"Commands","text":"<p>Below are useful IIS commands for debugging and testing the configuration:</p> <pre><code># Check IIS Site Bindings\nGet-WebBinding\n\n# Test Rewrite Rules\nGet-WebConfigurationProperty -filter '/system.webServer/rewrite/rules' -name '.' -PSPath 'IIS:\\'\n\n# Verify ARR Proxy Settings\nGet-WebConfigurationProperty -filter '/system.webServer/proxy' -name '.' -PSPath 'IIS:\\'\n</code></pre>"},{"location":"documentation/Local_n8n/accessibility/#examples","title":"Examples","text":"<p>Example IIS configuration snippet for ARR proxy settings:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;configuration&gt;\n  &lt;system.webServer&gt;\n\n\n\n    &lt;!-- Rewrite rules for proxying to n8n --&gt;\n    &lt;rewrite&gt;\n      &lt;rules&gt;\n\n        &lt;!-- Proxy API requests (e.g., /rest/workflows) --&gt;\n        &lt;rule name=\"Proxy API Calls to n8n\" stopProcessing=\"true\"&gt;\n          &lt;match url=\"^rest/(.*)$\" /&gt;\n          &lt;conditions&gt;\n            &lt;add input=\"{HTTP_HOST}\" pattern=\"^n8n\\.domein\\.nl$\" /&gt;\n          &lt;/conditions&gt;\n          &lt;action type=\"Rewrite\" url=\"http://localhost:5678/rest/{R:1}\" appendQueryString=\"true\" /&gt;\n        &lt;/rule&gt;\n\n        &lt;!-- Proxy everything else (UI, WebSocket, static files) --&gt;\n        &lt;rule name=\"Proxy All to n8n\" stopProcessing=\"true\"&gt;\n          &lt;match url=\"(.*)\" /&gt;\n          &lt;conditions&gt;\n            &lt;add input=\"{HTTP_HOST}\" pattern=\"^n8n\\.domein\\.nl$\" /&gt;\n          &lt;/conditions&gt;\n          &lt;action type=\"Rewrite\" url=\"http://localhost:5678/{R:1}\" appendQueryString=\"true\" /&gt;\n        &lt;/rule&gt;\n\n      &lt;/rules&gt;\n    &lt;/rewrite&gt;\n\n    &lt;!-- CORS headers --&gt;\n    &lt;httpProtocol&gt;\n      &lt;customHeaders&gt;\n        &lt;add name=\"Access-Control-Allow-Origin\" value=\"https://n8n.ruyter.org\" /&gt;\n        &lt;add name=\"Access-Control-Allow-Methods\" value=\"GET, POST, OPTIONS\" /&gt;\n        &lt;add name=\"Access-Control-Allow-Headers\" value=\"Content-Type, Authorization\" /&gt;\n      &lt;/customHeaders&gt;\n    &lt;/httpProtocol&gt;\n\n  &lt;/system.webServer&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"documentation/Local_n8n/accessibility/#resources","title":"Resources","text":"<ul> <li>Microsoft IIS ARR Documentation</li> <li>IIS URL Rewrite Guide</li> <li>n8n Official Docs</li> </ul>"},{"location":"documentation/Local_n8n/accessibility/#troubleshooting","title":"Troubleshooting","text":"Issue Resolution SSL Certificate Not Applied Verify certificate bindings in IIS. 502 Bad Gateway Error Check ARR settings; ensure correct proxy rules. Rewrite Rule Not Working Test the rule using IIS Rewrite logs. Local n8n Unreachable Confirm n8n is running and accessible at <code>localhost:5678</code>. <p>https://community.n8n.io/t/error-while-executing-workflow/28560</p> <p>Ensure WebSocket Protocol is installed in Windows features. - Go to \"Add Roles and Features\" &gt; under Web Server (IIS) &gt; Web Server &gt; Application Development. - Ensure WebSocket Protocol is checked.</p> <p>Generated using AI</p>"},{"location":"documentation/Local_n8n/configuration/","title":"Configuration","text":""},{"location":"documentation/Local_n8n/configuration/#configuration","title":"Configuration","text":""},{"location":"documentation/Local_n8n/configuration/#configuration-of-local-installed-n8n-environment","title":"Configuration of Local Installed n8n Environment","text":"<p>Setting up an n8n instance locally with network access and security considerations.</p>"},{"location":"documentation/Local_n8n/configuration/#overview","title":"Overview","text":"<p>This document provides a detailed guide for configuring an n8n environment installed on a local machine. It includes steps for enabling network access and setting up TLS/HTTPS for secure connections.</p>"},{"location":"documentation/Local_n8n/configuration/#technical-details","title":"Technical Details","text":"<p>This section dives deep into the configuration settings for a locally installed n8n environment.</p>"},{"location":"documentation/Local_n8n/configuration/#infobox","title":"Infobox","text":"Feature Description Host Config Allows access from other devices on the network TLS/HTTPS Secures connections with encryption"},{"location":"documentation/Local_n8n/configuration/#steps","title":"Steps","text":""},{"location":"documentation/Local_n8n/configuration/#configuring-host-for-network-access","title":"Configuring Host for Network Access","text":"<ol> <li>Modify the <code>.env</code> file to set the host:    ```env title=sample    WEBHOOK_URL=https://your-local-ip:5678    N8N_HOST=your-local-ip    N8N_PORT=5678    <pre><code>```env title=sample\nN8N_HOST=0.0.0.0\nN8N_PORT=5678\nN8N_PROTOCOL=http\nSSL_CERT_PATH=cert.pem\nSSL_KEY_PATH=key.pem\n</code></pre></li> </ol> <p>Store this file in the root of the n8n installation. In my case: </p><pre><code>C:\\Users\\username\\AppData\\Roaming\\npm\n</code></pre> <ol> <li>Restart the n8n service:    <pre><code>pm2 restart n8n\n</code></pre></li> </ol>"},{"location":"documentation/Local_n8n/configuration/#setting-up-tlshttps","title":"Setting Up TLS/HTTPS","text":"<ol> <li>Generate SSL certificates using Let's Encrypt or OpenSSL.</li> <li> <p>Configure n8n to use SSL:    </p><pre><code>N8N_PROTOCOL=https\nSSL_CERT_PATH=/path/to/fullchain.pem\nSSL_KEY_PATH=/path/to/privkey.pem\n</code></pre> </li> <li> <p>Restart n8n to apply changes.</p> </li> </ol>"},{"location":"documentation/Local_n8n/configuration/#commands","title":"Commands","text":"Command Description <code>pm2 restart n8n</code> Restarts the n8n service <code>openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes</code> Generates a self-signed SSL certificate"},{"location":"documentation/Local_n8n/configuration/#examples","title":"Examples","text":""},{"location":"documentation/Local_n8n/configuration/#sample-reverse-proxy-configuration-nginx","title":"Sample Reverse Proxy Configuration (NGINX)","text":"<pre><code>server {\n    listen 443 ssl;\n    server_name your-domain.com;\n\n    ssl_certificate /etc/letsencrypt/live/your-domain.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/your-domain.com/privkey.pem;\n\n    location / {\n        proxy_pass http://localhost:5678;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n</code></pre>"},{"location":"documentation/Local_n8n/configuration/#resources","title":"Resources","text":"<ul> <li>n8n Documentation</li> <li>Let's Encrypt Guide</li> <li>NGINX Reverse Proxy Setup</li> </ul>"},{"location":"documentation/Local_n8n/configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/Local_n8n/configuration/#issue-unable-to-access-from-other-devices","title":"Issue: Unable to Access from Other Devices","text":"<p>Solution: Ensure firewall settings allow connections on the specified port.</p>"},{"location":"documentation/Local_n8n/configuration/#issue-ssl-not-working","title":"Issue: SSL Not Working","text":"<p>Solution: Verify the certificate paths and permissions.</p> <p>Generated using AI</p>"},{"location":"documentation/Local_n8n/docker/","title":"Docker","text":""},{"location":"documentation/Local_n8n/docker/#docker","title":"Docker","text":""},{"location":"documentation/Local_n8n/docker/#installation-of-docker-for-windows-server-2025-and-wsl-with-ubuntu","title":"Installation of Docker for Windows Server 2025 and WSL with Ubuntu","text":""},{"location":"documentation/Local_n8n/docker/#overview","title":"Overview","text":"<p>This guide covers the installation process for Docker on Windows Server 2025, including setting up Windows Subsystem for Linux (WSL) with Ubuntu.</p>"},{"location":"documentation/Local_n8n/docker/#technical-details","title":"Technical Details","text":"<p>Docker provides containerization capabilities for running lightweight, portable applications. With Windows Server 2025, leveraging WSL allows a seamless integration of Linux distributions.</p>"},{"location":"documentation/Local_n8n/docker/#infobox","title":"Infobox","text":"Feature Description Docker Version Latest stable release OS Support Windows Server 2025 WSL Version WSL 2 Linux Distro Ubuntu"},{"location":"documentation/Local_n8n/docker/#steps","title":"Steps","text":""},{"location":"documentation/Local_n8n/docker/#step-1-clean-up","title":"Step 1: Clean-up","text":"<p>Remove all that we have installed and configured in the first installation.</p>"},{"location":"documentation/Local_n8n/docker/#step-2-add-roles-and-features","title":"Step 2: Add roles and features","text":"<p>Install Installeer Hyper-V and Containers</p> <p>Ensure that the necessary features are enabled: </p><pre><code>dism /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux\ndism /online /enable-feature /featurename:VirtualMachinePlatform\n</code></pre>"},{"location":"documentation/Local_n8n/docker/#step-3-install-docker-ce-moby","title":"Step 3: Install Docker CE / Moby","text":"<p>Install Docker </p><pre><code>Invoke-WebRequest -UseBasicParsing \"https://raw.githubusercontent.com/microsoft/Windows-Containers/Main/helpful_tools/Install-DockerCE/install-docker-ce.ps1\" -o install-docker-ce.ps1\n</code></pre> <pre><code>powershell -ExecutionPolicy Bypass -File install-docker-ce.ps1\n</code></pre>"},{"location":"documentation/Local_n8n/docker/#step-4-switch-os-type","title":"Step 4: Switch OS Type","text":"<p>Within Docker we now need to switch to Linux to be able to use Linux based packages. Normally you should do that with dockercli.exe -switchdeamon</p> <p></p><pre><code>&amp; 'C:\\Program Files\\Docker\\Docker\\DockerCli.exe' -SwitchDaemon\n</code></pre> The only problem is: I don't have that executable in my installation, so we need to do it the hard way. So let's continue."},{"location":"documentation/Local_n8n/docker/#step-5-enable-wsl-and-virtual-machine-platform","title":"Step 5: Enable WSL and Virtual Machine Platform","text":"<p>Run the following command in PowerShell (Administrator): Check for WSL 2 (back-end for linux contaciners)</p> <pre><code>wsl --list --verbose\n</code></pre> <pre><code>wsl --install -d Ubuntu\n</code></pre> <p>This will install Ubuntu. We still need to change the OS Type to Linux.</p> <pre><code>docker info | Select-String \"OSType\"\n</code></pre>"},{"location":"documentation/Local_n8n/docker/#step-6-installl-docker-in-ubuntu","title":"Step 6: Installl Docker in Ubuntu","text":"<p>As soon as you are in Ubuntu (WSL Terminal), you can install docker within Ubuntu. To do that use:</p> <pre><code>sudo apt update &amp;&amp; sudo apt install -y docker.io\n</code></pre> <pre><code>sudo systemctl enable --now docker\n</code></pre> <p>Check the installation:  </p> <pre><code>docker --version\n</code></pre> <p>Add your user to the docker group  </p> <pre><code>sudo usermod -aG docker $USER\n</code></pre> <pre><code>exec sudo su - $USER\n</code></pre> <p>This will avoid having to use sudo all the time. Test Linux containers in WSL Start a simple container to see if everything works:</p> <pre><code>docker run --rm -it alpine sh\n</code></pre> <p>Now Docker CE can run Linux containers via WSL.</p> <p></p>"},{"location":"documentation/Local_n8n/docker/#commands","title":"Commands","text":"Command Description <code>wsl --install</code> Installs WSL with the default Linux distribution. <code>winget install -e --id Docker.DockerDesktop</code> Installs Docker Desktop. <code>docker run hello-world</code> Tests the Docker installation. <pre><code>docker version\n</code></pre> <pre><code>docker info\n</code></pre>"},{"location":"documentation/Local_n8n/docker/#examples","title":"Examples","text":"<p>Run a simple Docker container: </p><pre><code>docker run -it ubuntu bash\n</code></pre>"},{"location":"documentation/Local_n8n/docker/#resources","title":"Resources","text":"<ul> <li>Docker Official Documentation</li> <li>WSL Documentation</li> <li>Switching to Docker</li> <li>Get started Prep Windows for containers</li> <li>Install Docker</li> </ul>"},{"location":"documentation/Local_n8n/docker/#troubleshooting","title":"Troubleshooting","text":"Issue Solution Docker not starting Ensure WSL 2 integration is enabled in Docker Desktop settings. Permission denied Run PowerShell as Administrator. <p>Generated using AI</p>"},{"location":"documentation/Local_n8n/installation/","title":"Installation","text":""},{"location":"documentation/Local_n8n/installation/#installation","title":"Installation","text":""},{"location":"documentation/Local_n8n/installation/#nodejs-installation","title":"Node.js Installation","text":"<p>Installing Node.js on Windows</p>"},{"location":"documentation/Local_n8n/installation/#overview","title":"Overview","text":"<p>Node.js is an open-source, cross-platform JavaScript runtime environment that allows developers to build scalable network applications. This guide provides step-by-step instructions for installing Node.js on Windows.</p>"},{"location":"documentation/Local_n8n/installation/#technical-details","title":"Technical Details","text":"<p>Node.js can be installed on Windows using the official installer or a package manager such as Chocolatey or Scoop. The recommended approach is to download the installer directly from the official Node.js website.</p>"},{"location":"documentation/Local_n8n/installation/#infobox","title":"Infobox","text":"Tool Description Node.js JavaScript runtime built on Chrome's V8 engine npm Default package manager for Node.js Chocolatey Windows package manager for automated installations Scoop Lightweight package manager for Windows"},{"location":"documentation/Local_n8n/installation/#steps","title":"Steps","text":""},{"location":"documentation/Local_n8n/installation/#download-and-install-nodejs","title":"Download and Install Node.js","text":"<ol> <li>Visit the Official Node.js website.</li> <li>Choose the recommended version for Windows.</li> <li>Download the installer (<code>.msi</code> file).</li> <li>Run the installer and follow the setup wizard instructions.</li> <li>Verify the installation using the command:</li> </ol> <pre><code>node -v\n</code></pre>"},{"location":"documentation/Local_n8n/installation/#install-via-chocolatey","title":"Install via Chocolatey","text":"<p>If Chocolatey is installed, use:</p> <pre><code>choco install nodejs\n</code></pre>"},{"location":"documentation/Local_n8n/installation/#install-via-scoop","title":"Install via Scoop","text":"<p>For Scoop users:</p> <pre><code>scoop install nodejs\n</code></pre>"},{"location":"documentation/Local_n8n/installation/#install-additional-tools-for-nodejs","title":"Install Additional Tools for Node.js","text":"<p>This script will install Python and the Visual Studio Build Tools, necessary to compile Node.js native modules. Note that Chocolatey and required Windows updates will also be installed. This will require about 3 GiB of free disk space, plus any space necessary to install Windows updates. This will take a while to run. Please close all open programs for the duration of the installation. If the installation fails, please ensure Windows is fully updated, reboot your computer and try to run this again. This script can be found in the Start menu under Node.js. Detailed instructions to install these tools manually are available at Tools for Node.js.</p> <p>This script will direct to Chocolatey to install packages. By using Chocolatey to install a package, you are accepting the license for the application, executable(s), or other artifacts delivered to your machine as a result of a Chocolatey install. This acceptance occurs whether you know the license terms or not. Read and understand the license terms of the packages being installed and their dependencies prior to installation:</p> <ul> <li>https://chocolatey.org/packages/chocolatey</li> <li>https://chocolatey.org/packages/python</li> <li>https://chocolatey.org/packages/visualstudio2019-workload-vctools</li> </ul> <p>This script is provided AS-IS without any warranties of any kind.</p> <pre><code>\"%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" ^\n-NoProfile ^\n-InputFormat None ^\n-ExecutionPolicy Bypass ^\n-Command Start-Process ^\n    '%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe' ^\n    -ArgumentList '-NoProfile -InputFormat None -ExecutionPolicy Bypass -Command ^\n    [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12; ^\n    iex ((New-Object System.Net.WebClient).DownloadString(''https://chocolatey.org/install.ps1'')); ^\n    choco upgrade -y python visualstudio2019-workload-vctools; ^\n    Read-Host ''Type ENTER to exit'' ' ^\n    -Verb RunAs\n</code></pre>"},{"location":"documentation/Local_n8n/installation/#install-n8n","title":"Install n8n","text":"<p>Open your command-line interface (CLI) and execute the command:</p> <pre><code>npm install n8n -g\n</code></pre> <p>This installs n8n globally on your machine, making it accessible from any directory.</p>"},{"location":"documentation/Local_n8n/installation/#your-done","title":"Your done","text":"<p>Launch n8n by typing n8n or n8n start in the CLI. This command starts the platform locally, allowing you to access it through your web browser.</p> <pre><code>n8n start\n</code></pre> <p>Once n8n is running, open your browser and navigate to the local address provided in the CLI. During the initial setup, you\u2019ll be prompted to create an admin account by entering your email address, name, and password. This account will serve as your primary access point for managing workflows and configurations.</p>"},{"location":"documentation/Local_n8n/installation/#how-to-update-n8n","title":"How to update n8n","text":"<p>Keeping n8n updated is essential to take advantage of the latest features, performance enhancements, and security updates. Updating the platform is simple and can be done using the following command in your CLI:</p> <pre><code>npm update -g n8n\n</code></pre> <p>It is recommended to check for updates regularly to ensure compatibility with external services and maintain optimal performance. Staying up-to-date also helps you avoid potential issues caused by outdated dependencies or integrations.</p>"},{"location":"documentation/Local_n8n/installation/#commands","title":"Commands","text":"Command Description <code>node -v</code> Check installed Node.js version <code>npm -v</code> Check installed npm version <code>npm install -g &lt;package&gt;</code> Install a global Node.js package"},{"location":"documentation/Local_n8n/installation/#examples","title":"Examples","text":""},{"location":"documentation/Local_n8n/installation/#running-a-simple-nodejs-script","title":"Running a Simple Node.js Script","text":"<p>Create a <code>hello.js</code> file:</p> <pre><code>console.log(\"Hello, Node.js!\");\n</code></pre> <p>Run the script:</p> <pre><code>node hello.js\n</code></pre>"},{"location":"documentation/Local_n8n/installation/#resources","title":"Resources","text":"<ul> <li>Node.js Official Documentation</li> <li>Chocolatey Node.js Package</li> <li>Scoop Node.js Package</li> <li>Hosting n8n</li> <li>Community Edition n8n</li> </ul>"},{"location":"documentation/Local_n8n/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/Local_n8n/installation/#path-issues","title":"Path Issues","text":"<p>Ensure Node.js is added to the system <code>PATH</code>:</p> <pre><code>echo %PATH%\n</code></pre>"},{"location":"documentation/Local_n8n/installation/#permission-errors","title":"Permission Errors","text":"<p>Run the installer as administrator or use:</p> <pre><code>npm config set prefix %USERPROFILE%\\npm\n</code></pre>"},{"location":"documentation/Local_n8n/installation/#choices","title":"Choices","text":"<p>And to make it even more complex: See my Docker CE adventure</p> <p>Generated using AI</p>"},{"location":"documentation/Local_n8n/nginx_n8n/","title":"NGINX n8n","text":""},{"location":"documentation/Local_n8n/nginx_n8n/#nginx-n8n","title":"NGINX n8n","text":""},{"location":"documentation/Local_n8n/nginx_n8n/#installation-of-nginx-and-n8n-in-wsl-docker","title":"Installation of NGINX and N8N in WSL Docker","text":""},{"location":"documentation/Local_n8n/nginx_n8n/#overview","title":"Overview","text":"<p>This guide walks through the installation and setup of NGINX and N8N in WSL Docker to enable a streamlined development environment.</p>"},{"location":"documentation/Local_n8n/nginx_n8n/#technical-details","title":"Technical Details","text":"<p>NGINX is a high-performance web server and reverse proxy, while N8N is an automation tool enabling workflow integrations. Running both in Docker under WSL enhances portability and efficiency.</p>"},{"location":"documentation/Local_n8n/nginx_n8n/#infobox","title":"Infobox","text":"Component Version Purpose NGINX Latest Web Server N8N Latest Workflow Automation Docker Latest Container Management WSL 2 Linux Compatibility"},{"location":"documentation/Local_n8n/nginx_n8n/#steps","title":"Steps","text":""},{"location":"documentation/Local_n8n/nginx_n8n/#1-install-docker-in-wsl","title":"1. Install Docker in WSL","text":"<pre><code>sudo apt update &amp;&amp; sudo apt install docker.io\nsudo systemctl enable --now docker\n</code></pre>"},{"location":"documentation/Local_n8n/nginx_n8n/#2-pull-and-run-nginx-container","title":"2. Pull and Run NGINX Container","text":"<pre><code>docker pull nginx\ndocker run -d -p 80:80 --name nginx-container nginx\n</code></pre>"},{"location":"documentation/Local_n8n/nginx_n8n/#3-pull-and-run-n8n-container","title":"3. Pull and Run N8N Container","text":"<pre><code>docker pull n8nio/n8n\ndocker run -d -p 5678:5678 --name n8n-container n8nio/n8n\n</code></pre>"},{"location":"documentation/Local_n8n/nginx_n8n/#4-configure-nginx-as-a-reverse-proxy","title":"4. Configure NGINX as a Reverse Proxy","text":"<p>Create an NGINX configuration file: </p><pre><code>nano /etc/nginx/conf.d/n8n.conf\n</code></pre> Add the following content: <pre><code>server {\n    listen 80;\n    server_name n8n.local;\n\n    location / {\n        proxy_pass http://localhost:5678;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n</code></pre> Then restart NGINX: <pre><code>docker exec nginx-container nginx -s reload\n</code></pre>"},{"location":"documentation/Local_n8n/nginx_n8n/#commands","title":"Commands","text":"<p>Common Docker commands for managing containers: </p><pre><code>docker ps          # List running containers\ndocker stop nginx-container n8n-container  # Stop containers\ndocker start nginx-container n8n-container # Start containers\ndocker logs nginx-container  # View logs\n</code></pre>"},{"location":"documentation/Local_n8n/nginx_n8n/#examples","title":"Examples","text":"<p>Running N8N workflows: </p><pre><code>docker exec -it n8n-container n8n\n</code></pre>"},{"location":"documentation/Local_n8n/nginx_n8n/#resources","title":"Resources","text":"<ul> <li>NGINX Official Docs</li> <li>N8N Documentation</li> <li>Docker in WSL Guide</li> </ul>"},{"location":"documentation/Local_n8n/nginx_n8n/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/Local_n8n/nginx_n8n/#issue-nginx-not-starting","title":"Issue: NGINX Not Starting","text":"<p>Check logs: </p><pre><code>docker logs nginx-container\n</code></pre> Verify configuration: <pre><code>nginx -t\n</code></pre>"},{"location":"documentation/Local_n8n/nginx_n8n/#issue-n8n-port-not-accessible","title":"Issue: N8N Port Not Accessible","text":"<p>Ensure the container is running: </p><pre><code>docker ps | grep n8n\n</code></pre> Restart the container: <pre><code>docker restart n8n-container\n</code></pre> <p>Generated using AI</p>"},{"location":"documentation/Local_n8n/workflows/","title":"Workflows","text":""},{"location":"documentation/Local_n8n/workflows/#workflows","title":"Workflows","text":""},{"location":"documentation/MkDocs/configuration/","title":"Configuration","text":""},{"location":"documentation/MkDocs/configuration/#configuration","title":"Configuration","text":""},{"location":"documentation/MkDocs/configuration/#configuration-of-mkdocs-material-with-features-and-extensions","title":"Configuration of MkDocs Material with Features and Extensions","text":"<p>Enhance your MkDocs documentation with advanced features and extensions.</p>"},{"location":"documentation/MkDocs/configuration/#overview","title":"Overview","text":"<p>MkDocs Material provides a rich set of features and extensions to create professional and interactive documentation. This guide explains how to configure these features and extensions effectively.</p>"},{"location":"documentation/MkDocs/configuration/#technical-details","title":"Technical Details","text":"<ul> <li>Requirements:<ul> <li>MkDocs 1.6.1 or later</li> <li>MkDocs Material 9.6.12 or later</li> </ul> </li> <li>Features:<ul> <li>Code annotation, copy buttons, external links, and more.</li> </ul> </li> <li>Extensions:<ul> <li>Advanced Markdown extensions like <code>pymdownx</code> for enhanced formatting.</li> </ul> </li> <li>Outcome: A fully customized and feature-rich documentation site.</li> </ul>"},{"location":"documentation/MkDocs/configuration/#infobox","title":"Infobox","text":"<p>Key Facts:    - Tool: MkDocs Material    - Language: Markdown    - Platform: MkDocs    - Features: Interactive navigation, search, and code enhancements.    - Extensions: <code>pymdownx</code> suite for advanced Markdown capabilities.</p>"},{"location":"documentation/MkDocs/configuration/#steps","title":"Steps","text":""},{"location":"documentation/MkDocs/configuration/#1-update-mkdocsyml","title":"1. Update <code>mkdocs.yml</code>","text":"<ol> <li>Open the <code>mkdocs.yml</code> file in your project directory.</li> <li>Add the following configuration for the theme:       <pre><code>theme:\n  name: material\n  palette:\n    - scheme: slate\n      toggle:\n        icon: material/weather-sunny\n        name: Dark mode\n      primary: light blue\n      accent: red\n    - scheme: default\n      toggle:\n        icon: material/weather-night\n        name: Light mode\n      primary: light blue\n      accent: red\n  features:\n    - content.code.annotate\n    - content.code.copy\n    - content.links.external\n    - navigation.indexes\n    - navigation.path\n    - navigation.top\n    - search.suggest\n    - search.highlights\n    - content.tab.link\n</code></pre></li> </ol>"},{"location":"documentation/MkDocs/configuration/#2-add-markdown-extensions","title":"2. Add Markdown Extensions","text":"<ol> <li>In the [mkdocs.yml] file, configure the following extensions:       <pre><code>markdown_extensions:\n  - abbr\n  - attr_list\n  - admonition\n  - footnotes\n  - pymdownx.arithmatex:\n      generic: true\n  - pymdownx.caret\n  - pymdownx.critic\n  - pymdownx.details\n  - pymdownx.emoji:\n      emoji_index: !!python/name:material.extensions.emoji.twemoji\n      emoji_generator: !!python/name:material.extensions.emoji.to_svg\n  - pymdownx.highlight:\n      anchor_linenums: true\n      line_spans: __span\n      pygments_lang_class: true\n  - pymdownx.inlinehilite\n  - pymdownx.keys\n  - pymdownx.mark\n  - pymdownx.snippets:\n      auto_append:\n      - includes/abbreviations.md\n  - pymdownx.superfences:\n      custom_fences:\n      - name: mermaid\n        class: mermaid\n        format: !!python/name:pymdownx.superfences.fence_code_format\n  - pymdownx.tabbed:\n      alternate_style: true\n  - pymdownx.tilde\n</code></pre></li> </ol>"},{"location":"documentation/MkDocs/configuration/#3-test-the-configuration","title":"3. Test the Configuration","text":"<ol> <li>Serve the documentation locally:       <pre><code>mkdocs serve\n</code></pre></li> <li>Open your browser and navigate to <code>http://127.0.0.1:8000</code> to verify the changes.</li> </ol>"},{"location":"documentation/MkDocs/configuration/#4-customize-further","title":"4. Customize Further","text":"<ul> <li>Add custom CSS or JavaScript files for additional styling or functionality.</li> <li>Update the [docs] folder with your content, using the configured features and extensions.</li> </ul>"},{"location":"documentation/MkDocs/configuration/#examples","title":"Examples","text":"<ul> <li>Add Code Annotation:      <pre><code># Example of annotated code\ndef greet(name):\n    \"\"\"Greets the user by name.\"\"\"\n    return f\"Hello, {name}!\"\n</code></pre></li> <li>Use Mermaid Diagrams:      <pre><code>graph TD;\n    A--&gt;B;\n    A--&gt;C;\n    B--&gt;D;\n    C--&gt;D;</code></pre></li> </ul>"},{"location":"documentation/MkDocs/configuration/#resources","title":"Resources","text":"<ul> <li>MkDocs Official Documentation</li> <li>MkDocs Material Documentation</li> <li>Pymdown Extensions Documentation</li> </ul>"},{"location":"documentation/MkDocs/configuration/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Issue: Features not applied.      Resolution: Ensure the <code>features</code> section is correctly configured in [mkdocs.yml].</li> <li>Issue: Extensions not working.      Resolution: Verify the <code>markdown_extensions</code> section in [mkdocs.yml] and ensure all dependencies are installed.</li> <li>Issue: Local server not accessible.      Resolution: Check if the port <code>8000</code> is open and not blocked by a firewall.</li> </ul> <p>Generated using AI</p>"},{"location":"documentation/MkDocs/installation/","title":"Installation","text":""},{"location":"documentation/MkDocs/installation/#installation","title":"Installation","text":""},{"location":"documentation/MkDocs/installation/#installation-of-mkdocs-material-with-python-on-windows-server","title":"Installation of MkDocs Material with Python on Windows Server","text":"<p>A step-by-step guide to setting up MkDocs Material.</p>"},{"location":"documentation/MkDocs/installation/#overview","title":"Overview","text":"<p>MkDocs Material is a powerful and customizable theme for MkDocs, designed to create professional documentation sites. This guide walks you through the installation and configuration process on a Windows Server using Python.</p>"},{"location":"documentation/MkDocs/installation/#technical-details","title":"Technical Details","text":"<ul> <li>Requirements:<ul> <li>Python 3.7 or later</li> <li>pip (Python's package manager)</li> <li>Windows Server 2016 or later</li> </ul> </li> <li>Dependencies:<ul> <li>MkDocs</li> <li>MkDocs Material theme</li> </ul> </li> <li>Outcome: A fully functional documentation site with Material design.</li> </ul>"},{"location":"documentation/MkDocs/installation/#infobox","title":"Infobox","text":"<p>Key Facts:    - Tool: MkDocs Material    - Language: Python    - Platform: Windows Server    - Dependencies: Python, pip, MkDocs</p>"},{"location":"documentation/MkDocs/installation/#steps","title":"Steps","text":""},{"location":"documentation/MkDocs/installation/#1-install-python","title":"1. Install Python","text":"<ol> <li>Download Python from the Official Python website.</li> <li>Run the installer and ensure the \"Add Python to PATH\" option is checked.</li> <li>Verify the installation:       <pre><code>python --version\n</code></pre></li> </ol>"},{"location":"documentation/MkDocs/installation/#2-install-mkdocs","title":"2. Install MkDocs","text":"<ol> <li>Open a terminal (Command Prompt or PowerShell).</li> <li>Install MkDocs using pip:       <pre><code>pip install mkdocs\n</code></pre></li> <li>Verify the installation:       <pre><code>mkdocs --version\n</code></pre></li> </ol>"},{"location":"documentation/MkDocs/installation/#3-install-mkdocs-material","title":"3. Install MkDocs Material","text":"<ol> <li>Install the Material theme:       <pre><code>pip install mkdocs-material\n</code></pre></li> <li>Verify the installation:       <pre><code>mkdocs --version\n</code></pre> Ensure the Material theme is listed in the output.</li> </ol>"},{"location":"documentation/MkDocs/installation/#4-install-material-images","title":"4. Install Material Images","text":"<ol> <li>Install the Material images:       <pre><code>pip install \"mkdocs-material[imaging]\"\n</code></pre></li> </ol>"},{"location":"documentation/MkDocs/installation/#5-create-a-new-mkdocs-project","title":"5. Create a New MkDocs Project","text":"<ol> <li>Navigate to your desired directory:       <pre><code>cd path\\to\\your\\directory\n</code></pre></li> <li>Create a new MkDocs project:       <pre><code>mkdocs new my-project\n</code></pre></li> <li>Navigate into the project directory:       <pre><code>cd my-project\n</code></pre></li> </ol>"},{"location":"documentation/MkDocs/installation/#6-configure-mkdocs-material","title":"6. Configure MkDocs Material","text":"<ol> <li>Open the [mkdocs.yml] file in a text editor.</li> <li>Update the theme section:       <pre><code>theme:\n  name: material\n</code></pre></li> <li>Save the file.</li> </ol>"},{"location":"documentation/MkDocs/installation/#7-serve-the-documentation-locally","title":"7. Serve the Documentation Locally","text":"<ol> <li>Run the following command:       <pre><code>mkdocs serve\n</code></pre></li> <li>Open your browser and go to <code>http://127.0.0.1:8000</code>.</li> </ol>"},{"location":"documentation/MkDocs/installation/#examples","title":"Examples","text":"<ul> <li>Install MkDocs:      <pre><code>pip install mkdocs\n</code></pre></li> <li>Install MkDocs Material:      <pre><code>pip install mkdocs-material\n</code></pre></li> <li>Create a New Project:      <pre><code>mkdocs new my-project\n</code></pre></li> <li>Serve Locally:      <pre><code>mkdocs serve\n</code></pre></li> <li>Update Pip:      <pre><code>python.exe -m pip install --upgrade pip\n</code></pre></li> <li>Update Material:      <pre><code>pip install --upgrade --force-reinstall mkdocs-material\n</code></pre></li> </ul>"},{"location":"documentation/MkDocs/installation/#resources","title":"Resources","text":"<ul> <li>MkDocs Official Documentation</li> <li>MkDocs Material Documentation</li> <li>Python Downloads</li> <li>Python Markdown</li> </ul>"},{"location":"documentation/MkDocs/installation/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Issue: <code>mkdocs</code> command not found.      Resolution: Ensure Python and pip are added to your system PATH.</li> <li>Issue: Theme not applied.      Resolution: Verify the <code>theme</code> section in [mkdocs.yml] is correctly configured.</li> <li>Issue: Local server not accessible.      Resolution: Check if the port <code>8000</code> is open and not blocked by a firewall.</li> <li> <p>Issue: ERROR   -  \"cairosvg\" Python module is installed, but it crashed.  </p> <p> </p> <p>Cause: On Windows, Python packages like cairosvg need the Cairo DLLs to be installed separately. Here's how to fix it, you need to install Cairo for Windows.  Resolution: Install MSYS2: Download and install from MSYS2.  Open the MSYS2 terminal (not cmd, not PowerShell).  Run these commands inside MSYS2:</p> In MSYS2 Terminal<pre><code>pacman -Sy\n</code></pre> <p></p>In MSYS2 Terminal<pre><code>pacman -S mingw-w64-x86_64-cairo\n</code></pre>  Add MSYS2's /mingw64/bin to your Windows PATH environment variable. </li> </ul> <p>Generated using AI</p>"},{"location":"documentation/MkDocs/links/","title":"Links","text":""},{"location":"documentation/MkDocs/links/#links","title":"Links","text":""},{"location":"documentation/MkDocs/links/#extract-external-links-and-group-by-name","title":"Extract External Links and Group by Name","text":"<p>Extract and organize external links from documentation.</p>"},{"location":"documentation/MkDocs/links/#overview","title":"Overview","text":"<p>This guide explains how to create a script that scans all Markdown documents in a project, extracts external links, and generates a page listing them alphabetically grouped by their names.</p>"},{"location":"documentation/MkDocs/links/#technical-details","title":"Technical Details","text":"<ul> <li>Input: Markdown files in the <code>docs</code> directory.</li> <li>Output: A Markdown file (<code>links.md</code>) containing all external links grouped alphabetically.</li> <li>Tools: Python, <code>os</code> module, <code>re</code> module.</li> <li>Outcome: A centralized page for external links, improving navigation and accessibility.</li> </ul>"},{"location":"documentation/MkDocs/links/#infobox","title":"Infobox","text":"<p>Key Facts:    - Language: Python    - Platform: MkDocs    - Features: External link extraction, alphabetical grouping, Markdown generation.    - Use Case: Documentation projects with numerous external references.</p>"},{"location":"documentation/MkDocs/links/#steps","title":"Steps","text":""},{"location":"documentation/MkDocs/links/#1-create-the-script","title":"1. Create the Script","text":"<p>Write a Python script to extract external links and generate the <code>links.md</code> file.</p> <p></p><pre><code># filepath: mkdocs.py\nimport os\nimport re\nfrom collections import defaultdict\n\ndocs_path = 'docs'\noutput_file = os.path.join(docs_path, 'links.md')\n\nlink_pattern = re.compile(r'\\[([^\\]]+)\\]\\((http[s]?://[^\\)]+)\\)')\n\nexternal_links = set()\n\nfor root, _, files in os.walk(docs_path):\n    for file in files:\n        if file.endswith('.md') and file != 'links.md':\n            path = os.path.join(root, file)\n            with open(path, encoding='utf-8') as f:\n                content = f.read()\n                matches = link_pattern.findall(content)\n                for text, url in matches:\n                    external_links.add((text.strip(), url.strip()))\n\n# Categorize by first letter of link text\nexternal_sorted = defaultdict(list)\nfor text, url in sorted(external_links, key=lambda x: x[0].lower()):\n    first_letter = text[0].upper() if text else '#'\n    if not first_letter.isalpha():\n        first_letter = '#'\n    external_sorted[first_letter].append((text, url))\n\n# Write output to Markdown\nwith open(output_file, 'w', encoding='utf-8') as f:\n    f.write(\"# Links\\n\\n\")\n    f.write(\"External links used across the documentation, sorted alphabetically by link text.\\n\\n\")\n    for letter in sorted(external_sorted):\n        f.write(f\"## {letter}\\n\\n\")\n        for text, url in external_sorted[letter]:\n            f.write(f\"- [{text}]({url})\\n\")\n        f.write(\"\\n\")\n</code></pre>"},{"location":"documentation/MkDocs/links/#2-run-the-script","title":"2. Run the Script","text":"<p>Execute the script to generate the <code>links.md</code> file.</p> <p></p><pre><code>python mkdocs.py\n</code></pre>"},{"location":"documentation/MkDocs/links/#3-add-the-generated-page-to-mkdocs","title":"3. Add the Generated Page to MkDocs","text":"<p>Update the <code>mkdocs.yml</code> file to include the <code>links.md</code> page in the navigation.</p> <p></p><pre><code>nav:\n  - Home: index.md\n  - Links: links.md\n</code></pre>"},{"location":"documentation/MkDocs/links/#4-serve-the-documentation-locally","title":"4. Serve the Documentation Locally","text":"<p>Test the changes by serving the documentation locally.</p> <p></p><pre><code>mkdocs serve\n</code></pre> <p>Open your browser and navigate to <code>http://127.0.0.1:8000</code> to verify the <code>Links</code> page.</p>"},{"location":"documentation/MkDocs/links/#examples","title":"Examples","text":""},{"location":"documentation/MkDocs/links/#example-output-in-linksmd","title":"Example Output in <code>links.md</code>","text":"<pre><code># Links\n\nExternal links used across the documentation, sorted alphabetically by link text.\n\n## A\n- [API Documentation](https://api.example.com)\n\n## G\n- [GitHub](https://github.com)\n\n## M\n- [MkDocs](https://www.mkdocs.org)\n</code></pre>"},{"location":"documentation/MkDocs/links/#resources","title":"Resources","text":"<ul> <li>Python Documentation</li> <li>MkDocs Official Documentation</li> <li>Regular Expressions in Python</li> </ul>"},{"location":"documentation/MkDocs/links/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/MkDocs/links/#issue-script-does-not-detect-links","title":"Issue: Script Does Not Detect Links","text":"<p>Resolution: Ensure the Markdown files follow the <code>[text](url)</code> format for links.</p>"},{"location":"documentation/MkDocs/links/#issue-linksmd-not-generated","title":"Issue: <code>links.md</code> Not Generated","text":"<p>Resolution: Verify the script's file paths and permissions.</p>"},{"location":"documentation/MkDocs/links/#issue-links-page-not-visible-in-navigation","title":"Issue: Links Page Not Visible in Navigation","text":"<p>Resolution: Check the <code>mkdocs.yml</code> file for correct navigation configuration.</p> <p>Generated using AI</p>"},{"location":"documentation/MkDocs/theme/","title":"Theme","text":""},{"location":"documentation/MkDocs/theme/#theme","title":"Theme","text":""},{"location":"documentation/MkDocs/theme/#use-of-material-theme-for-mkdocs-with-features-and-extensions","title":"Use of Material Theme for MkDocs with Features and Extensions","text":"<p>Enhance your MkDocs documentation with the Material theme and advanced extensions.</p>"},{"location":"documentation/MkDocs/theme/#overview","title":"Overview","text":"<p>The Material theme for MkDocs offers a modern, feature-rich framework for creating professional documentation. This guide explains how to configure and utilize its features and extensions effectively.</p>"},{"location":"documentation/MkDocs/theme/#technical-details","title":"Technical Details","text":"<ul> <li>Requirements:<ul> <li>MkDocs 1.6.1 or later</li> <li>MkDocs Material 9.6.12 or later</li> </ul> </li> <li>Features:<ul> <li>Code annotation, copy buttons, external links, and more.</li> </ul> </li> <li>Extensions:<ul> <li>Advanced Markdown extensions like <code>pymdownx</code> for enhanced formatting.</li> </ul> </li> <li>Outcome: A fully customized and feature-rich documentation site.</li> </ul>"},{"location":"documentation/MkDocs/theme/#infobox","title":"Infobox","text":"<p>Key Facts:    - Tool: MkDocs Material    - Language: Markdown    - Platform: MkDocs    - Features: Interactive navigation, search, and code enhancements.    - Extensions: <code>pymdownx</code> suite for advanced Markdown capabilities.</p>"},{"location":"documentation/MkDocs/theme/#steps","title":"Steps","text":""},{"location":"documentation/MkDocs/theme/#1-update-mkdocsyml","title":"1. Update <code>mkdocs.yml</code>","text":"<ol> <li>Open the <code>mkdocs.yml</code> file in your project directory.</li> <li>Add the following configuration for the theme:       <pre><code>theme:\n  name: material\n  palette:\n    - scheme: slate\n      toggle:\n        icon: material/weather-sunny\n        name: Dark mode\n      primary: light blue\n      accent: red\n    - scheme: default\n      toggle:\n        icon: material/weather-night\n        name: Light mode\n      primary: light blue\n      accent: red\n  features:\n    - content.code.annotate\n    - content.code.copy\n    - content.links.external\n    - navigation.indexes\n    - navigation.path\n    - navigation.top\n    - search.suggest\n    - search.highlights\n    - content.tab.link\n</code></pre></li> </ol>"},{"location":"documentation/MkDocs/theme/#2-add-markdown-extensions","title":"2. Add Markdown Extensions","text":"<ol> <li>In the [mkdocs.yml] file, configure the following extensions:       <pre><code>markdown_extensions:\n  - abbr\n  - attr_list\n  - admonition\n  - footnotes\n  - pymdownx.arithmatex:\n      generic: true\n  - pymdownx.caret\n  - pymdownx.critic\n  - pymdownx.details\n  - pymdownx.emoji:\n      emoji_index: !!python/name:material.extensions.emoji.twemoji\n      emoji_generator: !!python/name:material.extensions.emoji.to_svg\n  - pymdownx.highlight:\n      anchor_linenums: true\n      line_spans: __span\n      pygments_lang_class: true\n  - pymdownx.inlinehilite\n  - pymdownx.keys\n  - pymdownx.mark\n  - pymdownx.snippets:\n      auto_append:\n      - includes/abbreviations.md\n  - pymdownx.superfences:\n      custom_fences:\n      - name: mermaid\n        class: mermaid\n        format: !!python/name:pymdownx.superfences.fence_code_format\n  - pymdownx.tabbed:\n      alternate_style: true\n  - pymdownx.tilde\n</code></pre></li> </ol>"},{"location":"documentation/MkDocs/theme/#3-test-the-configuration","title":"3. Test the Configuration","text":"<ol> <li>Serve the documentation locally:       <pre><code>mkdocs serve\n</code></pre></li> <li>Open your browser and navigate to <code>http://127.0.0.1:8000</code> to verify the changes.</li> </ol>"},{"location":"documentation/MkDocs/theme/#4-customize-further","title":"4. Customize Further","text":"<ul> <li>Add custom CSS or JavaScript files for additional styling or functionality.</li> <li>Update the [docs] folder with your content, using the configured features and extensions.</li> </ul>"},{"location":"documentation/MkDocs/theme/#examples","title":"Examples","text":"<ul> <li>Add Code Annotation:      <pre><code># Example of annotated code\ndef greet(name):\n    \"\"\"Greets the user by name.\"\"\"\n    return f\"Hello, {name}!\"\n</code></pre></li> <li>Use Mermaid Diagrams:      <pre><code>graph TD;\n    A--&gt;B;\n    A--&gt;C;\n    B--&gt;D;\n    C--&gt;D;</code></pre></li> </ul>"},{"location":"documentation/MkDocs/theme/#resources","title":"Resources","text":"<ul> <li>MkDocs Official Documentation</li> <li>MkDocs Material Documentation</li> <li>Pymdown Extensions Documentation</li> </ul>"},{"location":"documentation/MkDocs/theme/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Issue: Features not applied.      Resolution: Ensure the <code>features</code> section is correctly configured in [mkdocs.yml].</li> <li>Issue: Extensions not working.      Resolution: Verify the <code>markdown_extensions</code> section in [mkdocs.yml] and ensure all dependencies are installed.</li> <li>Issue: Local server not accessible.      Resolution: Check if the port <code>8000</code> is open and not blocked by a firewall.</li> </ul> <p>Generated using AI </p>"},{"location":"documentation/Server/configuration/","title":"Configuration","text":""},{"location":"documentation/Server/configuration/#configuration","title":"Configuration","text":""},{"location":"documentation/Server/installation/","title":"Installation","text":""},{"location":"documentation/Server/installation/#installation","title":"Installation","text":""},{"location":"documentation/Server/Software/start-stop_script/","title":"Start stop script","text":"<p>\\(timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\" Add-Content -Path \"\\)PSScriptRoot\\Start-Stop_Docker_n8n.log\" -Value \"[$timestamp] n8n server starting...\"</p>"},{"location":"documentation/Server/Software/start-stop_script/#set-working-directory-to-the-scripts-location","title":"Set working directory to the script's location","text":"<p>Set-Location -Path $PSScriptRoot</p>"},{"location":"documentation/Server/Software/start-stop_script/#stop-and-remove-existing-container","title":"Stop and remove existing container","text":"<p>docker stop n8n docker rm n8n</p>"},{"location":"documentation/Server/Software/start-stop_script/#generate-timestamped-backup-filename","title":"Generate timestamped backup filename","text":"<p>$backupDir = \"C:\\STORAGE\\STORAGE.BACKUP\\DOCKER_Volumes\" $backupTimestamp = Get-Date -Format \"yyyyMMdd_HHmmss\" \\(backupFile = \"n8n_data_backup_\\)backupTimestamp.tar.gz\"</p>"},{"location":"documentation/Server/Software/start-stop_script/#create-backup-directory-if-it-doesnt-exist","title":"Create backup directory if it doesn't exist","text":"<p>if (-not (Test-Path $backupDir)) {     New-Item -Path $backupDir -ItemType Directory | Out-Null }</p> <p>\\(containerCommand = \"tar czvf /backup/\\)backupFile -C /data .\"</p>"},{"location":"documentation/Server/Software/start-stop_script/#create-backup-using-temporary-alpine-container","title":"Create backup using temporary alpine container","text":"<p>docker run --rm <code>-v n8n_data:/data</code>     -v \"\\({backupDir}:/backup\" <code>alpine</code>     sh -c \"\\)containerCommand\"</p>"},{"location":"documentation/Server/Software/start-stop_script/#update-n8n-image","title":"Update n8n image","text":"<p>docker pull n8nio/n8n:latest docker pull alpine:latest</p>"},{"location":"documentation/Server/Software/start-stop_script/#start-container-again","title":"Start container again","text":"<p>docker run -d <code>--name n8n</code>   --restart unless-stopped <code>--env-file C:\\Users\\Administrator\\.docker\\n8n-config.env</code>   -p 5678:5678 <code>-v n8n_data:/home/node/.n8n</code>   n8nio/n8n:latest</p>"},{"location":"documentation/Server/Software/Docker%20Desktop/Volumes/backup/","title":"Backup","text":"<p>docker run --rm \\   -v n8n_data:/data \\   -v $(pwd):/backup \\   alpine \\   tar czvf /backup/n8n_data_backup.tar.gz -C /data .</p>"},{"location":"documentation/Server/Software/Docker%20Desktop/Volumes/restore/","title":"Restore","text":"<p>docker run --rm \\   -v n8n_data:/data \\   -v $(pwd):/backup \\   alpine \\   sh -c \"cd /data &amp;&amp; tar xzvf /backup/n8n_data_backup.tar.gz\"</p>"},{"location":"howto/cmd/docker.exe/","title":"Docker.exe","text":"<p>A self-sufficient runtime for containers</p> <p>Common Commands:   run         Create and run a new container from an image   exec        Execute a command in a running container   ps          List containers   build       Build an image from a Dockerfile   bake        Build from a file   pull        Download an image from a registry   push        Upload an image to a registry   images      List images   login       Authenticate to a registry   logout      Log out from a registry   search      Search Docker Hub for images   version     Show the Docker version information   info        Display system-wide information</p> <p>Management Commands:   ai         Docker AI Agent - Ask Gordon   builder     Manage builds   buildx     Docker Buildx   cloud      Docker Cloud   compose    Docker Compose   container   Manage containers   context     Manage contexts   debug      Get a shell into any image or container   desktop    Docker Desktop commands   extension  Manages Docker extensions   image       Manage images   init       Creates Docker-related starter files for your project   manifest    Manage Docker image manifests and manifest lists   mcp        Docker MCP Plugin   model      Docker Model Runner   network     Manage networks   plugin      Manage plugins   sbom       View the packaged-based Software Bill Of Materials (SBOM) for an image   scout      Docker Scout   system      Manage Docker   trust       Manage trust on Docker images   volume      Manage volumes</p> <p>Swarm Commands:   swarm       Manage Swarm</p> <p>Commands:   attach      Attach local standard input, output, and error streams to a running container   commit      Create a new image from a container's changes   cp          Copy files/folders between a container and the local filesystem   create      Create a new container   diff        Inspect changes to files or directories on a container's filesystem   events      Get real time events from the server   export      Export a container's filesystem as a tar archive   history     Show the history of an image   import      Import the contents from a tarball to create a filesystem image   inspect     Return low-level information on Docker objects   kill        Kill one or more running containers   load        Load an image from a tar archive or STDIN   logs        Fetch the logs of a container   pause       Pause all processes within one or more containers   port        List port mappings or a specific mapping for the container   rename      Rename a container   restart     Restart one or more containers   rm          Remove one or more containers   rmi         Remove one or more images   save        Save one or more images to a tar archive (streamed to STDOUT by default)   start       Start one or more stopped containers   stats       Display a live stream of container(s) resource usage statistics   stop        Stop one or more running containers   tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE   top         Display the running processes of a container   unpause     Unpause all processes within one or more containers   update      Update configuration of one or more containers   wait        Block until one or more containers stop, then print their exit codes</p> <p>Global Options:       --config string      Location of client config files (default                            \"C:\\Users\\Administrator\\.docker\")   -c, --context string     Name of the context to use to connect to the                            daemon (overrides DOCKER_HOST env var and                            default context set with \"docker context use\")   -D, --debug              Enable debug mode   -H, --host list          Daemon socket to connect to   -l, --log-level string   Set the logging level (\"debug\", \"info\",                            \"warn\", \"error\", \"fatal\") (default \"info\")       --tls                Use TLS; implied by --tlsverify       --tlscacert string   Trust certs signed only by this CA (default                            \"C:\\Users\\Administrator\\.docker\\ca.pem\")       --tlscert string     Path to TLS certificate file (default                            \"C:\\Users\\Administrator\\.docker\\cert.pem\")       --tlskey string      Path to TLS key file (default                            \"C:\\Users\\Administrator\\.docker\\key.pem\")       --tlsverify          Use TLS and verify the remote   -v, --version            Print version information and quit</p> <p>Run 'docker COMMAND --help' for more information on a command.</p> <p>For more help on how to use Docker, head to https://docs.docker.com/go/guides/</p>"},{"location":"howto/cmd/manage-bde.exe/","title":"Manage bde.exe","text":"<p>BitLocker Drive Encryption: Configuration Tool version 10.0.26100 Copyright (C) 2013 Microsoft Corporation. All rights reserved.</p> <p>manage-bde[.exe] -parameter [arguments]</p> <p>Description:     Configures BitLocker Drive Encryption on disk volumes.</p> <p>Parameter List:     -status     Provides information about BitLocker-capable volumes.     -on         Encrypts the volume and turns BitLocker protection on.     -off        Decrypts the volume and turns BitLocker protection off.     -pause      Pauses encryption, decryption, or free space wipe.     -resume     Resumes encryption, decryption, or free space wipe.     -lock       Prevents access to BitLocker-encrypted data.     -unlock     Allows access to BitLocker-encrypted data.     -autounlock Manages automatic unlocking of data volumes.     -protectors Manages protection methods for the encryption key.     -SetIdentifier or -si                 Configures the identification field for a volume.     -ForceRecovery or -fr                 Forces a BitLocker-protected OS to recover on restarts.     -changepassword                 Modifies password for a data volume.     -changepin  Modifies PIN for a volume.     -changekey  Modifies startup key for a volume.     -KeyPackage or -kp                 Generates a key package for a volume.     -upgrade    Upgrades the BitLocker version.     -WipeFreeSpace or -w                 Wipes the free space on the volume.     -ComputerName or -cn                 Runs on another computer. Examples: \"ComputerX\", \"127.0.0.1\"     -? or /?    Displays brief help. Example: \"-ParameterSet -?\"     -Help or -h Displays complete help. Example: \"-ParameterSet -h\"</p> <p>Examples:     manage-bde -status     manage-bde -on C: -RecoveryPassword -RecoveryKey F:\\     manage-bde -unlock E: -RecoveryKey F:\\84E151C1...7A62067A512.bek</p>"},{"location":"howto/cmd/mklink.exe/","title":"Mklink.exe","text":"<p>Creates a symbolic link.</p> <p>MKLINK [[/D] | [/H] | [/J]] Link Target</p> <pre><code>    /D      Creates a directory symbolic link.  Default is a file\n            symbolic link.\n    /H      Creates a hard link instead of a symbolic link.\n    /J      Creates a Directory Junction.\n    Link    Specifies the new symbolic link name.\n    Target  Specifies the path (relative or absolute) that the new link\n            refers to.\n</code></pre>"},{"location":"howto/cmd/w32tm.exe/","title":"W32tm.exe","text":"<p>w32tm [/? | /register | /unregister ]   ? - this help screen.   register - register to run as a service and add default     configuration to the registry.   unregister - unregister service and remove all configuration     information from the registry.</p> <p>w32tm /monitor [/domain:]                [/computers:[,[,...]]]                [/threads:] [/ipprotocol:&lt;4|6&gt;] [/nowarn]   domain - specifies which domain to monitor. If no domain name     is given, or neither the domain nor computers option is     specified, the default domain is used. This option may be     used more than once.   computers - monitors the given list of computers. Computer    names are separated by commas, with no spaces. If a name is     prefixed with a '*', it is treated as an AD PDC. This option     may be used more than once.   threads - how many computers to analyze simultaneously. The     default value is 3. Allowed range is 1-50.   ipprotocol - specify the IP protocol to use. The default is     to use whatever is available.   nowarn - skip warning message.</p> <p>w32tm /ntte    Convert a NT system time, in (10^-7)s intervals from 0h 1-Jan 1601,   into a readable format.</p> <p>w32tm /ntpte    Convert an NTP time, in (2^-32)s intervals from 0h 1-Jan 1900, into   a readable format.</p> <p>w32tm /resync [/computer:] [/nowait] [/rediscover] [/soft]   Tell a computer that it should resynchronize its clock as soon   as possible, throwing out all accumulated error statistics.   computer: - computer that should resync. If not     specified, the local computer will resync.   nowait - do not wait for the resync to occur;     return immediately. Otherwise, wait for the resync to     complete before returning.   rediscover - redetect the network configuration and rediscover     network sources, then resynchronize.   soft - resync utilizing existing error statistics. Not useful,     provided for compatibility.</p> <p>w32tm /stripchart /computer: [/period:]     [/dataonly] [/samples:] [/packetinfo] [/ipprotocol:&lt;4|6&gt;] [/rdtsc]   Display a strip chart of the offset between this computer and   another computer.   computer: - the computer to measure the offset against.   period: - the time between samples, in seconds. The     default is 2s   dataonly - display only the data, no graphics.   samples: - collect  samples, then stop. If not     specified, samples will be collected until Ctrl-C is pressed.   packetinfo - print out NTP packet response message.   ipprotocol - specify the IP protocol to use. The default is      to use whatever is available.   rdtsc - display the TSC values and time offset data in CSV format.     The output displays TSC and FILETIME values captured before the      NTP request is sent, TSC value after an NTP response is received     along with NTP roundtrip and time offset values.</p> <p>w32tm /config [/computer:] [/update]     [/manualpeerlist:] [/syncfromflags:]     [/LocalClockDispersion:]     [/reliable:(YES|NO)]     [/largephaseoffset:]   computer: - adjusts the configuration of . If not     specified, the default is the local computer.   update - notifies the time service that the configuration has     changed, causing the changes to take effect.   manualpeerlist: - sets the manual peer list to ,     which is a space-delimited list of DNS and/or IP addresses.     When specifying multiple peers, this switch must be enclosed in     quotes.   syncfromflags: - sets what sources the NTP client should     sync from.  should be a comma separated list of     these keywords (not case sensitive):       MANUAL - sync from peers in the manual peer list       DOMHIER - sync from an AD DC in the domain hierarchy       NO - sync from none       ALL - sync from both manual and domain peers    LocalClockDispersion: - configures the accuracy of the     internal clock that w32time will assume when it can't acquire      time from its configured sources.   reliable:(YES|NO) - set whether this machine is a reliable time source.     This setting is only meaningful on domain controllers.       YES - this machine is a reliable time service       NO - this machine is not a reliable time service   largephaseoffset: - sets the time difference between      local and network time which w32time will consider a spike.  </p> <p>w32tm /tz   Display the current time zone settings.</p> <p>w32tm /dumpreg [/subkey:] [/computer:]   Display the values associated with a given registry key.   The default key is HKLM\\System\\CurrentControlSet\\Services\\W32Time     (the root key for the time service).   subkey: - displays the values associated with subkey       of the default key.   computer: - queries registry settings for computer .</p> <p>w32tm /query [/computer:]      {/source | /configuration | /peers | /status}      [/verbose]   Display a computer's windows time service information.   computer: - query the information of . If not     specified, the default is the local computer.   source: display the time source.   configuration: display the configuration of run-time and where      the setting comes from. In verbose mode, display the undefined      or unused setting too.   peers: display a list of peers and their status.   status: display windows time service status.   verbose: set the verbose mode to display more information.</p> <p>w32tm /debug {/disable | {/enable /file: /size: /entries:     [/truncate]}}   Enable or disable local computer windows time service private log.   disable: disable the private log.   enable: enable the private log.     file: - specify the absolute filename.     size: - specify the maximum size for circular logging.     entries: - contains a list of flags, specified by number and       separated by commas, that specify the types of information that        should be logged. Valid numbers are 0 to 300. A range of numbers        is valid, in addition to single numbers, such as 0-100,103,106.        Value 0-300 is for logging all information.   truncate: truncate the file if it exists.</p> <p>w32tm /leapseconds /getstatus [/verbose]   Display the status of leap seconds on the local machine.   verbose: Set the verbose mode to display more information.</p> <p>w32tm /ptp_monitor [/duration:]   Monitor the network for PTP traffic and print the status.   This command communicates through PTP UDP ports 319 and 320 on all network interfaces of the local machine   and uses PTP provider registry settings for comparison purposes or as defaults.   Please ensure firewall and PTP settings are in place and PTP time provider is stopped before running this command.   duration: Specifies the monitoring duration or defaults to 90 seconds.</p> <p>Info</p> <pre><code>w32tm /config /manualpeerlist:\"time.google.com\" /syncfromflags:manual /reliable:yes /update\n</code></pre>"},{"location":"howto/powershell/learn%20about%20this%20picture/","title":"Learn about this picture","text":"<pre><code>Windows Registry Editor Version 5.00\n\n[-HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Desktop\\NameSpace\\{2cc5ca98-6485-489a-920e-b3e88a6ccce3}]\n\n[HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\HideDesktopIcons\\NewStartPanel]\n\"{2cc5ca98-6485-489a-920e-b3e88a6ccce3}\"=dword:00000001\n</code></pre> <pre><code>$namespaceKey = \"HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Desktop\\NameSpace\\{2cc5ca98-6485-489a-920e-b3e88a6ccce3}\"\nif (Test-Path $namespaceKey) {\n    Remove-Item -Path $namespaceKey -Recurse -Force\n    Write-Output \"Verwijderd: $namespaceKey\"\n} else {\n    Write-Output \"Sleutel niet gevonden: $namespaceKey\"\n}\n\n$hideIconsKey = \"HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\HideDesktopIcons\\NewStartPanel\"\nif (-not (Test-Path $hideIconsKey)) {\n    New-Item -Path $hideIconsKey -Force | Out-Null\n    Write-Output \"Aangemaakt: $hideIconsKey\"\n}\n\nNew-ItemProperty -Path $hideIconsKey -Name \"{2cc5ca98-6485-489a-920e-b3e88a6ccce3}\" -PropertyType DWORD -Value 1 -Force\nWrite-Output \"DWORD toegevoegd: {2cc5ca98-6485-489a-920e-b3e88a6ccce3} = 1\"\n</code></pre> <p>https://learn.microsoft.com/en-us/answers/questions/2157455/how-to-remove-a-persistent-shortcut-learn-about-th</p>"},{"location":"howto/powershell/product%20key/","title":"Product key","text":"<p>Run Powershell Command</p> <p>Open Powershell and type the command listed below</p> <p>Old method</p> <p></p><pre><code>powershell \"(Get-WmiObject -query 'select * from SoftwareLicensingService').OA3xOriginalProductKey\"\n</code></pre> Hit - Enter : your Windows product key will show up in the - PowerShell window Note : I suggest to : Copy+Paste the above, code into the blue - Powershell Command as (Admin) and press - Enter <p>New method</p> <p></p><pre><code>(Get-CimInstance -query 'select * from SoftwareLicensingService').OA3xOriginalProductKey\n</code></pre> Hit - Enter : your Windows product key will show up in the - PowerShell window Note : I suggest to : Copy+Paste the above, code into the blue - Powershell Command as (Admin) and press - Enter <p>Alternative method</p> <pre><code>Set WshShell = CreateObject(\"WScript.Shell\")\nMsgBox ConvertToKey(WshShell.RegRead(\"HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\DigitalProductId\"))\n\nFunction ConvertToKey(Key)\n    Const KeyOffset = 52\n    i = 28\n    Chars = \"BCDFGHJKMPQRTVWXY2346789\"\n    Do\n        Cur = 0\n        x = 14\n        Do\n            Cur = Cur * 256\n            Cur = Key(x + KeyOffset) + Cur\n            Key(x + KeyOffset) = (Cur \\ 24) And 255\n            Cur = Cur Mod 24\n            x = x -1\n        Loop While x &gt;= 0\n        i = i -1\n        KeyOutput = Mid(Chars, Cur + 1, 1) &amp; KeyOutput\n        If (((29 - i) Mod 6) = 0) And (i &lt;&gt; -1) Then\n            i = i -1\n            KeyOutput = \"-\" &amp; KeyOutput\n        End If\n    Loop While i &gt;= 0\n    ConvertToKey = KeyOutput\nEnd Function\n</code></pre> <p>Installing PowerShell on Windows</p>"},{"location":"tutorials/all_public_functions/","title":"Developing and Documenting Public Python Functions","text":""},{"location":"tutorials/all_public_functions/#developing-and-documenting-public-python-functions","title":"Developing and Documenting Public Python Functions","text":""},{"location":"tutorials/all_public_functions/#introduction","title":"Introduction","text":"<p>In software development, especially when creating libraries, modules, or reusable components, public functions serve as the primary interface for users to interact with your code. These functions are part of the public API (Application Programming Interface) and are designed to be used by other parts of your application or by external developers.</p> <p>This tutorial guides you through the process of designing, implementing, and most importantly, documenting public functions effectively in Python. Mastering this skill ensures your code is not only functional but also intuitive, easy to use, and maintainable for anyone consuming it.</p>"},{"location":"tutorials/all_public_functions/#overview","title":"Overview","text":"<p>The challenge with creating reusable code lies in its accessibility and clarity. Without proper structure and documentation, even the most robust functions can become a burden to use and understand. This leads to:</p> <ul> <li>Confusion: Users struggle to understand what a function does, its parameters, or what it returns.</li> <li>Misuse: Functions are used incorrectly, leading to bugs or unexpected behavior.</li> <li>Maintenance Overhead: Developers spend more time deciphering existing code than writing new features.</li> <li>Limited Adoption: Your well-crafted code goes unused because it's too difficult to integrate.</li> </ul> <p>This tutorial addresses these problems by demonstrating best practices for defining public functions, emphasizing the critical role of docstrings and type hints in making your code self-documenting and user-friendly.</p>"},{"location":"tutorials/all_public_functions/#prerequisites","title":"Prerequisites","text":"<p>Before you begin this tutorial, ensure you have the following:</p> <ul> <li>Python 3.6+: Installed on your system. You can download it from python.org.</li> <li>Basic Python Knowledge: Familiarity with Python syntax, functions, and modules.</li> <li>Text Editor or IDE: Such as VS Code, PyCharm, or Sublime Text.</li> <li>Command Line Interface (CLI): Basic understanding of navigating directories and executing Python scripts.</li> </ul>"},{"location":"tutorials/all_public_functions/#execution","title":"Execution","text":"<p>Follow these steps to create and document your first public Python function.</p>"},{"location":"tutorials/all_public_functions/#step-1-set-up-your-project-directory","title":"Step 1: Set Up Your Project Directory","text":"<p>First, create a new directory for your project and navigate into it.</p> <pre><code>mkdir public_functions_tutorial\ncd public_functions_tutorial\n</code></pre>"},{"location":"tutorials/all_public_functions/#step-2-create-a-module-with-a-public-function","title":"Step 2: Create a Module with a Public Function","text":"<p>We will create a file named <code>shapes.py</code> that will contain our public function for calculating the area of a rectangle.</p> <p>Create a file named <code>shapes.py</code> in your <code>public_functions_tutorial</code> directory and add the following content:</p> <pre><code># shapes.py\n\ndef calculate_rectangle_area(length: float, width: float) -&gt; float:\n    \"\"\"\n    Calculate the area of a rectangle.\n\n    This function takes the length and width of a rectangle\n    and returns its area.\n\n    Args:\n        length (float): The length of the rectangle.\n        width (float): The width of the rectangle.\n\n    Returns:\n        float: The calculated area of the rectangle.\n\n    Raises:\n        ValueError: If length or width is negative.\n\n    Examples:\n        &gt;&gt;&gt; calculate_rectangle_area(5, 10)\n        50.0\n        &gt;&gt;&gt; calculate_rectangle_area(7.5, 2.0)\n        15.0\n    \"\"\"\n    if length &lt; 0 or width &lt; 0:\n        raise ValueError(\"Length and width must be non-negative values.\")\n    return length * width\n\n# This function is considered 'private' by convention\n# because its name starts with an underscore.\ndef _private_helper_function(value: float) -&gt; float:\n    \"\"\"A helper function not intended for public use.\"\"\"\n    return value * 2\n</code></pre> <p>Docstring Standards</p> <p>The example above uses the Google Style Docstring format, which is highly readable and widely adopted. Other popular formats include reStructuredText (used by Sphinx) and NumPy style. Choose one and stick to it for consistency.</p>"},{"location":"tutorials/all_public_functions/#understanding-the-code","title":"Understanding the Code:","text":"<ul> <li>Function Naming: <code>calculate_rectangle_area</code> follows Python's PEP 8 guidelines for function names (lowercase, words separated by underscores). Public functions should have clear, descriptive names.</li> <li>Docstring: This multi-line string immediately after the function signature is crucial. It describes what the function does, its arguments (<code>Args</code>), what it returns (<code>Returns</code>), potential errors (<code>Raises</code>), and usage examples (<code>Examples</code>).</li> <li>Type Hints (<code>: float</code>, <code>-&gt; float</code>): These provide static type information, making the code easier to understand and enabling static analysis tools (like MyPy) to catch potential type-related errors.</li> <li>Error Handling: The <code>ValueError</code> demonstrates how to handle invalid inputs gracefully, providing clear feedback to the user.</li> <li>Private Functions: The <code>_private_helper_function</code> demonstrates a convention where functions prefixed with an underscore (<code>_</code>) are considered internal to the module and not part of the public API.</li> </ul>"},{"location":"tutorials/all_public_functions/#step-3-use-the-public-function","title":"Step 3: Use the Public Function","text":"<p>Now, let's create a script to import and use our public function. Create a file named <code>main.py</code> in the same directory:</p> <pre><code># main.py\nimport shapes\n\ndef run_example():\n    \"\"\"Demonstrates how to use the calculate_rectangle_area function.\"\"\"\n    print(\"--- Using calculate_rectangle_area ---\")\n\n    # Valid usage\n    length = 5\n    width = 10\n    area = shapes.calculate_rectangle_area(length, width)\n    print(f\"The area of a rectangle with length {length} and width {width} is: {area}\")\n\n    # Another valid usage\n    length = 7.5\n    width = 2.0\n    area = shapes.calculate_rectangle_area(length, width)\n    print(f\"The area of a rectangle with length {length} and width {width} is: {area}\")\n\n    # Invalid usage (demonstrates error handling)\n    print(\"\\n--- Demonstrating error handling ---\")\n    try:\n        shapes.calculate_rectangle_area(-1, 5)\n    except ValueError as e:\n        print(f\"Caught an expected error: {e}\")\n\n    # Attempting to use a \"private\" function (discouraged)\n    print(\"\\n--- Attempting to use a 'private' function (discouraged) ---\")\n    result = shapes._private_helper_function(10)\n    print(f\"Result from _private_helper_function: {result}\")\n\nif __name__ == \"__main__\":\n    run_example()\n</code></pre>"},{"location":"tutorials/all_public_functions/#step-4-run-the-script","title":"Step 4: Run the Script","text":"<p>Execute the <code>main.py</code> script from your terminal:</p> <pre><code>python main.py\n</code></pre>"},{"location":"tutorials/all_public_functions/#validation","title":"Validation","text":"<p>After running the <code>main.py</code> script, verify the output and explore the function's documentation.</p>"},{"location":"tutorials/all_public_functions/#check-console-output","title":"Check Console Output","text":"<p>Your console output should look similar to this:</p> <pre><code>--- Using calculate_rectangle_area ---\nThe area of a rectangle with length 5 and width 10 is: 50.0\nThe area of a rectangle with length 7.5 and width 2.0 is: 15.0\n\n--- Demonstrating error handling ---\nCaught an expected error: Length and width must be non-negative values.\n\n--- Attempting to use a 'private' function (discouraged) ---\nResult from _private_helper_function: 20.0\n</code></pre> <p>This confirms that: 1.  The <code>calculate_rectangle_area</code> function correctly computes the area for valid inputs. 2.  The <code>ValueError</code> is raised and caught as expected for invalid inputs. 3.  The \"private\" function can technically be called, but its usage is discouraged.</p>"},{"location":"tutorials/all_public_functions/#inspecting-documentation","title":"Inspecting Documentation","text":"<p>Python's built-in <code>help()</code> function is invaluable for inspecting the documentation of modules, classes, and functions.</p> <p>Open a Python interactive shell in the same directory:</p> <pre><code>python\n</code></pre> <p>Now, import your <code>shapes</code> module and use <code>help()</code>:</p> <pre><code>&gt;&gt;&gt; import shapes\n&gt;&gt;&gt; help(shapes.calculate_rectangle_area)\n</code></pre> <p>You should see the beautifully formatted docstring displayed, making it easy to understand the function's purpose, parameters, return value, and examples:</p> <pre><code>Help on function calculate_rectangle_area in module shapes:\n\ncalculate_rectangle_area(length: float, width: float) -&gt; float\n    Calculate the area of a rectangle.\n\n    This function takes the length and width of a rectangle\n    and returns its area.\n\n    Args:\n        length (float): The length of the rectangle.\n        width (float): The width of the rectangle.\n\n    Returns:\n        float: The calculated area of the rectangle.\n\n    Raises:\n        ValueError: If length or width is negative.\n\n    Examples:\n        &gt;&gt;&gt; calculate_rectangle_area(5, 10)\n        50.0\n        &gt;&gt;&gt; calculate_rectangle_area(7.5, 2.0)\n        15.0\n</code></pre> <p>This live documentation is a direct benefit of writing clear docstrings and is one of the most powerful tools for developers using your public functions.</p>"},{"location":"tutorials/all_public_functions/#tearing-down","title":"Tearing Down","text":"<p>To clean up the resources created during this tutorial, simply remove the <code>public_functions_tutorial</code> directory:</p> <pre><code>cd ..\nrm -rf public_functions_tutorial\n</code></pre>"},{"location":"tutorials/all_public_functions/#conclusion","title":"Conclusion","text":"<p>Developing and documenting public functions effectively is a cornerstone of writing high-quality, maintainable, and reusable code. By following the practices outlined in this tutorial, you can ensure your Python modules and libraries are a pleasure for others to use.</p> <p>Key takeaways:</p> <ul> <li>Descriptive Naming: Give your functions clear, unambiguous names that convey their purpose.</li> <li>Comprehensive Docstrings: Every public function must have a docstring that explains its purpose, parameters, return values, and any exceptions it might raise. Use a consistent style (e.g., Google, reStructuredText, NumPy).</li> <li>Type Hints: Use type hints to improve readability, enable static analysis, and clearly define the expected types of arguments and return values.</li> <li>Error Handling: Implement robust error handling to guide users when they provide invalid input.</li> <li>Public vs. Private: Distinguish between public API functions and internal helper functions (often by convention using a leading underscore <code>_</code>).</li> </ul> <p>By adhering to these principles, you contribute to a more collaborative and efficient development ecosystem. ```</p>"},{"location":"tutorials/cloudconvert/","title":"Integrating the Cloud Convert API","text":""},{"location":"tutorials/cloudconvert/#integrating-the-cloud-convert-api","title":"Integrating the Cloud Convert API","text":""},{"location":"tutorials/cloudconvert/#introduction","title":"Introduction","text":"<p>In today's digital landscape, the ability to convert files between different formats is a common requirement for many applications. Whether it's transforming documents, images, audio, or video, a robust conversion solution is invaluable. The Cloud Convert API provides a powerful, cloud-based service that handles a vast array of file conversions, abstracting away the complexities of format specifics and conversion engines.</p> <p>This tutorial will guide you through the process of integrating and utilizing the Cloud Convert API to perform a common file conversion task: converting a PDF document into a set of JPG images. We will use Python for our examples, demonstrating how to interact with the API to create jobs, manage tasks, and retrieve converted files.</p>"},{"location":"tutorials/cloudconvert/#overview","title":"Overview","text":"<p>The problem this tutorial addresses is the need for programmatic file conversion without managing local conversion software or complex libraries. Traditional approaches often involve:</p> <ul> <li>Installing and maintaining specialized software for each file type (e.g., ImageMagick for images, FFmpeg for video, LibreOffice for documents).</li> <li>Handling diverse file formats and their unique parsing requirements.</li> <li>Scaling conversion processes for high volumes.</li> <li>Dealing with security considerations of executing third-party tools.</li> </ul> <p>The Cloud Convert API solves these challenges by offering:</p> <ul> <li>Broad Format Support: Converts virtually any file format (over 200 different formats).</li> <li>Cloud-Based Processing: Offloads conversion tasks to powerful cloud servers, freeing up your local resources.</li> <li>Simple RESTful Interface: Easy to integrate using standard HTTP requests and JSON responses.</li> <li>Scalability: Designed to handle high-volume conversions efficiently.</li> <li>Reliability: Managed service ensures conversions are performed consistently.</li> </ul> <p>By following this guide, you will learn how to leverage these benefits to seamlessly integrate file conversion capabilities into your applications.</p>"},{"location":"tutorials/cloudconvert/#prerequisites","title":"Prerequisites","text":"<p>Before you begin this tutorial, ensure you have the following:</p> <ul> <li>Cloud Convert Account and API Key: You will need an API key to authenticate your requests. You can register for free and obtain your key from the Cloud Convert Dashboard.</li> <li>Python 3.6+: Installed on your system. You can download it from python.org.</li> <li><code>requests</code> Python Library: For making HTTP requests. Install it via pip:     <pre><code>pip install requests\n</code></pre></li> <li>Basic Understanding of REST APIs: Familiarity with HTTP methods (GET, POST), request headers, and JSON data formats.</li> <li>Text Editor or IDE: Such as VS Code, PyCharm, or Sublime Text.</li> </ul>"},{"location":"tutorials/cloudconvert/#execution","title":"Execution","text":"<p>Let's walk through the steps to convert a remote PDF file into JPG images using the Cloud Convert API.</p>"},{"location":"tutorials/cloudconvert/#step-1-obtain-your-cloud-convert-api-key","title":"Step 1: Obtain Your Cloud Convert API Key","text":"<p>If you haven't already, sign up for a Cloud Convert account at cloudconvert.com. Once logged in, navigate to your API dashboard to find your API key. It typically starts with <code>eyJ...</code>. Keep this key secure.</p>"},{"location":"tutorials/cloudconvert/#step-2-set-up-your-project","title":"Step 2: Set Up Your Project","text":"<p>Create a new directory for your project and a Python file (e.g., <code>convert_pdf_to_jpg.py</code>).</p> <pre><code>mkdir cloudconvert_tutorial\ncd cloudconvert_tutorial\ntouch convert_pdf_to_jpg.py\n</code></pre>"},{"location":"tutorials/cloudconvert/#step-3-define-api-credentials-and-base-url","title":"Step 3: Define API Credentials and Base URL","text":"<p>Open <code>convert_pdf_to_jpg.py</code> and add your API key and the API base URL.</p> <pre><code># convert_pdf_to_jpg.py\nimport requests\nimport json\nimport time\nimport os\n\n# --- Configuration ---\nAPI_KEY = \"YOUR_CLOUD_CONVERT_API_KEY\"  # Replace with your actual API Key\nAPI_BASE_URL = \"https://api.cloudconvert.com/v2\"\n# Example remote PDF URL - feel free to replace with another publicly accessible PDF\nSOURCE_PDF_URL = \"https://www.africau.edu/images/default/sample.pdf\"\nOUTPUT_DIRECTORY = \"converted_files\"\n\n# Ensure output directory exists\nos.makedirs(OUTPUT_DIRECTORY, exist_ok=True)\n\nprint(\"Cloud Convert API Integration Tutorial\")\nprint(\"-\" * 40)\n\n# Headers for API requests\nheaders = {\n    \"Authorization\": f\"Bearer {API_KEY}\",\n    \"Content-Type\": \"application/json\",\n    \"Accept\": \"application/json\"\n}\n</code></pre> <p>API Key Security</p> <p>Never hardcode your API key directly in production code or commit it to version control. Use environment variables or a secure configuration management system. For this tutorial, we're hardcoding it for simplicity, but be mindful of security best practices.</p>"},{"location":"tutorials/cloudconvert/#step-4-create-a-job","title":"Step 4: Create a Job","text":"<p>All conversions in Cloud Convert are managed through \"Jobs.\" A job is a container for one or more tasks. First, we create an empty job.</p> <pre><code># --- Step 1: Create a Job ---\nprint(\"1. Creating a new job...\")\ncreate_job_url = f\"{API_BASE_URL}/jobs\"\ncreate_job_payload = {\n    \"tasks\": {\n        # Tasks will be added dynamically later\n    }\n}\n\ntry:\n    response = requests.post(create_job_url, headers=headers, json=create_job_payload)\n    response.raise_for_status()  # Raise an exception for HTTP errors\n    job_data = response.json().get(\"data\")\n    job_id = job_data.get(\"id\")\n    print(f\"   Job created successfully. Job ID: {job_id}\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"   Error creating job: {e}\")\n    if hasattr(e, 'response') and e.response is not None:\n        print(f\"   Response: {e.response.text}\")\n    exit() # Exit if job creation fails\n</code></pre>"},{"location":"tutorials/cloudconvert/#step-5-add-tasks-to-the-job","title":"Step 5: Add Tasks to the Job","text":"<p>Now, we add tasks to our newly created job. For PDF to JPG conversion, we need two main tasks:</p> <ol> <li><code>import/url</code> task: To fetch the PDF from the provided URL.</li> <li><code>convert</code> task: To convert the imported PDF into JPG images.</li> <li><code>export/url</code> task: To make the converted files available for download via a URL.</li> </ol> <pre><code># --- Step 2: Add Tasks to the Job ---\nprint(\"\\n2. Adding tasks to the job...\")\ntasks_url = f\"{API_BASE_URL}/jobs/{job_id}/tasks\"\n\n# 2a. Import Task (fetching the PDF from URL)\nimport_task_name = \"import-pdf\"\nimport_task_payload = {\n    \"name\": import_task_name,\n    \"operation\": \"import/url\",\n    \"url\": SOURCE_PDF_URL\n}\ntry:\n    response = requests.post(tasks_url, headers=headers, json=import_task_payload)\n    response.raise_for_status()\n    print(f\"   Import task '{import_task_name}' added.\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"   Error adding import task: {e}\")\n    if hasattr(e, 'response') and e.response is not None:\n        print(f\"   Response: {e.response.text}\")\n    exit()\n\n# 2b. Convert Task (PDF to JPG)\nconvert_task_name = \"convert-to-jpg\"\nconvert_task_payload = {\n    \"name\": convert_task_name,\n    \"operation\": \"convert\",\n    \"input\": import_task_name,  # Input from the import task\n    \"output_format\": \"jpg\",\n    \"converter_options\": {\n        \"quality\": 80,  # JPG quality (0-100)\n        \"page_range\": \"1-end\" # Convert all pages\n    }\n}\ntry:\n    response = requests.post(tasks_url, headers=headers, json=convert_task_payload)\n    response.raise_for_status()\n    print(f\"   Convert task '{convert_task_name}' added.\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"   Error adding convert task: {e}\")\n    if hasattr(e, 'response') and e.response is not None:\n        print(f\"   Response: {e.response.text}\")\n    exit()\n\n# 2c. Export Task (make JPGs downloadable)\nexport_task_name = \"export-jpg\"\nexport_task_payload = {\n    \"name\": export_task_name,\n    \"operation\": \"export/url\",\n    \"input\": convert_task_name # Input from the convert task\n}\ntry:\n    response = requests.post(tasks_url, headers=headers, json=export_task_payload)\n    response.raise_for_status()\n    print(f\"   Export task '{export_task_name}' added.\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"   Error adding export task: {e}\")\n    if hasattr(e, 'response') and e.response is not None:\n        print(f\"   Response: {e.response.text}\")\n    exit()\n</code></pre>"},{"location":"tutorials/cloudconvert/#step-6-process-the-job-and-monitor-status","title":"Step 6: Process the Job and Monitor Status","text":"<p>After adding all tasks, you need to initiate the job processing. Then, we poll the job status until it's <code>finished</code> or <code>error</code>.</p> <pre><code># --- Step 3: Start Processing the Job ---\nprint(\"\\n3. Starting job processing...\")\nprocess_job_url = f\"{API_BASE_URL}/jobs/{job_id}/process\"\ntry:\n    response = requests.post(process_job_url, headers=headers)\n    response.raise_for_status()\n    print(\"   Job initiated for processing.\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"   Error initiating job processing: {e}\")\n    if hasattr(e, 'response') and e.response is not None:\n        print(f\"   Response: {e.response.text}\")\n    exit()\n\n\n# --- Step 4: Monitor Job Status ---\nprint(\"\\n4. Monitoring job status (this may take a moment)...\")\njob_status_url = f\"{API_BASE_URL}/jobs/{job_id}\"\njob_status = None\nwhile job_status not in [\"finished\", \"error\"]:\n    try:\n        response = requests.get(job_status_url, headers=headers)\n        response.raise_for_status()\n        job_data = response.json().get(\"data\")\n        job_status = job_data.get(\"status\")\n        print(f\"   Current job status: {job_status}...\")\n        if job_status in [\"finished\", \"error\"]:\n            break\n        time.sleep(5)  # Wait 5 seconds before checking again\n    except requests.exceptions.RequestException as e:\n        print(f\"   Error checking job status: {e}\")\n        if hasattr(e, 'response') and e.response is not None:\n            print(f\"   Response: {e.response.text}\")\n        exit()\n\nif job_status == \"error\":\n    print(\"\\n   Job finished with an error. Please check the Cloud Convert dashboard for details.\")\n    exit()\n\nprint(\"\\n   Job finished successfully!\")\n</code></pre>"},{"location":"tutorials/cloudconvert/#step-7-download-the-converted-files","title":"Step 7: Download the Converted File(s)","text":"<p>Once the job is <code>finished</code>, retrieve the export task's files and download them. Since a PDF can have multiple pages, this will likely result in multiple JPG files.</p> <pre><code># --- Step 5: Download Converted Files ---\nprint(\"\\n5. Retrieving and downloading converted files...\")\n\n# Fetch the complete job data again to get task details\ntry:\n    response = requests.get(job_status_url, headers=headers)\n    response.raise_for_status()\n    job_data = response.json().get(\"data\")\n    tasks = job_data.get(\"tasks\")\n\n    export_task = next((task for task in tasks if task.get(\"name\") == export_task_name), None)\n\n    if export_task and export_task.get(\"status\") == \"finished\":\n        files = export_task.get(\"result\", {}).get(\"files\", [])\n        if not files:\n            print(\"   No files found in the export task result.\")\n\n        download_count = 0\n        for file_info in files:\n            file_url = file_info.get(\"url\")\n            file_name = file_info.get(\"filename\")\n\n            if file_url and file_name:\n                download_path = os.path.join(OUTPUT_DIRECTORY, file_name)\n                print(f\"   Downloading '{file_name}' to '{OUTPUT_DIRECTORY}'...\")\n                file_response = requests.get(file_url, stream=True)\n                file_response.raise_for_status()\n\n                with open(download_path, 'wb') as f:\n                    for chunk in file_response.iter_content(chunk_size=8192):\n                        f.write(chunk)\n                print(f\"   Downloaded: {file_name}\")\n                download_count += 1\n            else:\n                print(f\"   Warning: Skipping file due to missing URL or filename: {file_info}\")\n\n        if download_count &gt; 0:\n            print(f\"\\nSuccessfully downloaded {download_count} file(s) to '{OUTPUT_DIRECTORY}'.\")\n        else:\n            print(\"\\nNo files were downloaded.\")\n    else:\n        print(\"   Export task not found or not finished.\")\n\nexcept requests.exceptions.RequestException as e:\n    print(f\"   Error retrieving or downloading files: {e}\")\n    if hasattr(e, 'response') and e.response is not None:\n        print(f\"   Response: {e.response.text}\")\n</code></pre>"},{"location":"tutorials/cloudconvert/#step-8-run-the-script","title":"Step 8: Run the Script","text":"<p>Save the <code>convert_pdf_to_jpg.py</code> file and run it from your terminal:</p> <pre><code>python convert_pdf_to_jpg.py\n</code></pre> <p>Observe the output as the script creates the job, adds tasks, monitors progress, and finally downloads the converted JPG files.</p>"},{"location":"tutorials/cloudconvert/#validation","title":"Validation","text":"<p>After the script completes, you can validate the outcome in a few ways:</p> <ol> <li>Check Console Output:<ul> <li>Ensure the script printed \"Job finished successfully!\"</li> <li>Confirm that it reported successfully downloading files.</li> </ul> </li> <li>Inspect the Output Directory:<ul> <li>Navigate to the <code>converted_files</code> directory created by the script.</li> <li>You should find one or more <code>.jpg</code> files there, corresponding to each page of the original PDF.</li> <li>The file names will typically be derived from the original, e.g., <code>sample-0001.jpg</code>, <code>sample-0002.jpg</code>.</li> </ul> </li> <li>Open the Converted Files:<ul> <li>Open the downloaded JPG images using an image viewer.</li> <li>Verify that they correctly represent the pages of the original PDF document.</li> </ul> </li> </ol> <p>If the files are present, correctly named, and open as expected, your Cloud Convert API integration was successful!</p>"},{"location":"tutorials/cloudconvert/#tearing-down","title":"Tearing Down","text":"<p>For this tutorial, there are no persistent resources created on the Cloud Convert side that require explicit \"tearing down\" beyond the temporary job, which expires after a short period. However, for cleanup of your local machine:</p> <ol> <li>Delete the Output Directory:     <pre><code>rm -rf converted_files\n</code></pre></li> <li>Delete the Python Script:     <pre><code>rm convert_pdf_to_jpg.py\n</code></pre></li> <li>Remove the Project Directory (Optional):     <pre><code>cd ..\nrmdir cloudconvert_tutorial\n</code></pre></li> </ol> <p>Remember to keep your API key secure and revoke it from your Cloud Convert dashboard if it's compromised or no longer needed for development.</p>"},{"location":"tutorials/cloudconvert/#conclusion","title":"Conclusion","text":"<p>This tutorial has provided a practical, step-by-step guide to integrating the Cloud Convert API into your Python applications. You've learned how to:</p> <ul> <li>Obtain and use your Cloud Convert API key for authentication.</li> <li>Create a job to encapsulate your conversion process.</li> <li>Add different types of tasks (import, convert, export) to a job.</li> <li>Monitor the status of a job until completion.</li> <li>Programmatically download the converted files.</li> </ul> <p>The Cloud Convert API is incredibly versatile. Beyond this basic PDF to JPG conversion, you can explore:</p> <ul> <li>File Uploads: Instead of <code>import/url</code>, use <code>import/upload</code> for local files.</li> <li>Other Formats: Experiment with various <code>output_format</code> values (e.g., <code>docx</code> to <code>pdf</code>, <code>mp4</code> to <code>mp3</code>).</li> <li>Advanced Options: Dive into <code>converter_options</code> for specific formats (e.g., video codecs, image resizing).</li> <li>Webhooks: Get notified when a job is complete instead of polling.</li> <li>Client Libraries: For many languages, official and community-contributed client libraries exist to simplify API interactions further. Refer to the Official Cloud Convert API documentation for more details.</li> </ul> <p>By mastering the concepts covered here, you now have a powerful tool at your disposal to handle diverse file conversion needs within your projects efficiently and reliably.</p>"},{"location":"tutorials/falai/","title":"Interacting with fal.ai Public Functions","text":"","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#interacting-with-falai-public-functions","title":"Interacting with fal.ai Public Functions","text":"","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#1-introduction","title":"1. Introduction","text":"<p>Welcome to this tutorial on interacting with <code>fal.ai</code>'s public functions. <code>fal.ai</code> provides a powerful serverless platform designed for running AI models, particularly those requiring GPUs. Beyond deploying your custom functions, <code>fal.ai</code> offers a suite of pre-built, publicly accessible functions (often referred to as models) that you can readily integrate into your applications.</p> <p>This guide will walk you through the process of leveraging these public functions programmatically using the <code>fal-ai</code> Python SDK, focusing on a practical example like generating images with Stable Diffusion.</p>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#2-overview","title":"2. Overview","text":"<p>Many developers and researchers require access to state-of-the-art AI models without the overhead of managing underlying GPU infrastructure, model deployment, or scaling. This is particularly true for resource-intensive tasks such as large language model inference or complex image generation.</p> <p><code>fal.ai</code> solves this problem by providing a streamlined API to invoke these models as serverless functions. You simply send inputs, and <code>fal.ai</code> handles the execution on optimized hardware, returning the outputs. This tutorial will demonstrate how to:</p> <ul> <li>Set up your development environment.</li> <li>Authenticate with the <code>fal.ai</code> platform.</li> <li>Discover and call a public function using the <code>fal-ai</code> Python SDK.</li> <li>Process the results from the function execution.</li> </ul>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#3-prerequisites","title":"3. Prerequisites","text":"<p>Before you begin, ensure you have the following:</p> <ul> <li>Python 3.8 or newer: You can download it from python.org.</li> <li><code>pip</code>: Python's package installer, usually bundled with Python installations.</li> <li>A <code>fal.ai</code> Account:<ul> <li>You can sign up for a free account at fal.ai. Basic usage often falls within the free tier.</li> </ul> </li> <li> <p><code>fal.ai</code> API Key:</p> <ul> <li>Once logged into your <code>fal.ai</code> dashboard, navigate to the \"API Keys\" section.</li> <li>Generate a new API key. This key grants programmatic access to your <code>fal.ai</code> resources. Treat it as sensitive information.</li> </ul> <p>Keep Your API Key Secure</p> <p>Never expose your API key in client-side code, public repositories, or plain text in configuration files. Use environment variables or secure secret management services.</p> </li> <li> <p>Basic Command Line Knowledge: Familiarity with executing commands in a terminal.</p> </li> <li>Basic Python Knowledge: Understanding of Python syntax, functions, and data structures.</li> </ul>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#4-execution","title":"4. Execution","text":"<p>Follow these steps to interact with a <code>fal.ai</code> public function. We'll use the Stable Diffusion <code>v1.5</code> text-to-image model as our example.</p>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#step-1-install-the-fal-ai-sdk","title":"Step 1: Install the <code>fal-ai</code> SDK","text":"<p>Open your terminal or command prompt and install the <code>fal-ai</code> Python SDK:</p> <pre><code>pip install fal_ai\n</code></pre>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#step-2-set-up-your-falai-api-key","title":"Step 2: Set Up Your <code>fal.ai</code> API Key","text":"<p>It is best practice to set your <code>fal.ai</code> API key as an environment variable. Replace <code>YOUR_FAL_KEY_HERE</code> with the actual key you obtained from your <code>fal.ai</code> dashboard.</p> <p>Linux / macOS:</p> <pre><code>export FAL_KEY=\"YOUR_FAL_KEY_HERE\"\n</code></pre> <p>Windows (Command Prompt):</p> <pre><code>set FAL_KEY=\"YOUR_FAL_KEY_HERE\"\n</code></pre> <p>Windows (PowerShell):</p> <pre><code>$env:FAL_KEY=\"YOUR_FAL_KEY_HERE\"\n</code></pre> <p>Alternatively, you can pass the key directly in your Python script, but this is less recommended for production environments:</p> <pre><code>import fal_ai as fal\nfal.FAL_KEY = \"YOUR_FAL_KEY_HERE\" # Not recommended for production\n</code></pre>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#step-3-choose-a-public-function-model-id","title":"Step 3: Choose a Public Function (Model ID)","text":"<p><code>fal.ai</code> hosts numerous public models. You can find a list and their respective <code>model_id</code> values in the <code>fal.ai</code> documentation, for example, under their Models section.</p> <p>For this tutorial, we will use the Stable Diffusion <code>v1.5</code> model, which has the <code>model_id</code>: <code>fal-ai/stable-diffusion-v1-5</code>.</p>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#step-4-write-the-python-script","title":"Step 4: Write the Python Script","text":"<p>Create a new Python file (e.g., <code>generate_image.py</code>) and add the following code:</p> <pre><code>import fal_ai as fal\nimport os\nimport requests\n\n# Define the model ID for the Stable Diffusion v1.5 public function\n# You can explore other public models in the fal.ai documentation.\nMODEL_ID = \"fal-ai/stable-diffusion-v1-5\"\n\n# Define the prompt for image generation\nPROMPT = \"a professional photograph of an astronaut riding a majestic horse on the moon, cinematic, 8k\"\n\n# Define output directory\nOUTPUT_DIR = \"generated_images\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(f\"--- Calling fal.ai public function: {MODEL_ID} ---\")\nprint(f\"Prompt: {PROMPT}\")\n\ntry:\n    # Call the fal.run() method with the model ID and its specific arguments\n    # The arguments dictionary varies per function. Refer to fal.ai docs for each model.\n    result = fal.run(\n        MODEL_ID,\n        arguments={\n            \"prompt\": PROMPT,\n            \"width\": 768,\n            \"height\": 512,\n            \"num_inference_steps\": 50,\n            \"seed\": 42, # A fixed seed for reproducibility\n        },\n    )\n\n    # Check if images were returned\n    if result and \"images\" in result and len(result[\"images\"]) &gt; 0:\n        image_url = result[\"images\"][0][\"url\"]\n        image_filename = os.path.join(OUTPUT_DIR, \"generated_image.png\")\n\n        print(f\"\\n--- Image generated successfully! ---\")\n        print(f\"Image URL: {image_url}\")\n\n        # Download the image\n        print(f\"Downloading image to {image_filename}...\")\n        response = requests.get(image_url)\n        if response.status_code == 200:\n            with open(image_filename, \"wb\") as f:\n                f.write(response.content)\n            print(\"Image saved successfully.\")\n        else:\n            print(f\"Failed to download image. Status code: {response.status_code}\")\n    else:\n        print(\"\\n--- No images found in the result. ---\")\n        print(f\"Full result: {result}\")\n\nexcept fal.FalServerlessError as e:\n    print(f\"\\n--- An error occurred during function execution: ---\")\n    print(f\"Error Type: {type(e).__name__}\")\n    print(f\"Message: {e}\")\n    print(f\"Details: {e.details}\")\nexcept Exception as e:\n    print(f\"\\n--- An unexpected error occurred: ---\")\n    print(f\"Error Type: {type(e).__name__}\")\n    print(f\"Message: {e}\")\n</code></pre>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#code-explanation","title":"Code Explanation:","text":"<ul> <li><code>import fal_ai as fal</code>: Imports the <code>fal_ai</code> SDK.</li> <li><code>fal.run(MODEL_ID, arguments={...})</code>: This is the core function call.<ul> <li><code>MODEL_ID</code>: Specifies which <code>fal.ai</code> public function to execute.</li> <li><code>arguments</code>: A dictionary of parameters required by the specific model. These parameters are unique to each model (e.g., <code>prompt</code>, <code>width</code>, <code>height</code> for image generation). Always refer to the model's specific documentation on <code>fal.ai</code> for required arguments.</li> </ul> </li> <li>The <code>result</code> object contains the output from the function, which for image generation includes a list of image URLs.</li> <li>We use the <code>requests</code> library to download the generated image. You might need to <code>pip install requests</code> if you don't have it.</li> </ul>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#step-5-run-the-script","title":"Step 5: Run the Script","text":"<p>Save the file and run it from your terminal:</p> <pre><code>python generate_image.py\n</code></pre>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#5-validation","title":"5. Validation","text":"<p>Upon successful execution, your terminal output should resemble the following:</p> <pre><code>--- Calling fal.ai public function: fal-ai/stable-diffusion-v1-5 ---\nPrompt: a professional photograph of an astronaut riding a majestic horse on the moon, cinematic, 8k\n\n--- Image generated successfully! ---\nImage URL: https://media.fal.ai/path/to/your/generated_image.png\nDownloading image to generated_images/generated_image.png...\nImage saved successfully.\n</code></pre> <p>Additionally, you should find a new directory named <code>generated_images</code> in the same location as your script, containing a file named <code>generated_image.png</code>. Open this image file to verify the output from the Stable Diffusion model.</p> <p>Troubleshooting</p> <ul> <li>Authentication Error: If you see an error related to <code>FAL_KEY</code> or authentication, double-check that your <code>FAL_KEY</code> environment variable is correctly set and that the key itself is valid.</li> <li>Argument Error: If the model complains about missing or invalid arguments, cross-reference the <code>arguments</code> dictionary in your script with the official <code>fal.ai</code> documentation for the specific <code>MODEL_ID</code> you are using.</li> <li>Network Issues: Ensure you have an active internet connection.</li> <li>Rate Limits: If you are making many requests quickly, you might hit <code>fal.ai</code>'s rate limits. The SDK usually handles retries, but a brief pause might be needed.</li> </ul>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#6-tearing-down","title":"6. Tearing Down","text":"<p>Since <code>fal.ai</code>'s public functions are serverless, there is no infrastructure for you to explicitly \"tear down\" or de-provision. However, you can clean up your local environment and manage your <code>fal.ai</code> account resources:</p> <ul> <li>Delete Generated Files: Remove the <code>generated_images</code> directory and its contents:     <pre><code>rm -rf generated_images  # Linux/macOS\nrmdir /s /q generated_images # Windows\n</code></pre></li> <li>Delete Script: Remove the <code>generate_image.py</code> file.</li> <li>Uninstall SDK (Optional): If you no longer plan to use <code>fal.ai</code>, you can uninstall the SDK:     <pre><code>pip uninstall fal_ai requests\n</code></pre></li> <li>Revoke API Key (Optional but Recommended): For security, if you no longer need the API key used for this tutorial, consider revoking it from your <code>fal.ai</code> dashboard. This prevents unauthorized use.</li> </ul>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/falai/#7-conclusion","title":"7. Conclusion","text":"<p>You have successfully learned how to interact with <code>fal.ai</code>'s powerful public functions using the <code>fal-ai</code> Python SDK. You can now:</p> <ul> <li>Set up your development environment for <code>fal.ai</code> API calls.</li> <li>Securely authenticate using your <code>fal.ai</code> API key.</li> <li>Invoke pre-trained AI models like Stable Diffusion for tasks such as image generation.</li> <li>Process and validate the results from <code>fal.ai</code> function executions.</li> </ul> <p>This capability opens up a world of possibilities for integrating advanced AI into your applications without the complexities of infrastructure management. Explore the <code>fal.ai</code> documentation further to discover other public functions and learn about deploying your own custom serverless applications.</p> <ul> <li>fal.ai Official Documentation</li> <li>fal.ai Models List ```</li> </ul>","tags":["fal.ai","API","serverless","python","AI","tutorial"]},{"location":"tutorials/pixeldrain/","title":"Interacting with the Pixeldrain Public API","text":"","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#interacting-with-the-pixeldrain-public-api","title":"Interacting with the Pixeldrain Public API","text":"<p>This tutorial provides a comprehensive guide on how to interact with the Pixeldrain public API using common programming concepts. You will learn to upload files, retrieve file information, download files, and manage uploaded content programmatically.</p>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#introduction","title":"Introduction","text":"<p>Pixeldrain is a versatile online service for sharing files. While its web interface offers a convenient way to upload and download content, its public API unlocks powerful capabilities for developers and users who wish to automate file management tasks. This guide will walk you through the essential API endpoints, enabling you to integrate Pixeldrain functionality directly into your applications or scripts.</p>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#overview","title":"Overview","text":"<p>The primary challenge this tutorial addresses is the need for programmatic interaction with a file-sharing service. Manually uploading or downloading numerous files through a web browser can be time-consuming and inefficient. By leveraging the Pixeldrain API, users can:</p> <ul> <li>Automate file uploads from scripts or applications.</li> <li>Retrieve detailed information about uploaded files without manual inspection.</li> <li>Programmatically download files for processing or archiving.</li> <li>Manage uploaded content through deletion commands.</li> </ul> <p>This tutorial focuses on the fundamental public API endpoints, providing a solid foundation for more complex integrations.</p>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following:</p> <ul> <li>Basic understanding of HTTP requests: Familiarity with concepts like GET, POST, and DELETE methods.</li> <li>A programming environment: This tutorial will use Python for its simplicity and widespread adoption, along with the <code>requests</code> library for making HTTP calls.</li> <li><code>pip</code>: Python's package installer, used to install the <code>requests</code> library.</li> <li>An internet connection: To access the Pixeldrain API.</li> <li><code>curl</code> (optional): Useful for quick tests and direct API calls from the command line.</li> </ul> <p>To install the <code>requests</code> library, open your terminal or command prompt and run:</p> <pre><code>pip install requests\n</code></pre>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#execution","title":"Execution","text":"<p>This section details the step-by-step process of interacting with the Pixeldrain API.</p>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#step-1-uploading-a-file","title":"Step 1: Uploading a File","text":"<p>The most common operation is uploading a file. Pixeldrain allows anonymous uploads, which are ideal for quick sharing.</p> <p>API Endpoint: <code>POST https://pixeldrain.com/api/file</code> Method: <code>POST</code> Parameters: - <code>file</code>: The file data to upload. - <code>anonymous</code> (optional): Set to <code>true</code> to perform an anonymous upload.</p> <p>Let's create a dummy file for upload:</p> <pre><code>echo \"This is a test file for the Pixeldrain API tutorial.\" &gt; my_test_file.txt\n</code></pre> <p>Now, upload it using Python:</p> <pre><code>import requests\nimport json\n\nfile_path = 'my_test_file.txt'\n\ntry:\n    with open(file_path, 'rb') as f:\n        files = {'file': f}\n        data = {'anonymous': 'true'} # Optional: upload anonymously\n\n        print(f\"Uploading {file_path}...\")\n        response = requests.post('https://pixeldrain.com/api/file', files=files, data=data)\n        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n\n        upload_info = response.json()\n\n        file_id = upload_info.get('id')\n        delete_key = upload_info.get('deleteKey') # Important for deletion!\n\n        if file_id:\n            print(f\"File uploaded successfully!\")\n            print(f\"File ID: {file_id}\")\n            print(f\"Delete Key: {delete_key}\")\n            print(f\"View URL: https://pixeldrain.com/u/{file_id}\")\n            print(f\"Download URL: https://pixeldrain.com/api/file/{file_id}\")\n\n            # Save info for later steps\n            with open('uploaded_file_info.json', 'w') as info_file:\n                json.dump(upload_info, info_file, indent=4)\n            print(\"File ID and Delete Key saved to 'uploaded_file_info.json'\")\n        else:\n            print(\"Upload successful, but 'id' not found in response.\")\n            print(f\"Response: {json.dumps(upload_info, indent=4)}\")\n\nexcept requests.exceptions.RequestException as e:\n    print(f\"An error occurred during upload: {e}\")\nexcept FileNotFoundError:\n    print(f\"Error: File not found at {file_path}\")\n</code></pre> <p>Note</p> <p>The <code>deleteKey</code> is crucial if you intend to programmatically delete the file later. Always store it securely if needed. For anonymous uploads without an account, this is the only way to delete the file.</p>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#step-2-getting-file-information","title":"Step 2: Getting File Information","text":"<p>Once a file is uploaded, you can retrieve its metadata.</p> <p>API Endpoint: <code>GET https://pixeldrain.com/api/file/{id}/info</code> Method: <code>GET</code> Parameters: <code>{id}</code> - The ID of the uploaded file.</p> <p>Let's use the <code>file_id</code> obtained from the previous step:</p> <pre><code>import requests\nimport json\n\n# Load file info saved from the upload step\ntry:\n    with open('uploaded_file_info.json', 'r') as f:\n        uploaded_file_info = json.load(f)\n        file_id = uploaded_file_info.get('id')\n\n    if not file_id:\n        print(\"Error: 'file_id' not found in 'uploaded_file_info.json'. Please run the upload step first.\")\n        exit()\n\nexcept FileNotFoundError:\n    print(\"Error: 'uploaded_file_info.json' not found. Please run the upload step first.\")\n    exit()\n\ntry:\n    print(f\"\\nRetrieving info for File ID: {file_id}...\")\n    response = requests.get(f'https://pixeldrain.com/api/file/{file_id}/info')\n    response.raise_for_status()\n\n    file_info = response.json()\n    print(\"File Information:\")\n    print(json.dumps(file_info, indent=4))\n\nexcept requests.exceptions.RequestException as e:\n    print(f\"An error occurred while retrieving file info: {e}\")\n    if response.status_code == 404:\n        print(\"Error: File not found. It might have been deleted or the ID is incorrect.\")\n</code></pre>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#step-3-downloading-a-file","title":"Step 3: Downloading a File","text":"<p>You can directly download the content of an uploaded file.</p> <p>API Endpoint: <code>GET https://pixeldrain.com/api/file/{id}</code> Method: <code>GET</code> Parameters: <code>{id}</code> - The ID of the file to download.</p> <p>Let's download the <code>my_test_file.txt</code> we uploaded:</p> <pre><code>import requests\nimport json\nimport os\n\n# Load file info\ntry:\n    with open('uploaded_file_info.json', 'r') as f:\n        uploaded_file_info = json.load(f)\n        file_id = uploaded_file_info.get('id')\n        original_filename = uploaded_file_info.get('name', 'downloaded_file.txt') # Use original name or default\n\n    if not file_id:\n        print(\"Error: 'file_id' not found in 'uploaded_file_info.json'. Please run the upload step first.\")\n        exit()\n\nexcept FileNotFoundError:\n    print(\"Error: 'uploaded_file_info.json' not found. Please run the upload step first.\")\n    exit()\n\ndownload_path = f\"downloaded_{original_filename}\"\n\ntry:\n    print(f\"\\nDownloading File ID: {file_id} to {download_path}...\")\n    response = requests.get(f'https://pixeldrain.com/api/file/{file_id}', stream=True)\n    response.raise_for_status()\n\n    with open(download_path, 'wb') as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n\n    print(f\"File downloaded successfully to: {os.path.abspath(download_path)}\")\n\nexcept requests.exceptions.RequestException as e:\n    print(f\"An error occurred while downloading the file: {e}\")\n    if response.status_code == 404:\n        print(\"Error: File not found. It might have been deleted or the ID is incorrect.\")\n</code></pre>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#step-4-deleting-a-file","title":"Step 4: Deleting a File","text":"<p>To clean up or manage storage, you can delete uploaded files. This requires the <code>deleteKey</code> obtained during the upload.</p> <p>API Endpoint: <code>DELETE https://pixeldrain.com/api/file/{id}</code> Method: <code>DELETE</code> Parameters: - <code>{id}</code>: The ID of the file to delete. - <code>key</code>: The <code>deleteKey</code> associated with the file.</p> <pre><code>import requests\nimport json\nimport os\n\n# Load file info\ntry:\n    with open('uploaded_file_info.json', 'r') as f:\n        uploaded_file_info = json.load(f)\n        file_id = uploaded_file_info.get('id')\n        delete_key = uploaded_file_info.get('deleteKey')\n\n    if not file_id or not delete_key:\n        print(\"Error: 'file_id' or 'deleteKey' not found in 'uploaded_file_info.json'. Please run the upload step first.\")\n        exit()\n\nexcept FileNotFoundError:\n    print(\"Error: 'uploaded_file_info.json' not found. Please run the upload step first.\")\n    exit()\n\ntry:\n    print(f\"\\nAttempting to delete File ID: {file_id}...\")\n\n    # Send the delete key as a query parameter\n    response = requests.delete(f'https://pixeldrain.com/api/file/{file_id}?key={delete_key}')\n    response.raise_for_status()\n\n    delete_status = response.json()\n    if delete_status.get('success'):\n        print(f\"File ID {file_id} deleted successfully.\")\n    else:\n        print(f\"Failed to delete file. Response: {json.dumps(delete_status, indent=4)}\")\n\nexcept requests.exceptions.RequestException as e:\n    print(f\"An error occurred during file deletion: {e}\")\n    if response.status_code == 404:\n        print(\"Error: File not found (already deleted or incorrect ID/key).\")\n    elif response.status_code == 401:\n        print(\"Error: Unauthorized. The delete key might be incorrect or expired.\")\n\n# Remove the temporary info file\nif os.path.exists('uploaded_file_info.json'):\n    os.remove('uploaded_file_info.json')\n    print(\"Removed 'uploaded_file_info.json'\")\n</code></pre>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#validation","title":"Validation","text":"<p>To verify the tutorial's outcome, perform the following checks:</p> <ol> <li>After Upload:<ul> <li>Confirm that the Python script outputs a <code>File ID</code> and <code>Delete Key</code>.</li> <li>Visit the <code>View URL</code> (e.g., <code>https://pixeldrain.com/u/{file_id}</code>) in your web browser. You should see the uploaded file content or a file information page.</li> </ul> </li> <li>After Getting File Information:<ul> <li>Verify that the script prints a JSON output containing details like <code>id</code>, <code>name</code>, <code>size</code>, <code>uploadDate</code>, etc., matching your expectations for the uploaded file.</li> </ul> </li> <li>After Downloading File:<ul> <li>Check your local directory for a new file named <code>downloaded_my_test_file.txt</code> (or whatever your <code>original_filename</code> was).</li> <li>Open this file and confirm its content matches the original <code>my_test_file.txt</code>.</li> <li>Compare the file sizes to ensure a complete download.</li> </ul> </li> <li>After Deleting File:<ul> <li>Re-attempt to visit the <code>View URL</code> (<code>https://pixeldrain.com/u/{file_id}</code>) in your web browser. You should now see a \"404 Not Found\" page or an error indicating the file does not exist.</li> <li>Re-run the \"Getting File Information\" script. It should now report a \"404 Not Found\" error, confirming the file's deletion from Pixeldrain.</li> </ul> </li> </ol>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#tearing-down","title":"Tearing Down","text":"<p>To clean up resources and your local environment:</p> <ol> <li> <p>Delete Local Files: Remove the temporary files created during the tutorial:</p> <ul> <li><code>my_test_file.txt</code> (the original file uploaded)</li> <li><code>downloaded_my_test_file.txt</code> (the file downloaded)</li> </ul> <p>You can do this manually or use a command like: </p><pre><code>rm my_test_file.txt downloaded_my_test_file.txt\n</code></pre> (On Windows, use <code>del my_test_file.txt downloaded_my_test_file.txt</code>) </li> <li> <p>Pixeldrain Files: The \"Deleting a File\" step explicitly removed the uploaded file from Pixeldrain using its <code>deleteKey</code>. If you skipped that step, ensure you manually delete any files you don't wish to keep on Pixeldrain, especially if they are not anonymous or contain sensitive information. For anonymous uploads without an account, the <code>deleteKey</code> is the only way to delete the file programmatically.</p> </li> </ol>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"tutorials/pixeldrain/#conclusion","title":"Conclusion","text":"<p>This tutorial has guided you through the fundamental interactions with the Pixeldrain public API, covering file uploads, information retrieval, downloads, and deletions. You have learned how to use Python's <code>requests</code> library to send HTTP requests, handle responses, and manage temporary data crucial for API operations.</p> <p>By mastering these basic operations, you are now equipped to:</p> <ul> <li>Automate routine file sharing tasks.</li> <li>Integrate Pixeldrain functionality into larger scripts or applications.</li> <li>Efficiently manage digital assets without relying solely on the web interface.</li> </ul> <p>Remember to consult the official Pixeldrain API documentation for more advanced features, such as folder management, user-specific operations (if authenticated), and additional parameters for existing endpoints. The principles learned here are transferable to many other RESTful APIs.</p>","tags":["API","Pixeldrain","File Management","Upload","Download","Automation"]},{"location":"blog/archive/2025/","title":"2025","text":""}]}